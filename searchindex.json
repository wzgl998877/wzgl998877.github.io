{"categories":[{"title":"Java","uri":"https://wzgl998877.github.io/categories/java/"},{"title":"Linux","uri":"https://wzgl998877.github.io/categories/linux/"},{"title":"中间件","uri":"https://wzgl998877.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"title":"常用框架","uri":"https://wzgl998877.github.io/categories/%E5%B8%B8%E7%94%A8%E6%A1%86%E6%9E%B6/"},{"title":"数据库","uri":"https://wzgl998877.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"title":"日常总结","uri":"https://wzgl998877.github.io/categories/%E6%97%A5%E5%B8%B8%E6%80%BB%E7%BB%93/"},{"title":"算法","uri":"https://wzgl998877.github.io/categories/%E7%AE%97%E6%B3%95/"},{"title":"系统设计","uri":"https://wzgl998877.github.io/categories/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"title":"网络编程","uri":"https://wzgl998877.github.io/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"}],"posts":[{"content":"[TOC]\n本篇文章是(Mysql是怎样运行的)阅读笔记，这本书网上很多人的评价都很高，看了下书也不是很厚，所以读读。\nMySQL的架构 mysql 工作的整体流程为，客户端进程向服务器进程发送一段文本（MySQL语句），服务器进程处理后再向客户端进程发送一段文本（处理结果）。如图：\n连接管理 ​\t客户端进程可以采用我们上边介绍的TCP/IP 、命名管道或共享内存、Unix域套接字这几种方式之一来与服务 器进程建立连接，每当有一个客户端进程连接到服务器进程时，服务器进程都会创建一个线程来专门处理与这个 客户端的交互，当该客户端退出时会与服务器断开连接，服务器并不会立即把与该客户端交互的线程销毁掉，而 是把它缓存起来，在另一个新的客户端再进行连接时，把这个缓存的线程分配给该新客户端。这样就起到了不频 繁创建和销毁线程的效果，从而节省开销。 ​\t当连接建立后，与该客户端关联的服务器线程会一直等待客户端发送过来的请求， MySQL 服务器接收到的请求只是一个文本消息，该文本消息还要经过各种处理，才能转化为mysql能识别的语句。\n解析与优化 ​\tMySQL 服务器获得了文本形式的请求后，接着 还要经过九九八十一难的处理，其中的几个比较重要的部分分别是查询缓存、语法解析和查询优化。\n查询缓存 ​\tMySQL 服务器程序处理查询请求时，会把刚刚处理过的查询请求和结果缓存起来，如果下一次有一模一样的请求过来，直接从缓存中查找结果就好了，就不用再傻呵呵的去底层的表中查找了。这个查询缓存可以在不同客户端之间共享，也就是说如果客户端A刚刚查询了一个语句，而客户端B之后发送了同样的查询请求，那么客户端B的这次查询就可以直接使用查询缓存中的数据。 ​\t当然， MySQL 服务器并没有人聪明，如果两个查询请求在任何字符上的不同（例如：空格、注释、大小写），都会导致缓存不会命中。另外，如果查询请求中包含某些系统函数、用户自定义变量和函数、一些系统表，如 mysql 、information_schema、 performance_schema 数据库中的表，那这个请求就不会被缓存。以某些系统函数举例，可能同样的函数的两次调用会产生不一样的结果，比如函数NOW ，每次调用都会产生最新的当前时间，如果在一个查询请求中调用了这个函数，那即使查询请求的文本信息都一样，那不同时间的两次查询也应该得到不同的结果，如果在第一次查询时就缓存了，那第二次查询的时候直接使用第一次查询的结果就是错误的！ 不过既然是缓存，那就有它缓存失效的时候。\n​\tMySQL的缓存系统会监测涉及到的每张表，只要该表的结构或者数据被修改，如对该表使用了INSERT 、 UPDATE 、DELETE 、TRUNCATE TABLE 、ALTER TABLE 、DROP TABLE 或 DROP DATABASE 语句，那使用该表的所有高速缓存查询都将变为无效并从高速缓存中删除！\n 虽然查询缓存有时可以提升系统性能，但也不得不因维护这块缓存而造成一些开销，比如每次都要去查 询缓存中检索，查询请求处理完需要更新查询缓存，维护该查询缓存对应的内存区域。从MySQL 5.7.20 开始，不推荐使用查询缓存，并在MySQL 8.0中删除。\n 语法解析 ​\t如果查询缓存没有命中，接下来就需要进入正式的查询阶段了。因为客户端程序发送过来的请求只是一段文本而已，所以MySQL 服务器程序首先要对这段文本做分析，判断请求的语法是否正确，然后从文本中将要查询的表、各种查询条件都提取出来放到MySQL 服务器内部使用的一些数据结构上来。\n查询优化 ​\t语法解析之后，服务器程序获得到了需要的信息，比如要查询的列是哪些，表是哪个，搜索条件是什么等等，但光有这些是不够的，因为我们写的MySQL 语句执行起来效率可能并不是很高， MySQL 的优化程序会对我们的语句做一些优化，如外连接转换为内连接、表达式简化、子查询转为连接等。优化的结果就是生成一个执行计划，这个执行计划表明了应该使用哪些索引进行查询，表之间的连接顺序是啥样的。我们可以使用EXPLAIN 语句来查看某个语句的执行计划\n存储引擎 ​\t截止到服务器程序完成了查询优化为止，还没有真正的去访问真实的数据表， MySQL 服务器把数据的存储和提取操作都封装到了一个叫存储引擎的模块里。我们知道表是由一行一行的记录组成的，但这只是一个逻辑上的概 念，物理上如何表示记录，怎么从表中读取数据，怎么把数据写入具体的物理存储器上，这都是存储引擎负责 的事情。为了实现不同的功能， MySQL 提供了各式各样的存储引擎，不同存储引擎管理的表具体的存储结构 可能不同，采用的存取算法也可能不同。\n​\t为了管理方便，人们把连接管理、查询缓存、语法解析、查询优化这些并不涉及真实数据存储的功能划分 为MySQL server 的功能，把真实存取数据的功能划分为存储引擎的功能。各种不同的存储引擎向上边的MySQL server 层提供统一的调用接口（也就是存储引擎API），包含了几十个底层函数，像\u0026quot;读取索引第一条内容\u0026quot;、\u0026ldquo;读 取索引下一条内容\u0026rdquo;、\u0026ldquo;插入记录\u0026quot;等等。\n​\t常用的存储引擎有：ARCHIVE、BLACKHOLE、InnoDB、MyISAM等，最常用的就是InnoDB 和MyISAM，其中InnoDB 是MySQL 默认的存储引擎。\n深入研究InnoDB ​\tInnoDB 是一个将表中的数据存储到磁盘上的存储引擎，所以即使关机后重启我们的数据还是存在的。而真正处 理数据的过程是发生在内存中的，所以需要把磁盘中的数据加载到内存中，如果是处理写入或修改请求的话，还 需要把内存中的内容刷新到磁盘上。而我们知道读写磁盘的速度非常慢，和内存读写差了几个数量级，所以当我 们想从表中获取某些记录时， InnoDB 存储引擎需要一条一条的把记录从磁盘上读出来么？不，那样会慢死， InnoDB 采取的方式是：将数据划分为若干个页，以页作为磁盘和内存之间交互的基本单位，InnoDB中页的大小 一般为 16 KB。也就是在一般情况下，一次最少从磁盘中读取16KB的内容到内存中，一次最少把内存中的16KB 内容刷新到磁盘中\nInnoDB行格式 ​\t我们平时是以记录为单位来向表中插入数据的，这些记录在磁盘上的存放方式也被称为行格式或者记录格式。 设计InnoDB 存储引擎的大叔们到现在为止设计了4种不同类型的行格式，分别是Compact 、Redundant 、 Dynamic 和Compressed 行格式。\nCompact ​\t从图中可以看出来，一条完整的记录其实可以被分为记录的额外信息和记录的真实数据两大部分，下边我 们详细看一下这两部分的组成。\n记录的额外信息 ​\t这部分信息是服务器为了描述这条记录而不得不额外添加的一些信息，这些额外信息分为3类，分别是变长字段 长度列表、NULL值列表和记录头信息，我们分别看一下。\n变长字段长度列表\n​\tMySQL 支持一些变长的数据类型，比如VARCHAR(M) 、VARBINARY(M) 、各种TEXT 类型，各种BLOB 类型，我们也可以把拥有这些数据类型的列称为变长字段，变长字段中存储多少字节的数据是不固定的，所以我 们在存储真实数据的时候需要顺便把这些数据占用的字节数也存起来，这样才不至于把MySQL 服务器搞懵，所以 这些变长字段占用的存储空间分为两部分：\n 真正的数据内容 占用的字节数  在Compact 行格式中，把所有变长字段的真实数据占用的字节长度都存放在记录的开头部位，从而形成一个变长 字段长度列表，各变长字段数据占用的字节数按照列的顺序逆序存放，我们再次强调一遍，是逆序存放！\n我们拿record_format_demo 表中的第一条记录来举个例子。因为record_format_demo 表的c1 、c2 、c4 列 都是VARCHAR(10) 类型的，也就是变长的数据类型，所以这三个列的值的长度都需要保存在记录开头处，因为 record_format_demo 表中的各个列都使用的是ascii 字符集，所以每个字符只需要1个字节来进行编码，来看 一下第一条记录各变长字段内容的长度：\n   列名 存储内容 内容长度（十进制表示） 内容长度（十六进制表示）     c1 \u0026lsquo;aaaa\u0026rsquo; 4 0x04   c2 \u0026lsquo;bbb\u0026rsquo; 3 0x03   c4 \u0026rsquo;d' 1 0x01    又因为这些长度值需要按照列的逆序存放，所以最后变长字段长度列表的字节串用十六进制表示的效果就是 （各个字节之间实际上没有空格，用空格隔开只是方便理解）： 01 03 04 把这个字节串组成的变长字段长度列表填入上边的示意图中的效果就是：\n由于第一行记录中c1 、c2 、c4 列中的字符串都比较短，也就是说内容占用的字节数比较小，用1个字节就可 以表示，但是如果变长列的内容占用的字节数比较多，可能就需要用2个字节来表示。具体用1个还是2个字节来 表示真实数据占用的字节数， InnoDB 有它的一套规则，我们首先声明一下W 、M 和L 的意思：\n 假设某个字符集中表示一个字符最多需要使用的字节数为W ，也就是使用SHOW CHARSET 语句的结果中的 Maxlen 列，比方说utf8 字符集中的W 就是3 ， gbk 字符集中的W 就是2 ， ascii 字符集中的W 就是1 。 对于变长类型VARCHAR(M) 来说，这种类型表示能存储最多M 个字符（注意是字符不是字节），所以这个类 型能表示的字符串最多占用的字节数就是M×W 。 假设它实际存储的字符串占用的字节数是L 。   所以确定使用1个字节还是2个字节表示真正字符串占用的字节数的规则就是这样： 如果M×W \u0026lt;= 255 ，那么使用1个字节来表示真正字符串占用的字节数，为什么呢？很简单因为一个字节由8位二进制构成而8位二进制最多也只能表示256这个数，（但还有一位是标志位所以就是255）。\n​\t如果M×W \u0026gt; 255 ，则分为两种情况： ​\t如果L \u0026lt;= 127 ，则用1个字节来表示真正字符串占用的字节数。 ​\t如果L \u0026gt; 127 ，则用2个字节来表示真正字符串占用的字节数。 InnoDB在读记录的变长字段长度列表时先查看表结构，如果某个变长字段允许存储的最大字节 数大于255时，该怎么区分它正在读的某个字节是一个单独的字段长度还是半个字段长度呢？ 设计InnoDB的大叔使用该字节的第一个二进制位作为标志位：如果该字节的第一个位为0，那 **该字节就是一个单独的字段长度（**使用一个字节表示不大于127的二进制的第一个位都为0）， 如果该字节的第一个位为1，那该字节就是半个字段长度。 对于一些占用字节数非常多的字段，比方说某个字段长度大于了16KB，那么如果该记录在单个 页面中无法存储时，InnoDB会把一部分数据存放到所谓的溢出页中（我们后边会唠叨），在变 长字段长度列表处只存储留在本页面中的长度，所以使用两个字节也可以存放下来。\n 总结一下就是说：如果该可变字段允许存储的最大字节数（ M×W ）超过255字节并且真实存储的字节数（ L ） 超过127字节，则使用2个字节，否则使用1个字节。\nNULL值列表\n​\t我们知道表中的某些列可能存储NULL 值，如果把这些NULL 值都放到记录的真实数据中存储会很占地方，所 以Compact 行格式把这些值为NULL 的列统一管理起来，存储到NULL 值列表中，它的处理过程是这样的\n 首先统计表中允许存储NULL 的列有哪些。 我们前边说过，主键列、被NOT NULL 修饰的列都是不可以存储NULL 值的，所以在统计的时候不会把这些列 算进去。比方说表record_format_demo 的3个列c1 、c3 、c4 都是允许存储NULL 值的，而c2 列是被 NOT NULL 修饰，不允许存储NULL 值。 如果表中没有允许存储 NULL 的列，则 NULL值列表 也不存在了，否则将每个允许存储NULL 的列对应一个 二进制位，二进制位按照列的顺序逆序排列，二进制位表示的意义如下： 二进制位的值为1 时，代表该列的值为NULL 。 二进制位的值为0 时，代表该列的值不为NULL 。 再一次强调，二进制位按照列的顺序逆序排列，所以第一个列c1 和最后一个二进制位对应。：  MySQL 规定NULL值列表必须用整数个字节的位表示，如果使用的二进制位个数不是整数个字节，则在字节 的高位补0 。表record_format_demo 只有3个值允许为NULL 的列，对应3个二进制位，不足一个字节，所以在字节的高位补0 ，效果就是这样：  知道了规则后，再看看null值列表应该怎么存储，因为只有c1 、c3 、c4 都是允许存储NULL 值的所以只需要一个字节。\n对于第一条记录来说， c1 、c3 、c4 这3个列的值都不为NULL ，所以它们对应的二进制位都是0 ，用十六进制表示就是0x00 对于第二条记录来说， c1 、c3 、c4 这3个列中c3 和c4 的值都为NULL ，用十六进制表示就是： 0x06 。所以添加后为\n记录头信息\n​\t除了变长字段长度列表、NULL值列表之外，还有一个用于描述记录的记录头信息，它是由固定的5 个字节组 成。5 个字节也就是40 个二进制位，不同的位代表不同的意思\n记录的真实数据 ​\t对于record_format_demo 表来说， 记录的真实数据除了c1 、c2 、c3 、c4 这几个我们自己定义的列的数据 以外， MySQL 会为每个记录默认的添加一些列（也称为隐藏列），具体的列如下： 实际上这几个列的真正名称其实是：DB_ROW_ID （行ID唯一标识一条记录）、DB_TRX_ID（事务ID）、DB_ROLL_PTR（回滚指针）。 这里需要提一下InnoDB 表对主键的生成策略：优先使用用户自定义主键作为主键，如果用户没有定义主键，则 选取一个Unique 键作为主键，如果表中连Unique 键都没有定义的话，则InnoDB 会为表默认添加一个名为 row_id 的隐藏列作为主键。所以我们从上表中可以看出：InnoDB存储引擎会为每条记录都添加 transaction_id 和 roll_pointer 这两个列，但是 row_id 是可选的（在没有自定义主键以及Unique键的情况下才会添加该列）。 这些隐藏列的值不用我们操心， InnoDB 存储引擎会自己帮我们生成的。加上记录的真实数据的两个记录为：\n看这个图的时候我们需要注意几点：\n 表record_format_demo 使用的是ascii 字符集，所以0x61616161 就表示字符串\u0026rsquo;aaaa' ， 0x626262 就表 示字符串\u0026rsquo;bbb' ，以此类推。 注意第1条记录中c3 列的值，它是CHAR(10) 类型的，它实际存储的字符串是： \u0026lsquo;cc\u0026rsquo; ，而ascii 字符集中 的字节表示是'0x6363' ，虽然表示这个字符串只占用了2个字节，但整个c3 列仍然占用了10个字节的空 间，除真实数据以外的8个字节的统统都用空格字符填充，空格字符在ascii 字符集的表示就是0x20 。 注意第2条记录中c3 和c4 列的值都为NULL ，它们被存储在了前边的NULL值列表处，在记录的真实数据处 就不再冗余存储，从而节省存储空间。  对于 CHAR(M) 类型的列来说，当列采用的是定长字符集时，该列占用的字节数不会被加到变长字段长度列表，而如果采用变长字符集时，该列占用的字节数也会被加到变长字段长度列表。\n​\t另外有一点还需要注意，变长字符集的CHAR(M) 类型的列要求至少占用M 个字节，而VARCHAR(M) 却没有这个要求。比方说对于使用utf8 字符集的CHAR(10) 的列来说，该列存储的数据字节长度的范围是10～30个字节。即 使我们向该列中存储一个空字符串也会占用10 个字节，这是怕将来更新该列的值的字节长度大于原有值的字节 长度而小于10个字节时，可以在该记录处直接更新，而不是在存储空间中重新分配一个新的记录空间，导致原有 的记录空间成为所谓的碎片。\n行溢出数据 ​\t我们知道对于VARCHAR(M) 类型的列最多可以占用65535 个字节。其中的M 代表该类型最多存储的字符数量，如果我们使用ascii 字符集的话，一个字符就代表一个字节。为什么最多是65535呢？很简单，因为前面讲过的\n如果该可变字段允许存储的最大字节数（ M×W ）超过255字节并且真实存储的字节数（ L ） 超过127字节，则使用2个字节，否则使用1个字节。也就是说一个可变字段允许存储的最大字节数的长度最多只能用2个字节存储，而两个字节能表示的最大长度就是256*256=65536然后需要减去一个标志位。\n​\tMySQL 对一条记录占用的最大存储空间是有限制的，除了BLOB 或者TEXT 类型的列之外，其他所有的列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过65535 个字节。所以MySQL 服务器建议我们把存储类型改为TEXT 或者BLOB 的类型。这个65535 个字节除了列本身的数据之外，还包括一些其他的数据（ storage overhead ），比如说我们为了存储一个VARCHAR(M) 类型的列，其实需要占用3部分存储空间：\n 真实数据 真实数据占用字节的长度(变长字段长度列表最多为两个字节) NULL 值标识，如果该列有NOT NULL 属性则可以没有这部分存储空间（NULL值列表，一个字节）   因此，如果该VARCHAR(M)类型的列没有NOT NULL 属性，那最多只能存储65532 个字节的数据（65535-2-1），而根据字符集的不同，最大能存储的字符数也不同，比如gbk 字符集表示一个字符最多需要2 个字 节，那在该字符集下， M 的最大取值就是32766 （也就是：65532/2），也就是说最多能存储32766 个字符；utf8 字符集表示一个字符最多需要3 个字节，那在该字符集下， M 的最大取值就是21844 ，就是说最多能存储21844 （也就是：65532/3）个字符。\n 记录中的数据太多产生的溢出 ​\tMySQL 中磁盘和内存交互的基本单位是页，也就是说MySQL 是以页为基本单位来管理存储空间的，我们的记录都会被分配到某个页中存储。而一个页的大小一般是16KB ，也就是16384 字节，而一个VARCHAR(M) 类 型的列就最多可以存储65532 个字节，这样就可能造成一个页存放不了一条记录的尴尬情况\n​\t对于Compact 和Reduntant 行格式来说，如果某一列中的数据非常多的话，在本记录的真实数据处只会存储该列的前768 个字节的数据和一个指向其他页的地址，然后把剩下的数据存放到其他页中，这个过程也叫做行溢出，存储超出768 字节的那些页面也被称为溢出页\n\n 不只是 VARCHAR(M) 类型的列，其他的 TEXT、BLOB 类型的列在存储数据非常多的时候也会发生行溢出。\n 总结：对于Compact 来说，所占用的额外信息最多为27 字节：\n  2个字节用于存储真实数据的长度（最多）\n  1个字节用于存储列是否是NULL值（如果该列有NOT NULL 属性则可以没有这部分存储空间）\n  5个字节大小的头信息\n  6个字节的row_id 列（在没有自定义主键以及Unique键的情况下）\n  6个字节的transaction_id 列\n  7个字节的roll_pointer 列\n  Dynamic和Compressed行格式 ​\tDynamic 和Compressed 行格式 ，这俩行格式和Compact 行格式挺像，只不过在处理行溢出数据时有点儿分歧，它们不会在记录的真实数据处存储字段真实数据的前768 个字节，而是把所有的字节都存储到其他页面中，只在记录的真实数据处存储其他页面的地址，就像这样：\n其中mysql5.6 默认使用 Compact，mysql 5.7 默认使用Dynamic\nInnoDB数据页结构 ​\t页是InnoDB 管理存储空间的基本单位，一个页的大小一般是16KB 。InnoDB 为了不同的目的而设计了许多种不同类型的页，比如存放表空间头部信息的页，存放Insert Buffer信息的页，存放INODE 信息的页，存放undo 日志信息的页等。我们聚焦的是那些存放我们表中记录的那种类型的页，官方称这种存放记录的页为索引（ INDEX ）页。数据页代表的这块16KB 大小的存储空间可以被划分为多个部分，不同部分有不同的功能，各个部分如图所示：\n记录在页中的存储 ​\t在页的7个组成部分中，我们自己存储的记录会按照我们指定的行格式存储到User Records 部分。但是在一开 始生成页的时候，其实并没有User Records 这个部分，每当我们插入一条记录，都会从Free Space 部分，也就 是尚未使用的存储空间中申请一个记录大小的空间划分到User Records 部分，当Free Space 部分的空间全部 被User Records 部分替代掉之后，也就意味着这个页使用完了，如果还有新的记录插入的话，就需要去申请新 的页了，这个过程的图示如下：\n为了更好的管理在User Records 中的这些记录， InnoDB 可费了一番力气呢，在哪费力气了呢？不就是把记录按 照指定的行格式一条一条摆在User Records 部分么？其实这话还得从记录行格式的记录头信息中说起。\n记录头信息的秘密 由上图可以看出记录头信息中共有5个字节的数据，记录头信息中各个属性的大体意思为（基于Compact 行格式）：\n   名称 大小（单位：bit 位） 描述     预留位1 1 没有使用   预留位2 1 没有使用   delete_mask 1 标记该记录是否被删除   min_rec_mask 1 B+树的每层非叶子节点中的最小记录都会添加该标记   n_owned 4 表示当前记录拥有的记录数   heap_no 13 表示当前记录在记录堆的位置信息   record_type 3 表示当前记录的类型， 0 表示普通记录， 1 表示B+树非叶节点记录， 2 表示最小记录， 3表示最大记录   next_record 16 表示下一条记录的相对位置    下面，根据几个实例一起分析下\n  delete_mask 这个属性标记着当前记录是否被删除，占用1个二进制位，值为0 的时候代表记录并没有被删除，为1 的时 候代表记录被删除掉了。这些被删除的记录之所以不立即从磁盘上移除，是因为移除它们之后把其他的记录在磁盘上重新排列需要性能消耗，所以只是打一个删除标记而已，所有被删除掉的记录都会组成一个所谓的垃圾链表，在这个链表中的记录占用的空间称之为所谓的可重用空间，之后如果有新记录插入到表中的话，可能把这些被删除的记录占用的存储空间覆盖掉。\n  heap_no\n这个属性表示当前记录在本页中的位置，从图中可以看出来，我们插入的4条记录在本页中的位置分别 是： 2 、3 、4 、5 。是不是少了点啥？是的，怎么不见heap_no 值为0 和1 的记录呢？这其实是设计InnoDB 的大叔们玩的一个小把戏，他们自动给每个页里边儿加了两个记录，由于这两个记录并不是我们自己插入的，所以有时候也称为伪记录或者虚拟记录。这两个伪记录一个代表最小记录，一个代表最大记录，等一下哈~，记录可以比大小么？是的，记录也可以比大小，对于一条完整的记录来说，比较记录的大小就是比较主键的大小。比方说我们插入的4行记录的主键值分别是： 1 、2 、3 、4 ，这也就意味着这4条记录的大小从小到大依次递增。但是不管我们向页中插入了多少自己的记录，设计InnoDB 的大叔们都规定他们定义的两条伪记录分别为最小记录与最大记录。这两条记录的构造十分简单，都是由5字节大小的记录头信息和8字节大小的一个固定的部分组成的，如图所示\n  ​\t由于这两条记录不是我们自己定义的记录，所以它们并不存放在页的User Records 部分，他们被单独放在 ​\t一个称为Infimum + Supremum 的部分。\n  next_record\n它表示从当前记录的真实数据到下一条记录的真实数据的地址偏移量。比方说第一条记录的next_record 值为32 ，意味着从第一条记录的真实数据的地址处向后找32 个字节便是下一条记录的真实数据。如果你熟悉数据结构的话，就立即明白了，这其实是个链表，可以通过一条记录找到它的下一条记录。但是需要注意注意再注意的一点是， 下一条记录指得并不是按照我们插入顺序的下一条记录，而是按照主键值由小到大的顺序的下一条记录。而且规定 Infimum记录（也就是最小记录） 的下一条记录就是本页中主键值最小的用户记录，而本页中主键值最大的用户记录的下一条记录就是 Supremum记录（也就是最大记录） ，为了更形象的表示一下这个next_record 起到的作用，我们用箭头来替代一下next_record 中的地址偏移量\n  从图中可以看出来，我们的记录按照主键从小到大的顺序形成了一个单链表。最大记录的next_record 的 值为0 ，这也就是说最大记录是没有下一条记录了，它是这个单链表中的最后一个节点。如果从中删除掉 一条记录，这个链表也是会跟着变化的，比如我们把第2条记录删掉：\n从图中可以看出来，删除第2条记录前后主要发生了这些变化：\n  第2条记录并没有从存储空间中移除，而是把该条记录的delete_mask 值设置为1 。\n  第2条记录的next_record 值变为了0，意味着该记录没有下一条记录了。\n  第1条记录的next_record 指向了第3条记录。\n  还有一点你可能忽略了，就是最大记录的n_owned 值从5 变成了4 ，关于这一点的变化我们稍后会详 细说明的。所以，不论我们怎么对页中的记录做增删改操作，InnoDB始终会维护一条记录的单链表，链表中的各个节点是按照主键值由小到大的顺序连接起来的。\n  Page Directory（页目录） 现在我们了解了记录在页中按照主键值由小到大顺序串联成一个单链表，那如果我们想根据主键值查找页中的某 条记录该咋办呢？比如说这样的查询语句： SELECT * FROM page_demo WHERE c1 = 3;\n我们平常想从一本书中查找某个内容的时候，一般会先看目录，找到需要查找的内容对应的书的页码，然后到对 应的页码查看内容。设计InnoDB 的大叔们为我们的记录也制作了一个类似的目录，他们的制作过程是这样的：\n 将所有正常的记录（包括最大和最小记录，不包括标记为已删除的记录）划分为几个组。 每个组的最后一条记录（也就是组内最大的那条记录）的头信息中的n_owned 属性表示该记录拥有多少条记 录，也就是该组内共有几条记录。 将每个组的最后一条记录的地址偏移量单独提取出来按顺序存储到靠近页的尾部的地方，这个地方就是所 谓的Page Directory ，也就是页目录（此时应该返回头看看页面各个部分的图）。页面目录中的这些地址 偏移量被称为槽（英文名： Slot ），所以这个页面目录就是由槽组成的。  比方说现在的page_demo 表中正常的记录共有6条， InnoDB 会把它们分成两组，第一组中只有一个最小记录， 第二组中是剩余的5条记录，看下边的示意图：\n从这个图中我们需要注意这么几点：\n 现在页目录部分中有两个槽，也就意味着我们的记录被分成了两个组， 槽1 中的值是112 ，代表最大记录 的地址偏移量（就是从页面的0字节开始数，数112个字节）； 槽0 中的值是99 ，代表最小记录的地址偏移 量。 注意最小和最大记录的头信息中的n_owned 属性  最小记录的n_owned 值为1 ，这就代表着以最小记录结尾的这个分组中只有1 条记录，也就是最小记录 本身。 最大记录的n_owned 值为5 ，这就代表着以最大记录结尾的这个分组中只有5 条记录，包括最大记录本 身还有我们自己插入的4 条记录。    用图表示就是：\n为什么最小记录的n_owned 值为1，而最大记录的n_owned 值为5 呢，这里头有什么猫腻么？ 是的，设计InnoDB 的大叔们对每个分组中的记录条数是有规定的：对于最小记录所在的分组只能有 1 条记录， 最大记录所在的分组拥有的记录条数只能在 1~8 条之间，剩下的分组中记录的条数范围只能在是 4~8 条之间。 所以分组是按照下边的步骤进行的：\n 初始情况下一个数据页里只有最小记录和最大记录两条记录，它们分属于两个分组。 之后每插入一条记录，都会从页目录中找到主键值比本记录的主键值大并且差值最小的槽，然后把该槽对 应的记录的n_owned 值加1，表示本组内又添加了一条记录，直到该组中的记录数等于8个。 在一个组中的记录数等于8个后再插入一条记录时，会将组中的记录拆分成两个组，一个组中4条记录，另一 个5条记录。这个过程会在页目录中新增一个槽来记录这个新增分组中最大的那条记录的偏移量。  了解了页目录的组成后，那么怎么就加快查找速度的过程呢？看下这个例子\n比方说我们想找主键值为6 的记录，过程是这样的：\n 计算中间槽的位置： (0+4)/2=2 ，所以查看槽2 对应记录的主键值为8 ，又因为8 \u0026gt; 6 ，所以设置 high=2 ， low 保持不变。 重新计算中间槽的位置： (0+2)/2=1 ，所以查看槽1 对应的主键值为4 ，又因为4 \u0026lt; 6 ，所以设置 low=1 ， high 保持不变。 因为high - low 的值为1，所以确定主键值为5 的记录在槽2 对应的组中。此刻我们需要找到槽2 中主键 值最小的那条记录，然后沿着单向链表遍历槽2 中的记录。但是我们前边又说过，每个槽对应的记录都是该 组中主键值最大的记录，这里槽2 对应的记录是主键值为8 的记录，怎么定位一个组中最小的记录呢？别忘 了各个槽都是挨着的，我们可以很轻易的拿到槽1 对应的记录（主键值为4 ），该条记录的下一条记录就 是槽2 中主键值最小的记录，该记录的主键值为5 。所以我们可以从这条主键值为5 的记录出发，遍历槽 2 中的各条记录，直到找到主键值为6 的那条记录即可。由于一个组中包含的记录条数只能是1~8条，所以 遍历一个组中的记录的代价是很小的。  这就是典型的二分法哈哈，总结：\n 通过二分法确定该记录所在的槽，并找到该槽中主键值最小的那条记录。 通过记录的next_record 属性遍历该槽所在的组中的各个记录。  这个就是索引为什么这么快的理由吗？？？\nPage Header（页面头部） 设计InnoDB 的大叔们为了能得到一个数据页中存储的记录的状态信息，比如本页中已经存储了多少条记录，第 一条记录的地址是什么，页目录中存储了多少个槽等等，特意在页中定义了一个叫Page Header 的部分，它是 页结构的第二部分，这个部分占用固定的56 个字节，专门存储各种状态信息，具体各个字节都是干嘛的看下\n   名称 占用空间大小 描述     PAGE_N_DIR_SLOTS 2 字节 在页目录中的槽数量   PAGE_HEAP_TOP 2 字节 还未使用的空间最小地址，也就是说从该地址之后就是Free Space   PAGE_N_HEAP 2 字节 本页中的记录的数量（包括最小和最大记录以及标记为删除的记录）   PAGE_FREE 2 字节 第一个已经标记为删除的记录地址（各个已删除的记录通过next_record 也会组成一个单链表，这个单链表中的记录可以被重新利用）   PAGE_GARBAGE 2 字节 已删除记录占用的字节数   PAGE_LAST_INSERT 2 字节 最后插入记录的位置   PAGE_DIRECTION 2 字节 记录插入的方向   PAGE_N_DIRECTION 2 字节 一个方向连续插入的记录数量   PAGE_N_RECS 2 字节 该页中记录的数量（不包括最小和最大记录以及被标记为删除的记录）   PAGE_MAX_TRX_ID 8 字节 修改当前页的最大事务ID，该值仅在二级索引中定义   PAGE_LEVEL 2 字节 当前页在B+树中所处的层级   PAGE_INDEX_ID 8 字节 索引ID，表示当前页属于哪个索引   PAGE_BTR_SEG_LEAF 10 字节 B+树叶子段的头部信息，仅在B+树的Root页定义   PAGE_BTR_SEG_TOP 10 字节 B+树非叶子段的头部信息，仅在B+树的Root页定义     PAGE_DIRECTION 假如新插入的一条记录的主键值比上一条记录的主键值大，我们说这条记录的插入方向是右边，反之则是左 边。用来表示最后一条记录插入方向的状态就是PAGE_DIRECTION 。 PAGE_N_DIRECTION 假设连续几次插入新记录的方向都是一致的， InnoDB 会把沿着同一个方向插入记录的条数记下来，这个条 数就用PAGE_N_DIRECTION 这个状态表示。当然，如果最后一条记录的插入方向改变了的话，这个状态的值 会被清零重新统计。  File Header（文件头部） ​\tPage Header 是专门针对数据页记录的各种状态信息，比方说页里头有多少个记录了呀，有多少个槽了呀。我们现在描述的File Header 针对各种类型的页都通用，也就是说不同类型的页都会以File Header 作为第一个组成部分，它描述了一些针对各种页都通用的一些信息，比方说这个页的编号是多少，它的上一个页、下一个页 这个部分占用固定的38 个字节，是由下边这些内容组成的\n   名称 占用空间大小 描述     FIL_PAGE_SPACE_OR_CHKSUM 4 字节 页的校验和（checksum值）   FIL_PAGE_OFFSET 4 字节 页号，InnoDB 通过页号来可以唯一定位一个页   FIL_PAGE_PREV 4 字节 上一个页的页号   FIL_PAGE_NEXT 4 字节 下一个页的页号   FIL_PAGE_LSN 8 字节 页面被最后修改时对应的日志序列位置（英文名是：Log SequenceNumber）   FIL_PAGE_TYPE 2 字节 该页的类型   FIL_PAGE_FILE_FLUSH_LSN 8 字节 仅在系统表空间的一个页中定义，代表文件至少被刷新到了对应的LSN值   FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID 4 字节 页属于哪个表空间    详解：\n  FIL_PAGE_SPACE_OR_CHKSUM\n这个代表当前页面的校验和（checksum）。啥是个校验和？就是对于一个很长很长的字节串来说，我们会 通过某种算法来计算一个比较短的值来代表这个很长的字节串，这个比较短的值就称为校验和。这样在比 较两个很长的字节串之前先比较这两个长字节串的校验和，如果校验和都不一样两个长字节串肯定是不同 的，所以省去了直接比较两个比较长的字节串的时间损耗。\n  FIL_PAGE_TYPE\n这个代表当前页的类型，我们前边说过， InnoDB 为了不同的目的而把页分为不同的类型，我们上边介绍的 其实都是存储记录的数据页，其实还有很多别的类型的页，我们存放记录的数据页的类型其实是FIL_PAGE_INDEX ，也就是所谓的索引页。\n  FIL_PAGE_PREV 和FIL_PAGE_NEXT\n我们前边强调过， InnoDB 都是以页为单位存放数据的，有时候我们存放某种类型的数据占用的空间非常大 （比方说一张表中可以有成千上万条记录）， InnoDB 可能不可以一次性为这么多数据分配一个非常大的存 储空间，如果分散到多个不连续的页中存储的话需要把这些页关联起来， FIL_PAGE_PREV 和FIL_PAGE_NEXT 就分别代表本页的上一个和下一个页的页号。这样通过建立一个双向链表把许许多多的页就都串联起来了， 而无需这些页在物理上真正连着\n  File Trailer 我们知道InnoDB 存储引擎会把数据存储到磁盘上，但是磁盘速度太慢，需要以页为单位把数据加载到内存中处 理，如果该页中的数据在内存中被修改了，那么在修改后的某个时间需要把数据同步到磁盘中。但是在同步了一 半的时候中断电了咋办，这不是莫名尴尬么？为了检测一个页是否完整（也就是在同步的时候有没有发生只同步 一半的尴尬情况），设计InnoDB 的大叔们在每个页的尾部都加了一个File Trailer 部分，这个部分由8 个字 节组成，可以分成2个小部分：\n 前4个字节代表页的校验和 这个部分是和File Header 中的校验和相对应的。每当一个页面在内存中修改了，在同步之前就要把它的校 验和算出来，因为File Header 在页面的前边，所以校验和会被首先同步到磁盘，当完全写完时，校验和也 会被写到页的尾部，如果完全同步成功，则页的首部和尾部的校验和应该是一致的。如果写了一半儿断电 了，那么在File Header 中的校验和就代表着已经修改过的页，而在File Trialer 中的校验和代表着原先 的页，二者不同则意味着同步中间出了错。 后4个字节代表页面被最后修改时对应的日志序列位置（LSN） 这个部分也是为了校验页的完整性的  这个File Trailer 与File Header 类似，都是所有类型的页通用的。\n总结  InnoDB为了不同的目的而设计了不同类型的页，我们把用于存放记录的页叫做数据页。 一个数据页可以被大致划分为7个部分，分别是   File Header ，表示页的一些通用信息，占固定的38字节。 Page Header ，表示数据页专有的一些信息，占固定的56个字节。 Infimum + Supremum ，两个虚拟的伪记录，分别表示页中的最小和最大记录，占固定的26 个字节。 User Records ：真实存储我们插入的记录的部分，大小不固定。 Free Space ：页中尚未使用的部分，大小不确定。 Page Directory ：页中的某些记录相对位置，也就是各个槽在页面中的地址偏移量，大小不固定，插 入的记录越多，这个部分占用的空间越多。 File Trailer ：用于检验页是否完整的部分，占用固定的8个字节。  每个记录的头信息中都有一个next_record 属性，从而使页中的所有记录串联成一个单链表。 InnoDB 会为把页中的记录划分为若干个组，每个组的最后一个记录的地址偏移量作为一个槽，存放在 Page Directory 中，所以在一个页中根据主键查找记录是非常快的，分为两步：   通过二分法确定该记录所在的槽。 通过记录的next_record属性遍历该槽所在的组中的各个记录。  每个数据页的File Header 部分都有上一个和下一个页的编号，所以所有的数据页会组成一个双链表。 为保证从内存中同步到磁盘的页的完整性，在页的首部和尾部都会存储页中数据的校验和和页面最后修改时 对应的LSN 值，如果首部和尾部的校验和和LSN 值校验不成功的话，就说明同步过程出现了问题。  深入研究B+树索引 前边我们详细唠叨了InnoDB 数据页的7个组成部分，知道了各个数据页可以组成一个双向链表，而每个数据页 中的记录会按照主键值从小到大的顺序组成一个单向链表，每个数据页都会为存储在它里边儿的记录生成一个 页目录，在通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对 应分组中的记录即可快速找到指定的记录。页和记录的关系示意图如下：\n没有索引的查找 我们先了解一下没有索引的时候是怎么查找记录的。为了方便大家理解，我们下边先只唠叨搜索条件为对某个列精确匹配的情况，所谓精确匹配，就是搜索条件中用等于= 连接起的表达式，比如这样：\nSELECT [列名列表] FROM 表名 WHERE 列名 = xxx;\r 在一个页中的查找 假设目前表中的记录比较少，所有的记录都可以被存放到一个页中，在查找记录的时候可以根据搜索条件的不同 分为两种情况：\n 以主键为搜索条件 这个查找过程我们已经很熟悉了，可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应 分组中的记录即可快速找到指定的记录。 以其他列作为搜索条件 对非主键列的查找的过程可就不这么幸运了，因为在数据页中并没有对非主键列建立所谓的页目录，所以 我们无法通过二分法快速定位相应的槽。这种情况下只能从最小记录开始依次遍历单链表中的每条记录， 然后对比每条记录是不是符合搜索条件。很显然，这种查找的效率是非常低的。  在很多页中查找 大部分情况下我们表中存放的记录都是非常多的，需要好多的数据页来存储这些记录。在很多页中查找记录的话 可以分为两个步骤：\n 定位到记录所在的页。 从所在的页内中查找相应的记录。  在没有索引的情况下，不论是根据主键列或者其他列的值进行查找，由于我们并不能快速的定位到记录所在的 页，所以只能从第一个页沿着双向链表一直往下找，在每一个页中根据我们刚刚唠叨过的查找方式去查找指定的 记录。因为要遍历所有的数据页，所以这种方式显然是超级耗时的。\n索引 新建一个index_demo 表，该表有2个INT 类型的列，1个CHAR(1) 类型的列，而且我们规定了c1 列为主键，这个 表使用Compact 行格式来实际存储记录的。为了我们理解上的方便，我们简化了一下index_demo 表的行格式示 意图：\n把一些记录放到页里边的示意图就是：\n一个简单的索引方案 ​\t我们在根据某个搜索条件查找一些记录时为什么要遍历所有的数据页呢？因为各个页中的记录并没有\r规律，我们并不知道我们的搜索条件匹配哪些页中的记录，所以不得不依次遍历所有的数据页\n​\t所以如果我们想快速的定位到需要查找的记录在哪些数据页中该咋办？还记得我们为根据主键值快速定位一条记录在页中的位置而设立的页目录么？我们也可以想办法为快速定位记录所在的数据页而建立一个别的目录，建这个目录必须完成下边这些事儿：\n  下一个数据页中用户记录的主键值必须大于上一个页中用户记录的主键值。\n我们这里需要做一个假设：假设我们的每个数据页最多能存放3条记录（实际上一个 数据页非常大，可以存放下好多记录）。有了这个假设之后我们向index_demo 表插入3条记录：\nmysql\u0026gt; INSERT INTO index_demo VALUES(1, 4, 'u'), (3, 9, 'd'), (5, 3, 'y');\r 那么这些记录已经按照主键值的大小串联成一个单向链表了，如图所示：\n  此时我们再来插入一条记录:\nINSERT INTO index_demo VALUES(4, 4, 'a');\r 因为页10 最多只能放3条记录，所以我们不得不再分配一个新页：\n新分配的数据页编号可能并不是连续的，也就是说我们使用的这些页在存储空间里可能并不挨着。它们只是通过维护着上一个页和下一个页的编号而建立了链表关系\n页10 中用户记录最大的主键值是5 ，而页28 中有一条记录的主键值是4 ，因为5\u0026gt;4 ，所以这就不符合下一个数据页中用户记录的主键值必须大于上一个页中用户记录的主键值的要求，所以在插入主键值为4 的记录的时候需要伴随着一次记录移动，也就是把主键值为5 的记录移动到页28 中，然后再把主键值为4 的记录插入到页10 中，这个过程的示意图如下:\n这个过程表明了在对页中的记录进行增删改操作的过程中，我们必须通过一些诸如记录移动的操作来始终保 证这个状态一直成立：下一个数据页中用户记录的主键值必须大于上一个页中用户记录的主键值。这个过程 我们也可以称为页分裂。\n  给所有的页建立一个目录项\n由于数据页的编号可能并不是连续的，所以在向index_demo 表中插入许多条记录后，可能是这样的效果：\n  ​\t因为这些16KB 的页在物理存储上可能并不挨着，所以如果想从这么多页中根据主键值快速定位某些记录所 在的页，我们需要给它们做个目录，每个页对应一个目录项，每个目录项包括下边两个部分：\n 页的用户记录中最小的主键值，我们用key 来表示。 页号，我们用page_no 表示。  所以我们为上边几个页做好的目录就像这样子：\n以页28 为例，它对应目录项2 ，这个目录项中包含着该页的页号28 以及该页中用户记录的最小主键值5 。我们只需要把几个目录项在物理存储器上连续存储，比如把他们放到一个数组里，就可以实现根据主键值快速查找某条记录的功能了。比方说我们想找主键值为20 的记录，具体查找过程分两步：\n 先从目录项中根据二分法快速确定出主键值为20 的记录在目录项3 中（因为 12 \u0026lt; 20 \u0026lt; 209 ），它对应的页是页9 。 再根据前边说的在页中查找记录的方式去页9 中定位具体的记录。  至此，针对数据页做的简易目录就搞定了。不过忘了说了，这个目录有一个别名，称为索引\nInnoDB中的索引方案 上边之所以称为一个简易的索引方案，是因为我们为了在根据主键值进行查找时使用二分法快速定位具体的目录 项而假设所有目录项都可以在物理存储器上连续存储，但是这样做有几个问题：\n InnoDB 是使用页来作为管理存储空间的基本单位，也就是最多能保证16KB 的连续存储空间，而随着表中记 录数量的增多，需要非常大的连续的存储空间才能把所有的目录项都放下，这对记录数量非常多的表是不现 实的。 我们时常会对记录进行增删，假设我们把页28 中的记录都删除了， 页28 也就没有存在的必要了，那意味 着目录项2 也就没有存在的必要了，这就需要把目录项2 后的目录项都向前移动一下，这种牵一发而动全身 的设计不是什么好主意～  所以，设计InnoDB 的大叔们需要一种可以灵活管理所有目录项的方式。他们灵光乍现，忽然发现这些目录项 其实长得跟我们的用户记录差不多，只不过目录项中的两个列是主键和页号而已，所以他们复用了之前存储 用户记录的数据页来存储目录项，为了和用户记录做一下区分，我们把这些用来表示目录项的记录称为目录项记 录。那InnoDB 怎么区分一条记录是普通的用户记录还是目录项记录呢？别忘了记录头信息里的 record_type 属性，它的各个取值代表的意思如下：\n 0 ：普通的用户记录 1 ：目录项记录 2 ：最小记录 3 ：最大记录 哈哈，原来这个值为1 的record_type 是这个意思呀，我们把前边使用到的目录项放到数据页中的样子就是这 样：  从图中可以看出来，我们新分配了一个编号为30 的页来专门存储目录项记录。这里再次强调一遍目录项记录 和普通的用户记录的不同点：\n 目录项记录的record_type 值是1，而普通用户记录的record_type 值是0。 目录项记录只有主键值和页的编号两个列，而普通的用户记录的列是用户自己定义的，可能包含很多列， 另外还有InnoDB 自己添加的隐藏列。 还记得我们之前在唠叨记录头信息的时候说过一个叫min_rec_mask 的属性么，只有在存储目录项记录的页 中的主键值最小的目录项记录的min_rec_mask 值为1 ，其他别的记录的min_rec_mask 值都是0 。  除了上述几点外，这两者就没啥差别了，它们用的是一样的数据页，页的组成结构也是一样一样的（就是我们前边介绍过的7个部分），都会为主键值生成Page Directory （页目录），从而在按照主键值进行查找时可以使用二分法来加快查询速度。现在以查找主键为20 的记录为例，根据某个主键值去查找记录的步骤就可以大致拆分成下边两步:\n 先到存储目录项记录的页，也就是页30 中通过二分法快速定位到对应目录项，因为12 \u0026lt; 20 \u0026lt; 209 ，所 以定位到对应的记录所在的页就是页9 。 再到存储用户记录的页9 中根据二分法快速定位到主键值为20 的用户记录  虽然说目录项记录中只存储主键值和对应的页号，比用户记录需要的存储空间小多了，但是不论怎么说一个页 只有16KB 大小，能存放的目录项记录也是有限的，那如果表中的数据太多，以至于一个数据页不足以存放所有 的目录项记录，该咋办呢？\n当然是再多整一个存储目录项记录的页喽～ 为了大家更好的理解新分配一个目录项记录页的过程，我们假设 一个存储目录项记录的页最多只能存放4条目录项记录，所以如果此时我们再向上图中插入一条主键值为320 的用户记录的话，那就需要分配一个新的存储目录项记录的页喽：\n从图中可以看出，我们插入了一条主键值为320 的用户记录之后需要两个新的数据页：\n 为存储该用户记录而新生成了页31 。 因为原先存储目录项记录的页30 的容量已满（我们前边假设只能存储4条目录项记录），所以不得不需 要一个新的页32 来存放页31 对应的目录项。  现在因为存储目录项记录的页不止一个，所以如果我们想根据主键值查找一条用户记录大致需要3个步骤，以查 找主键值为20 的记录为例：\n 确定目录项记录页 我们现在的存储目录项记录的页有两个，即页30 和页32 ，又因为页30 表示的目录项的主键值的范围是 [1, 320) ， 页32 表示的目录项的主键值不小于320 ，所以主键值为20 的记录对应的目录项记录在页30 中。 通过目录项记录页确定用户记录真实所在的页。 在真实存储用户记录的页中定位到具体的记录。  那么问题来了，在这个查询步骤的第1步中我们需要定位存储目录项记录的页，但是这些页在存储空间中也可能 不挨着，如果我们表中的数据非常多则会产生很多存储目录项记录的页，那我们怎么根据主键值快速定位一个 存储目录项记录的页呢？其实也简单，为这些存储目录项记录的页再生成一个更高级的目录，就像是一个多级 目录一样，大目录里嵌套小目录，小目录里才是实际的数据，所以现在各个页的示意图就是这样子\n如图，我们生成了一个存储更高级目录项的页33 ，这个页中的两条记录分别代表页30 和页32 ，如果用户记录 的主键值在[1, 320) 之间，则到页30 中查找更详细的目录项记录，如果主键值不小于320 的话，就到页32 中查找更详细的目录项记录。随着表中记录的增加，这个目录的层级会继续增加，如果简化一下，那么我们可以用下边这个图来描述它:\n这他妈的就是B+树了！！！\n更多b+树问题参考博文:\n什么是B树\n什么是B+树\nB树和B+树的插入、删除图文详解\n不论是存放用户记录的数据页，还是存放目录项记录的数据页，我们都把它们存放到B+ 树这个数据结构中了， 所以我们也称这些数据页为节点。从图中可以看出来，我们的实际用户记录其实都存放在B+树的最底层的节点 上，这些节点也被称为叶子节点或叶节点，其余用来存放目录项的节点称为非叶子节点或者内节点，其 中B+ 树最上边的那个节点也称为根节点。\n从图中可以看出来，一个B+ 树的节点其实可以分成好多层，设计InnoDB 的大叔们为了讨论方便，规定最下边的 那层，也就是存放我们用户记录的那层为第0 层，之后依次往上加。之前的讨论我们做了一个非常极端的假设： 存放用户记录的页最多存放3条记录，存放目录项记录的页最多存放4条记录。其实真实环境中一个页存放的记录 数量是非常大的，假设，假设，假设所有存放用户记录的叶子节点代表的数据页可以存放100条用户记录，所有 存放目录项记录的内节点代表的数据页可以存放1000条目录项记录，那么：\n 如果B+ 树只有1层，也就是只有1个用于存放用户记录的节点，最多能存放100 条记录。 如果B+ 树有2层，最多能存放1000×100=100000 条记录。 如果B+ 树有3层，最多能存放1000×1000×100=100000000 条记录。 如果B+ 树有4层，最多能存放1000×1000×1000×100=100000000000 条记录。  你的表里能存放100000000000 条记录么？所以一般情况下，我们用到的B+ 树都不会超过4层，那我们通过主键 值去查找某条记录最多只需要做4个页面内的查找（查找3个目录项页和一个用户记录页），又因为在每个页面内 有所谓的Page Directory （页目录），所以在页面内也可以通过二分法实现快速定位记录。\n聚簇索引 我们上边介绍的B+ 树本身就是一个目录，或者说本身就是一个索引。它有两个特点：\n 使用记录主键值的大小进行记录和页的排序，这包括三个方面的含义：   页内的记录是按照主键的大小顺序排成一个单向链表。 各个存放用户记录的页也是根据页中用户记录的主键大小顺序排成一个双向链表。 存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的主键大小顺序排成 一个双向链表。  B+ 树的叶子节点存储的是完整的用户记录。 所谓完整的用户记录，就是指这个记录中存储了所有列的值（包括隐藏列）。  我们把具有这两种特性的B+ 树称为聚簇索引，所有完整的用户记录都存放在这个聚簇索引的叶子节点处。这 种聚簇索引并不需要我们在MySQL 语句中显式的使用INDEX 语句去创建（后边会介绍索引相关的语句）， InnoDB 存储引擎会自动的为我们创建聚簇索引。另外有趣的一点是，在InnoDB 存储引擎中， 聚簇索引就是数 据的存储方式（所有的用户记录都存储在了叶子节点），也就是所谓的索引即数据，数据即索引。\n二级索引 ​\t大家有木有发现，上边介绍的聚簇索引只能在搜索条件是主键值时才能发挥作用，因为B+ 树中的数据都是按照 主键进行排序的。那如果我们想以别的列作为搜索条件该咋办呢？难道只能从头到尾沿着链表依次遍历记录么？ 不，我们可以多建几棵B+ 树，不同的B+ 树中的数据采用不同的排序规则。比方说我们用c2 列的大小作为数据 页、页中记录的排序规则，再建一棵B+ 树，效果如下图所示：\n这个B+ 树与上边介绍的聚簇索引有几处不同：\n 使用记录c2 列的大小进行记录和页的排序，这包括三个方面的含义：  页内的记录是按照c2 列的大小顺序排成一个单向链表。 各个存放用户记录的页也是根据页中记录的c2 列大小顺序排成一个双向链表。 存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的c2 列大小顺序排 成一个双向链表。   B+ 树的叶子节点存储的并不是完整的用户记录，而只是c2列+主键这两个列的值。 目录项记录中不再是主键+页号的搭配，而变成了c2列+页号的搭配。  所以如果我们现在想通过c2 列的值查找某些记录的话就可以使用我们刚刚建好的这个B+ 树了。以查找c2 列的 值为4 的记录为例，查找过程如下：\n 确定目录项记录页 根据根页面，也就是页44 ，可以快速定位到目录项记录所在的页为页42 （因为2 \u0026lt; 4 \u0026lt; 9 ）。 通过目录项记录页确定用户记录真实所在的页。 在页42 中可以快速定位到实际存储用户记录的页，但是由于c2 列并没有唯一性约束，所以c2 列值为4 的 记录可能分布在多个数据页中，又因为2 \u0026lt; 4 ≤ 4 ，所以确定实际存储用户记录的页在页34 和页35 中。 在真实存储用户记录的页中定位到具体的记录。 到页34 和页35 中定位到具体的记录。 但是这个B+ 树的叶子节点中的记录只存储了c2 和c1 （也就是主键）两个列，所以我们必须再根据主键 值去聚簇索引中再查找一遍完整的用户记录。  我们根据这个以c2 列大小排序的B+ 树只能确定我们要查找记录的主键值，所以如果我们想根据c2 列的值查找到完整的用户记录的话，仍然需要到聚簇索引中再查一遍，这个过程也被称为回表。也就是根据c2 列的值查询一条完整的用户记录需要使用到2 棵B+ 树！！！\n因为这种按照非主键列建立的B+ 树需要一次回表操作才可以定位到完整的用户记录，所以这种B+ 树也被称为二级索引（英文名secondary index ），或者辅助索引。由于我们使用的是c2 列的大小作为B+ 树的排序规则，所以我们也称这个B+ 树为为c2列建立的索引。\n联合索引 我们也可以同时以多个列的大小作为排序规则，也就是同时为多个列建立索引，比方说我们想让B+ 树按照c2 和c3 列的大小进行排序，这个包含两层含义：\n 先把各个记录和页按照c2 列进行排序。 在记录的c2 列相同的情况下，采用c3 列进行排序  如图所示，我们需要注意一下几点：\n 每条目录项记录都由c2 、c3 、页号这三个部分组成，各条记录先按照c2 列的值进行排序，如果记录 的c2 列相同，则按照c3 列的值进行排序。 B+ 树叶子节点处的用户记录由c2 、c3 和主键c1 列组成。  千万要注意一点，以c2和c3列的大小为排序规则建立的B+树称为联合索引，本质上也是一个二级索引。它的意思 与分别为c2和c3列分别建立索引的表述是不同的，不同点如下：\n 建立联合索引只会建立如上图一样的1棵B+ 树。 为c2和c3列分别建立索引会分别以c2 和c3 列的大小为排序规则建立2棵B+ 树。  B+树索引的注意事项 根页面万年不动窝 我们前边介绍B+ 树索引的时候，为了大家理解上的方便，先把存储用户记录的叶子节点都画出来，然后接着画 存储目录项记录的内节点，实际上B+ 树的形成过程是这样的：\n 每当为某个表创建一个B+ 树索引（聚簇索引不是人为创建的，默认就有）的时候，都会为这个索引创建一 个根节点页面。最开始表中没有数据的时候，每个B+ 树索引对应的根节点中既没有用户记录，也没有目 录项记录。 随后向表中插入用户记录时，先把用户记录存储到这个根节点中。 当根节点中的可用空间用完时继续插入记录，此时会将根节点中的所有记录复制到一个新分配的页，比 如页a 中，然后对这个新页进行页分裂的操作，得到另一个新页，比如页b 。这时新插入的记录根据键值 （也就是聚簇索引中的主键值，二级索引中对应的索引列的值）的大小就会被分配到页a 或者页b 中，而 根节点便升级为存储目录项记录的页。  这个过程需要大家特别注意的是：一个B+树索引的根节点自诞生之日起，便不会再移动。这样只要我们对某个表 建立一个索引，那么它的根节点的页号便会被记录到某个地方，然后凡是InnoDB 存储引擎需要用到这个索引的 时候，都会从那个固定的地方取出根节点的页号，从而来访问这个索引。\n内节点中目录项记录的唯一性 我们知道B+ 树索引的内节点中目录项记录的内容是索引列 + 页号的搭配，但是这个搭配对于二级索引来说有 点儿不严谨。还拿index_demo 表为例，假设这个表中的数据是这样的\n   c1 c2 c3     1 1 \u0026lsquo;u\u0026rsquo;   3 1 \u0026rsquo;d'   5 1 \u0026lsquo;y\u0026rsquo;   7 1 \u0026lsquo;a\u0026rsquo;    如果二级索引中目录项记录的内容只是索引列 + 页号的搭配的话，那么为c2 列建立索引后的B+ 树应该长这 样：\n如果我们想新插入一行记录，其中c1 、c2 、c3 的值分别是： 9 、1 、\u0026lsquo;c\u0026rsquo; ，那么在修改这个为c2 列建立 的二级索引对应的B+ 树时便碰到了个大问题：由于页3 中存储的目录项记录是由c2列 + 页号的值构成的， 页3 中的两条目录项记录对应的c2 列的值都是1 ，而我们新插入的这条记录的c2 列的值也是1 ，那我们这条 新插入的记录到底应该放到页4 中，还是应该放到页5 中啊？\n为了让新插入记录能找到自己在哪个页里，我们需要保证在B+树的同一层内节点的目录项记录除页号这个字段 以外是唯一的。所以对于二级索引的内节点的目录项记录的内容实际上是由三个部分构成的：\n 索引列的值 主键值 页号  也就是我们把主键值也添加到二级索引内节点中的目录项记录了，这样就能保证B+ 树每一层节点中各条目录项 记录除页号这个字段外是唯一的，所以我们为c2 列建立二级索引后的示意图实际上应该是这样子的\n一个页面最少存储2条记录 ​\t我们前边说过一个B+树只需要很少的层级就可以轻松存储数亿条记录，查询速度杠杠的！这是因为B+树本质上 就是一个大的多层级目录，每经过一个目录时都会过滤掉许多无效的子目录，直到最后访问到存储真实数据的目 录。那如果一个大的目录中只存放一个子目录是个啥效果呢？那就是目录层级非常非常非常多，而且最后的那个 存放真实数据的目录中只能存放一条记录。所以InnoDB 的一个数据页至少可以存放两条记录，这也是我们之前唠叨记录行格式的时候说过一个结论（我们当时依据这个结论推导了表中只有一个列时该列在不发生行溢出的情况下最多能存储多少字节，忘了的话回去看看吧）。\nMyISAM中的索引方案简单介绍 ​\t至此，我们介绍的都是InnoDB 存储引擎中的索引方案，我们有必要再简单介绍一下MyISAM 存储引擎中的索引方案。我们知道InnoDB 中索引即数据，也就是聚簇索引的那棵B+ 树的叶子节点中已经把所有完整的用户记录都包含了，而MyISAM 的索引方案虽然也使用树形结构，但是却将索引和数据分开存储：\n 将表中的记录按照记录的插入顺序单独存储在一个文件中，称之为数据文件。这个文件并不划分为若干个 数据页，有多少记录就往这个文件中塞多少记录就成了。我们可以通过行号而快速访问到一条记录。 MyISAM 记录也需要记录头信息来存储一些额外数据，我们以上边唠叨过的index_demo 表为例，看一下这个 表中的记录使用MyISAM 作为存储引擎在存储空间中的表示：  ​\t由于在插入数据的时候并没有刻意按照主键大小排序，所以我们并不能在这些数据上使用二分法进行查找。\n  使用MyISAM 存储引擎的表会把索引信息另外存储到一个称为索引文件的另一个文件中。MyISAM 会单独为 表的主键创建一个索引，只不过在索引的叶子节点中存储的不是完整的用户记录，而是主键值 + 行号的组 合。也就是先通过索引找到对应的行号，再通过行号去找对应的记录！ 这一点和InnoDB 是完全不相同的，在InnoDB 存储引擎中，我们只需要根据主键值对聚簇索引进行一次查 找就能找到对应的记录，而在MyISAM 中却需要进行一次回表操作，意味着MyISAM 中建立的索引相当于全 部都是二级索引\n  如果有需要的话，我们也可以对其它的列分别建立索引或者建立联合索引，原理和InnoDB 中的索引差不 多，不过在叶子节点处存储的是相应的列 + 行号。这些索引也全部都是二级索引\n  MySQL中创建和删除索引的语句 建表时\nCREATE TALBE 表名 (\r各种列的信息 ··· ,\r[KEY|INDEX] 索引名 (需要被索引的单个列或多个列)\r)\r 其中的KEY 和INDEX 是同义词，任意选用一个就可以\n添加索引\nALTER TABLE 表名 ADD [INDEX|KEY] 索引名 (需要被索引的单个列或多个列);\r 删除索引\nALTER TABLE 表名 DROP [INDEX|KEY] 索引名\r 索引名建议：以idx_ 为前缀，后边跟着需要建立索引的列名，多个列名之间用下划线_ 分隔开。\nB+树索引的使用  B+ 树索引总结:\n 每个索引都对应一棵B+ 树， B+ 树分为好多层，最下边一层是叶子节点，其余的是内节点。所有用户记录 都存储在B+ 树的叶子节点，所有目录项记录都存储在内节点。 InnoDB 存储引擎会自动为主键（如果没有它会自动帮我们添加）建立聚簇索引，聚簇索引的叶子节点包含 完整的用户记录。 我们可以为自己感兴趣的列建立二级索引， 二级索引的叶子节点包含的用户记录由索引列 + 主键组 成，所以如果想通过二级索引来查找完整的用户记录的话，需要通过回表操作，也就是在通过二级索引 找到主键值之后再到聚簇索引中查找完整的用户记录。 B+ 树中每层节点都是按照索引列值从小到大的顺序排序而组成了双向链表，而且每个页内的记录（不论是 用户记录还是目录项记录）都是按照索引列的值从小到大的顺序而形成了一个单链表。如果是联合索引的 话，则页面和记录先按照联合索引前边的列排序，如果该列值相同，再按照联合索引后边的列排序。 通过索引查找记录是从B+ 树的根节点开始，一层一层向下搜索。由于每个页面都按照索引列的值建立了 Page Directory （页目录），所以在这些页面中的查找非常快。  索引的代价   空间上的代价 这个是显而易见的，每建立一个索引都要为它建立一棵B+ 树，每一棵B+ 树的每一个节点都是一个数据页， 一个页默认会占用16KB 的存储空间，一棵很大的B+ 树由许多数据页组成，那可是很大的一片存储空间呢。 时间上的代价 每次对表中的数据进行增、删、改操作时，都需要去修改各个B+ 树索引。而且我们讲过， B+ 树每层节点都 是按照索引列的值从小到大的顺序排序而组成了双向链表。不论是叶子节点中的记录，还是内节点中的记录 （也就是不论是用户记录还是目录项记录）都是按照索引列的值从小到大的顺序而形成了一个单向链表。而 增、删、改操作可能会对节点和记录的排序造成破坏，所以存储引擎需要额外的时间进行一些记录移位，页 面分裂、页面回收啥的操作来维护好节点和记录的排序。如果我们建了许多索引，每个索引对应的B+ 树都 要进行相关的维护操作，这还能不给性能拖后腿么？  所以说，一个表上索引建的越多，就会占用越多的存储空间，在增删改记录的时候性能就越差。\nB+树索引适用的条件  下边我们将唠叨许多种让B+ 树索引发挥最大效能的技巧和注意事项，先创建一个person_info表，这个表是用来存储人的一些基本信息的：\nCREATE TABLE person_info(\rid INT NOT NULL auto_increment,\rname VARCHAR(100) NOT NULL,\rbirthday DATE NOT NULL,\rphone_number CHAR(11) NOT NULL,\rcountry varchar(100) NOT NULL,\rPRIMARY KEY (id),\rKEY idx_name_birthday_phone_number (name, birthday, phone_number)\r);\r 对于这个person_info 表我们需要注意两点：\n 表中的主键是id 列，它存储一个自动递增的整数。所以InnoDB 存储引擎会自动为id 列建立聚簇索引。 我们额外定义了一个二级索引idx_name_birthday_phone_number ，它是由3个列组成的联合索引。所以在这个索引对应的B+ 树的叶子节点处存储的用户记录只保留name 、birthday 、phone_number 这三个列的值 以及主键id 的值，并不会保存country 列的值。  person_info 表会为聚簇索引和idx_name_birthday_phone_number 索引建立2棵B+ 树。下边我们画一下索引 idx_name_birthday_phone_number 的示意图，不过既然我们已经掌握了InnoDB 的B+ 树索引原理，那我们在画 图的时候为了让图更加清晰，所以在省略一些不必要的部分，比如记录的额外信息，各页面的页号等等，其中内 节点中目录项记录的页号信息我们用箭头来代替，在记录结构中只保留name 、birthday 、phone_number 、 id 这四个列的真实数据值\n从图中可以看出这个idx_name_birthday_phone_number 索引对应的B+ 树中页面和记录的排序方式就是这的：\n 先按照name 列的值进行排序。 如果name 列的值相同，则按照birthday 列的值进行排序。 如果birthday 列的值也相同，则按照phone_number 的值进行排序  全值匹配  如果我们的搜索条件中的列和索引列一致的话，这种情况就称为全值匹配,例如：\nSELECT * FROM person_info WHERE name = 'Ashburn' AND birthday = '1990-09-27' AND phone_number = '15123983239';\r 这个毫无疑问会走索引，但WHERE 子句中的几个搜索条件的顺序对查询结果有啥影响么？也就是说如果我们调换 name 、birthday 、phone_number 这几个搜索列的顺序对查询的执行过程有影响么？例如：\nSELECT * FROM person_info WHERE birthday = '1990-09-27' AND phone_number = '15123983239' AND name = 'Ashburn';\r 答案是：没影响哈。MySQL 有查询优化器，会分析这些搜索条件并且按照可以使用的索引中列的顺序来决定先使用哪个搜索条件，后使用哪个搜索条件。\n匹配左边的列  其实在我们的搜索语句中也可以不用包含全部联合索引中的列，只包含左边的就行，比方说下边的查询语句：\nSELECT * FROM person_info WHERE name = 'Ashburn';\r或者包含多个左边的列也行：\rSELECT * FROM person_info WHERE name = 'Ashburn' AND birthday = '1990-09-27';\r 那这条查询语句能用到索引吗？\nSELECT * FROM person_info WHERE birthday = '1990-09-27';\r 答案是用不到，因为B+ 树的数据页和记录先是按照name 列的值排序的，在name 列的值相同的情况下才使用birthday 列进行排序，也就是说name 列的值不同的记录中birthday 的值可能是无序的\n需要特别注意的一点是，如果我们想使用联合索引中尽可能多的列，搜索条件中的各个列必须是联合索引中从最左边开始连续的列。比方说联合索引idx_name_birthday_phone_number 中列的定义顺序是name 、birthday 、phone_number ，如果我们的搜索条件中只有name 和phone_number ，而没有中间的birthday ，比方说这样：\nSELECT * FROM person_info WHERE name = 'Ashburn' AND phone_number = '15123983239';\r 这样只能用到name 列的索引， birthday 和phone_number 的索引就用不上了，因为name 值相同的记录先按照 birthday 的值进行排序， birthday 值相同的记录才按照phone_number 值进行排序\n匹配列前缀  为某个列建立索引的意思其实就是在对应的B+ 树的记录中使用该列的值进行排序，比方说person_info 表上建立的联合索引idx_name_birthday_phone_number 会先用name 列的值进行排序，字符串排序使用的当然就是字典序，也就是说这些字符串的前n个字符，也就是前缀都是排好序的，所以对于字符串类型的索引列来说，我们只匹配它的前缀也是可以快速定位记录的，例如：\n走索引 SELECT * FROM person_info WHERE name LIKE 'As%';\r不走索引 SELECT * FROM person_info WHERE name LIKE '%As%';\r 匹配范围值  idx_name_birthday_phone_number 索引的B+ 树示意图，所有记录都是按照索引列的值从小到大的顺序排好序的，所以这极大的方便我们查找索引列的值在某个范围内的记录。比方说下边这个查询语句\nSELECT * FROM person_info WHERE name \u0026gt; 'Asa' AND name \u0026lt; 'Barlow';\r 由于B+ 树中的数据页和记录是先按name 列排序的，所以我们上边的查询过程其实是这样的：\n 找到name 值为Asa 的记录(查找到范围的下限)。 遍历链表找到name 值为Barlow 的记录（查找到范围的上限）由于所有记录都是由链表连起来的（记录之间用单链表，数据页之间用双链表） 找到这些记录的主键值，再到聚簇索引中回表查找完整的记录。  注意\n如果对多个列同时进行范围查找的话，只有对索引最左边的那个列进行范围查找的时候才能用到B+ 树索引，\nSELECT * FROM person_info WHERE name \u0026gt; 'Asa' AND name \u0026lt; 'Barlow' AND birthday \u0026gt; '1980-01-01';\r 上边这个查询可以分成两个部分：\n 通过条件name \u0026gt; \u0026lsquo;Asa\u0026rsquo; AND name \u0026lt; \u0026lsquo;Barlow\u0026rsquo; 来对name 进行范围，查找的结果可能有多条name 值不同的 记录 对这些name 值不同的记录继续通过birthday \u0026gt; \u0026lsquo;1980-01-01\u0026rsquo; 条件继续过滤。 这样子对于联合索引idx_name_birthday_phone_number 来说，只能用到name 列的部分，而用不到birthday 列的部分，因为只有name 值相同的情况下才能用birthday 列的值进行排序，而这个查询中通过name 进行范围查找的记录中可能并不是按照birthday 列进行排序的，所以在搜索条件中继续以birthday 列进行查找时是用不到这个B+ 树索引的。  而与上面相反的是，精确匹配某一列并范围匹配另外一列,如\nSELECT * FROM person_info WHERE name = 'Ashburn' AND birthday \u0026gt; '1980-01-01' AND birthday\r\u0026lt; '2000-12-31' AND phone_number \u0026gt; '15100000000';\r 这个查询的条件可以分为3个部分：\n name = \u0026lsquo;Ashburn\u0026rsquo; ，对name 列进行精确查找，当然可以使用B+ 树索引了。 birthday \u0026gt; \u0026lsquo;1980-01-01\u0026rsquo; AND birthday \u0026lt; \u0026lsquo;2000-12-31\u0026rsquo; ，由于name 列是精确查找，所以通过name = \u0026lsquo;Ashburn\u0026rsquo; 条件查找后得到的结果的name 值都是相同的，它们会再按照birthday 的值进行排序。所以此时 对birthday 列进行范围查找是可以用到B+ 树索引的。 phone_number \u0026gt; \u0026lsquo;15100000000\u0026rsquo; ，通过birthday 的范围查找的记录的birthday 的值可能不同，所以这个 条件无法再利用B+ 树索引了，只能遍历上一步查询得到的记录。  用于排序  我们在写查询语句的时候经常需要对查询出来的记录通过ORDER BY 子句按照某种规则进行排序。一般情况下， 我们只能把记录都加载到内存中，再用一些排序算法，比如快速排序、归并排序等等在内存中对这些记录进行排序，有的时候可能查询的结果集太大以至于不能在内存中进行排序的话，还可能暂时借助磁盘的空间来存放中间结果，排序操作完成后再把排好序的结果集返回到客户端。在MySQL 中，把这种在内存中或者磁盘上进行排序的方式统称为文件排序（英文名： filesort ），文件排序是很慢的。但是如果ORDER BY 子句里使用到了我们的 索引列，就有可能省去在内存或文件中排序的步骤，比如下边这个简单的查询语句\nSELECT * FROM person_info ORDER BY name, birthday, phone_number LIMIT 10;\r 因为有idx_name_birthday_phone_number 索引，所以直接从索引中提取数据，然后进行回表操作取出所有数据\n对于联合索引有个问题需要注意， ORDER BY 的子句后边的列的顺序也必须按照索引列的顺序给出，否则也不能使用索引，同理， ORDER BY name 、ORDER BY name, birthday 这种匹配索引左边的列的形式可以使用部分的B+ 树索引。当联合索引左边列的值为常量，也可以使用后边的列进行排序，比如这样\nSELECT * FROM person_info WHERE name = 'A' ORDER BY birthday, phone_number LIMIT 10;\r 不可以使用索引进行排序的几种情况  ASC、DESC混用 对于使用联合索引进行排序的场景，我们要求各个排序列的排序顺序是一致的，也就是要么各个列都是ASC 规则 排序，要么都是DESC 规则排序。\n如果查询中的各个排序列的排序顺序是一致的，比方说下边这两种情况：\n ORDER BY name, birthday LIMIT 10 这种情况直接从索引的最左边开始往右读10行记录就可以了。 ORDER BY name DESC, birthday DESC LIMIT 10 ， 这种情况直接从索引的最右边开始往左读10行记录就可以了。  但是是先按照name 列进行升序排列，再按照birthday 列进行降序排列的话，比如说这样的查询语句：\nSELECT * FROM person_info ORDER BY name, birthday DESC LIMIT 10;\r 就不能走索引\nWHERE子句中出现非排序使用到的索引列 SELECT * FROM person_info WHERE country = 'China' ORDER BY name LIMIT 10;\r 这个查询只能先把符合搜索条件country = \u0026lsquo;China\u0026rsquo; 的记录提取出来后再进行排序，使用不到索引。\nSELECT * FROM person_info WHERE name = 'A' ORDER BY birthday, phone_number LIMIT 10;\r 虽然这个查询也有搜索条件，但是name = \u0026lsquo;A\u0026rsquo; 可以使用到索引idx_name_birthday_phone_number ，而且过滤剩 下的记录还是按照birthday 、phone_number 列排序的，所以还是可以使用索引进行排序的\n排序列包含非同一个索引的列 有时候用来排序的多个列不是一个索引里的，这种情况也不能使用索引进行排序，比方说：\nSELECT * FROM person_info ORDER BY name, country LIMIT 10;\r name 和country (即使country为索引列也不行)并不属于一个联合索引中的列，所以无法使用索引进行排序\n排序列使用了复杂的表达式 SELECT * FROM person_info ORDER BY UPPER(name) LIMIT 10;\r 使用了UPPER 函数修饰过的列就不是单独的列了，这样就无法使用索引进行排序。\n用于分组 SELECT name, birthday, phone_number, COUNT(*) FROM person_info GROUP BY name, birthday, phone_number\r 和使用B+ 树索引进行排序使用规则相同，分组列的顺序也需要和索引列的顺序一致，也可以只使用索引列中左边 的列进行分组等\n回表的代价  SELECT * FROM person_info WHERE name \u0026gt; 'Asa' AND name \u0026lt; 'Barlow';\r 在使用idx_name_birthday_phone_number 索引进行查询时大致可以分为这两个步骤：\n 从索引idx_name_birthday_phone_number 对应的B+ 树中取出name 值在Asa ～ Barlow 之间的用户记录。 由于索引idx_name_birthday_phone_number 对应的B+ 树用户记录中只包含name 、birthday 、 phone_number 、id 这4个字段，而查询列表是* ，意味着要查询表中所有字段，也就是还要包括country 字段。这时需要把从上一步中获取到的每一条记录的id 字段都到聚簇索引对应的B+ 树中找到完整的用户记 录，也就是我们通常所说的回表，然后把完整的用户记录返回给查询用户。  由于索引idx_name_birthday_phone_number 对应的B+ 树中的记录首先会按照name 列的值进行排序，所以值 在Asa ～ Barlow 之间的记录在磁盘中的存储是相连的，集中分布在一个或几个数据页中，我们可以很快的把这 些连着的记录从磁盘中读出来，这种读取方式我们也可以称为顺序I/O。根据第1步中获取到的记录的id 字段 的值可能并不相连，而在聚簇索引中记录是根据id （也就是主键）的顺序排列的，所以根据这些并不连续的id 值到聚簇索引中访问完整的用户记录可能分布在不同的数据页中，这样读取完整的用户记录可能要访问更多的数 据页，这种读取方式我们也可以称为随机I/O 。一般情况下，顺序I/O比随机I/O的性能高很多。所以这个使用索引idx_name_birthday_phone_number 的查询有这么两个特点：\n 会使用到两个B+ 树索引，一个二级索引，一个聚簇索引。 访问二级索引使用顺序I/O ，访问聚簇索引使用随机I/O 。  需要回表的记录越多，使用二级索引的性能就越低，甚至让某些查询宁愿使用全表扫描也不使用二级索引。比 方说name 值在Asa ～ Barlow 之间的用户记录数量占全部记录数量90%以上，那么如果使用 idx_name_birthday_phone_number 索引的话，有90%多的id 值需要回表，还不如直接去扫描聚簇索引（也就是全表扫描）。\n那什么时候采用全表扫描的方式，什么时候使用采用二级索引 + 回表的方式去执行查询呢？\n查询优化器会事先对表中的记录计算一些统计数据，然后再利用这些统计数据根据查询的条件来计算一下需要回表的记录数，需要回表的记录数越多，就越倾向于使用全表扫描，反之倾向于使用二级索引 + 回表的方式。\n一般情况下，限制查询获取较少的记录数会让优化器更倾向于选择使用二级索引 + 回表的方式进行查询，因为回表的记录越少，性能提升就越高，比方说上边的查询可以改写成这样：\nSELECT * FROM person_info WHERE name \u0026gt; 'Asa' AND name \u0026lt; 'Barlow' LIMIT 10;\r同样排序也可以：SELECT * FROM person_info ORDER BY name, birthday, phone_number LIMIT 10;\r 覆盖索引 为了彻底告别回表操作带来的性能损耗，最好在查询列表里只包含索引列，比如：\nSELECT name, birthday, phone_number FROM person_info WHERE name \u0026gt; 'Asa' AND name \u0026lt; 'Barlo\rw'\r 因为只查询name , birthday , phone_number 这三个索引列的值，所以通idx_name_birthday_phone_number 索引得到结果后就不必到聚簇索引中再查找记录的剩余列，这样就省去了回表操作带来的性能损耗。我们把这种只需要用到索引的查询方式称为索引覆盖,所以坚决不能用* 号作为查询列表，最好把我们需要查询的列依次标明。\n如何挑选索引  只为用于搜索、排序或分组的列创建索引 只为出现在WHERE 子句中的列、连接子句中的连接列，或者出现在ORDER BY 或GROUP BY 子句中的 列创建索引。而出现在查询列表中的列就没必要建立索引了\n考虑列的基数 列的基数指的是某一列中不重复数据的个数，比方说某个列包含值2, 5, 8, 2, 5, 8, 2, 5, 8 ，虽然有9 条记录，但该列的基数却是3 。也就是说，在记录行数一定的情况下，列的基数越大，该列中的值越分散，列的基数越小，该列中的值越集中。假设某个列的基数为1 ，也就是所有记录在该列中的值都一样，那为该列建立索引是没有用的，因为所有值都一样就无法排序，无法进行快速查找了，而且如果某个建立了二级索引的列的重复值特别多，那么使用这个二级索引查出的记录还可能要做回表操作，这样性能损耗就更大了。\n所以结论就是：最好为那些列的基数大的列建立索引，为基数太小列的建立索引效果可能不好（索引尽量建在数据重复不多的列上，比如XX_id,但XX_time上则不合适）\n索引列的类型尽量小 我们在定义表结构的时候要显式的指定列的类型，以整数类型为例，有TINYINT 、MEDIUMINT 、INT 、BIGINT 这么几种，它们占用的存储空间依次递增，我们这里所说的类型大小指的就是该类型表示的数据范围的大小。 能表示的整数范围当然也是依次递增，如果我们想要对某个整数列建立索引的话，在表示的整数范围允许的情况 下，尽量让索引列使用较小的类型，比如我们能使用INT 就不要使用BIGINT ，能使用MEDIUMINT 就不要使用 INT ～ 这是因为：\n 数据类型越小，在查询时进行的比较操作越快（这是CPU层次的东东） 数据类型越小，索引占用的存储空间就越少，在一个数据页内就可以放下更多的记录，从而减少磁盘I/O 带 来的性能损耗，也就意味着可以把更多的数据页缓存在内存中，从而加快读写效率。  这个建议对于表的主键来说更加适用，因为不仅是聚簇索引中会存储主键值，其他所有的二级索引的节点处都会 存储一份记录的主键值，如果主键适用更小的数据类型，也就意味着节省更多的存储空间和更高效的I/O\n索引字符串值的前缀 只对字符串的前几个字符进行索引也就是说在二级索引的记录中只保留字符串前几个字符。这样在查找记录时虽然不能精确的定位到记录的位置，但是能定位到相应前缀所在的位置，然后根据前缀相同的记录的主键值回表查询完整的字符串值，再对比就好了。这样只在B+ 树中存储字符串的前几个字符的编码，既节约空间，又减少了字符串的比较时间，比方说我们在建表语句中只对name 列的前10个字符进行索引可以这么写：\nCREATE TABLE person_info(\rname VARCHAR(100) NOT NULL,\rbirthday DATE NOT NULL,\rphone_number CHAR(11) NOT NULL,\rcountry varchar(100) NOT NULL,\rKEY idx_name_birthday_phone_number (name(10), birthday, phone_number)\r);\r name(10) 就表示在建立的B+ 树索引中只保留记录的前10 个字符的编码，这种只索引字符串值的前缀的策略是 我们非常鼓励的，尤其是在字符串类型能存储的字符比较多的时候。\nSELECT * FROM person_info ORDER BY name LIMIT 10;\r 因为二级索引中不包含完整的name 列信息，所以无法对前十个字符相同，后边的字符不同的记录进行排序，也 就是使用索引列前缀的方式无法支持使用索引排序，只好乖乖的用文件排序喽。\n让索引列在比较表达式中单独出现 假设表中有一个整数列my_col ，我们为这个列建立了索引。下边的两个WHERE 子句虽然语义是一致的，但是在 效率上却有差别：\n WHERE my_col * 2 \u0026lt; 4 WHERE my_col \u0026lt; 4/2  第1个WHERE 子句中my_col 列并不是以单独列的形式出现的，而是以my_col * 2 这样的表达式的形式出现的， 存储引擎会依次遍历所有的记录，计算这个表达式的值是不是小于4 ，所以这种情况下是使用不到为my_col 列 建立的B+ 树索引的。而第2个WHERE 子句中my_col 列并是以单独列的形式出现的，这样的情况可以直接使用 B+ 树索引。 所以结论就是：如果索引列在比较表达式中不是以单独列的形式出现，而是以某个表达式，或者函数调用形式出 现的话，是用不到索引的。\n主键插入顺序 我们知道，对于一个使用InnoDB 存储引擎的表来说，在我们没有显式的创建索引时，表中的数据实际上都是存 储在聚簇索引的叶子节点的。而记录又是存储在数据页中的，数据页和记录又是按照记录主键值从小到大的顺 序进行排序，所以如果我们插入的记录的主键值是依次增大的话，那我们每插满一个数据页就换到下一个数据页 继续插，而如果我们插入的主键值忽大忽小的话，这就比较麻烦了，假设某个数据页存储的记录已经满了，它存 储的主键值在1~100 之间：\n如果此时再插入一条主键值为9 的记录，那它插入的位置就如下图：\n可这个数据页已经满了啊，再插进来咋办呢？我们需要把当前页面分裂成两个页面，把本页中的一些记录移动到 新创建的这个页中。页面分裂和记录移位意味着什么？意味着：性能损耗！所以如果我们想尽量避免这样无谓的 性能损耗最好让插入的记录的主键值依次递增\n冗余和重复索引 有时候有的同学有意或者无意的就对同一个列创建了多个索引，比方说这样写建表语句：\nCREATE TABLE person_info(\rid INT UNSIGNED NOT NULL AUTO_INCREMENT,\rname VARCHAR(100) NOT NULL,\rbirthday DATE NOT NULL,\rphone_number CHAR(11) NOT NULL,\rcountry varchar(100) NOT NULL,\rPRIMARY KEY (id),\rKEY idx_name_birthday_phone_number (name(10), birthday, phone_number),\rKEY idx_name (name(10))\r);\r 通过idx_name_birthday_phone_number 索引就可以对name 列进行快速搜索，再创建一个专门针对name 列的索引就算是一个冗余索引，维护这个索引只会增加维护的成本，并不会对搜索有什么好处。这个自己也犯过\n总结   B+ 树索引在空间和时间上都有代价，所以没事儿别瞎建索引。\n  B+ 树索引适用于下边这些情况：\n 全值匹配 匹配左边的列 匹配范围值 精确匹配某一列并范围匹配另外一列 用于排序 用于分组    在使用索引时需要注意下边这些事项：\n 只为用于搜索、排序或分组的列创建索引 为列的基数大的列创建索引 索引列的类型尽量小 可以只对字符串值的前缀建立索引 只有索引列在比较表达式中单独出现才可以适用索引 为了尽可能少的让聚簇索引发生页面分裂和记录移位的情况，主键一定要依次递增。 定位并删除表中的重复和冗余索引 尽量使用覆盖索引进行查询，避免回表带来的性能损耗。    InnoDB的表空间 表空间是一个抽象的概念，对于系统表空间来说，对应着文件系统中一个或多个实际文件；对于每个独立表空间来说，对应着文件系统中一个名为表名.ibd 的实际文件。大家可以把表空间想象成被切分为许许多多个页的池子，当我们想为某个表插入一条记录的时候，就从池子中捞出一个对应的页来把数据写进去。\n独立表空间结构  InnoDB 支持许多种类型的表空间，重点关注独立表空间和系统表空间的结构。它们的结构比较相似。\n区（extent）的概念  表空间中的页实在是太多了，为了更好的管理这些页面，提出了区（英文名： extent ）的概念。对于16KB的页来说，连续的64个页就是一个区，也就是说一个区默认占用1MB空间大小。不论是系统表空间还是独立表空间，都可以看成是由若干个区组成的，每256个区被划分成一组\n这些组的头几个页面的类型都是类似的，就像这样\n从上图中我们能得到如下信息：\n 第一个组最开始的3个页面的类型是固定的，也就是说extent 0 这个区最开始的3个页面的类型是固定的， 分别是：  FSP_HDR 类型：这个类型的页面是用来登记整个表空间的一些整体属性以及本组所有的区，也就是extent 0 ~ extent 255 这256个区的属性，稍后详细唠叨。需要注意的一点是，整个表空间只有一个FSP_HDR 类型的页面。 IBUF_BITMAP 类型：这个类型的页面是存储本组所有的区的所有页面关于INSERT BUFFER 的信息。 INODE 类型：这个类型的页面存储了许多称为INODE 的数据结构。   其余各组最开始的2个页面的类型是固定的，也就是说extent 256 、extent 512 这些区最开始的2个页面 的类型是固定的，分别是：  XDES 类型：全称是extent descriptor ，用来登记本组256个区的属性，也就是说对于在extent 256 区中的该类型页面存储的就是extent 256 ~ extent 511 这些区的属性，对于在extent 512 区中的该 类型页面存储的就是extent 512 ~ extent 767 这些区的属性。上边介绍的FSP_HDR 类型的页面其实 和XDES 类型的页面的作用类似，只不过FSP_HDR 类型的页面还会额外存储一些表空间的属性。 IBUF_BITMAP 类型：上边介绍过了。    总之，表空间被划分为许多连续的区，每个区默认由64个页组成，每256个区划分为一组，每个组的最开始的几个页面类型是固定的\n段（segment）的概念  为啥好端端的提出一个区（ extent ）的概念呢？我们以前分析问题的套路都是这样的：表中的记录存储到页里 边儿，然后页作为节点组成B+ 树，这个B+ 树就是索引，但我们来考虑一下下边这个场景：\n 我们每向表中插入一条记录，本质上就是向该表的聚簇索引以及所有二级索引代表的B+ 树的节点中插入数 据。而B+ 树的每一层中的页都会形成一个双向链表，如果是以页为单位来分配存储空间的话，双向链表相 邻的两个页之间的物理位置可能离得非常远。我们介绍B+ 树索引的适用场景的时候特别提到范围查询只需 要定位到最左边的记录和最右边的记录，然后沿着双向链表一直扫描就可以了，而如果链表中相邻的两个页 物理位置离得非常远，就是所谓的随机I/O 。再一次强调，磁盘的速度和内存的速度差了好几个数量级， 随 机I/O 是非常慢的，所以我们应该尽量让链表中相邻的页的物理位置也相邻，这样进行范围查询的时候才可 以使用所谓的顺序I/O  所以才引入了区（ extent ）的概念，一个区就是在物理位置上连续的64个页。。在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区为单位分配，甚至在表中的数据十分非常特别多的时候，可以一次性分配多个连续的区。\n我们提到的范围查询，其实是对B+ 树叶子节点中的记录进行顺序扫描，而如果不区分叶子节点和非叶子节点，统统把节点代表的页面放到申请到的区中的话，进行范围扫描的效果就大打折扣了。所以设计InnoDB 的大叔们对B+ 树的叶子节点和非叶子节点进行了区别对待，也就是说叶子节点有自己独有的区，非叶子节点也有自己独有的区。存放叶子节点的区的集合就算是一个段（ segment ），存放非叶子节点的区的集合也算是一个段。也就是说一个索引会生成2个段，一个叶子节点段，一个非叶子节点段。\n默认情况下一个使用InnoDB 存储引擎的表只有一个聚簇索引，一个索引会生成2个段，而段是以区为单位申请存 储空间的，一个区默认占用1M存储空间，所以默认情况下一个只存了几条记录的小表也需要2M的存储空间么？ 以后每次添加一个索引都要多申请2M的存储空间么？这对于存储记录比较少的表简直是天大的浪费。设计InnoDB 的大叔们提出了一个碎片（fragment）区的概念，也就是在一个碎片区中，并不是所有的页都是为了存储同一个段的数据而存在的，而是碎片区中的页可以用于不同的目的，比如有些页用于段A，有些页用于段B，有些页甚至哪个段都不属于。碎片区直属于表空间，并不属于任何一个段。所以此后为某个段分配存储空间的策略是这样的：\n 在刚开始向表中插入数据的时候，段是从某个碎片区以单个页面为单位来分配存储空间的。 当某个段已经占用了32个碎片区页面之后，就会以完整的区为单位来分配存储空间。  所以现在段不能仅定义为是某些区的集合，更精确的应该是某些零散的页面以及一些完整的区的集合\n区的分类  表空间是由若干个区组成的，这些区大体上可以分为4种类型：\n 空闲的区（Free）：现在还没有用到这个区中的任何页面。 有剩余空间的碎片区(FREE_FRAG)：表示碎片区中还有可用的页面。 没有剩余空间的碎片区(FULL_FRAG)：表示碎片区中的所有页面都被使用，没有空闲页面。 附属于某个段的区(FSEG)。每一个索引都可以分为叶子节点段和非叶子节点段，除此之外InnoDB还会另外定义一些特殊作用的段，在这些段中的数据量很大时将使用区来作为基本的分配单位。  这4种类型的区也可以被称为区的4种状态（ Free、FREE_FRAG、FULL_FRAG、FSEG）,处于FREE 、FREE_FRAG 以及FULL_FRAG 这三种状态的区都是独立的，算是直属于表空间；而处于FSEG 状态的区是附属于某个段的\n 如果把表空间比作是一个集团军，段就相当于师，区就相当于团。一般的团都是隶属于某个师的，就像 是处于FSEG的区全都隶属于某个段，而处于FREE、FREE_FRAG以及FULL_FRAG这三种状态的区却 直接隶属于表空间，就像独立团直接听命于军部一样。\n 为了方便管理这些区，设计InnoDB 的大叔设计了一个称为XDES Entry 的结构（全称就是Extent Descriptor Entry），每一个区都对应着一个XDES Entry 结构，这个结构记录了对应的区的一些属性。\nXDES Entry 是一个40个字节的结构，大致分为4个部分，各个部分的释义如下：\n Segment ID （8字节） 每一个段都有一个唯一的编号，用ID表示，此处的Segment ID 字段表示就是该区所在的段。当然前提是该 区已经被分配给某个段了，不然的话该字段的值没啥意义。 List Node （12字节） 这个部分可以将若干个XDES Entry 结构串联成一个链表，如果我们想定位表空间内的某一个位置的话，只需指定页号以及该位置在指定页号中的页内偏移量即可。  Pre Node Page Number 和Pre Node Offset 的组合就是指向前一个XDES Entry 的指针 Next Node Page Number 和Next Node Offset 的组合就是指向后一个XDES Entry 的指针。    也就是说把一些XDES Entry 结构连成了一个链表\n  State （4字节）\n这个字段表明区的状态。可选的值就是我们前边说过的那4个，分别是： FREE 、FREE_FRAG 、FULL_FRAG 和FSEG\n  Page State Bitmap （16字节） 这个部分共占用16个字节，也就是128个比特位。我们说一个区默认有64个页，这128个比特位被划分为64 个部分，每个部分2个比特位，对应区中的一个页。比如Page State Bitmap 部分的第1和第2个比特位对应 着区中的第1个页面，第3和第4个比特位对应着区中的第2个页面，依此类推， Page State Bitmap 部分的第 127和128个比特位对应着区中的第64个页面。这两个比特位的第一个位表示对应的页是否是空闲的，第二个 比特位还没有用\n  XDES Entry链表 我们已经提出了五花八门的概念，什么区、段、碎片区、附属于段的区、XDES Entry 结构，走远了千万别忘了自己为什么出发，我们把事情搞这么麻烦的初心仅仅是想提高向表插入数据的效率又不至于数据量少的表浪费空间。我们知道向表中插入数据本质上就是向表中各个索引的叶子节点段、非叶子节点段插入数据，也知道了不同的区有不同的状态，再回到最初的起点，捋一捋向某个段中插入数据的过程\n  当段中数据较少的时候，首先会查看表空间中是否有状态为FREE_FRAG 的区，也就是找还有空闲空间的碎片区，如果找到了，那么从该区中取一些零碎的页把数据插进去；否则到表空间下申请一个状态为FREE 的区，也就是空闲的区，把该区的状态变为FREE_FRAG ，然后从该新申请的区中取一些零碎的页把数据插进去。之后不同的段使用零碎页的时候都会从该区中取，直到该区中没有空闲空间，然后该区的状态就变成了FULL_FRAG 。\n现在的问题是你怎么知道表空间里的哪些区是FREE 的，哪些区的状态FREE_FRAG 的，哪些区是FULL_FRAG 的？要知道表空间的大小是可以不断增大的，当增长到GB级别的时候，区的数量也就上千了， 我们总不能每次都遍历这些区对应的XDES Entry 结构吧？这时候就是XDES Entry 中的List Node 部分发挥奇效的时候了，我们可以通过List Node 中的指针，做这么三件事：\n  把状态为FREE 的区对应的XDES Entry 结构通过List Node 来连接成一个链表，这个链表我们就称之为FREE 链表。\n 把状态为FREE_FRAG 的区对应的XDES Entry 结构通过List Node 来连接成一个链表，这个链表我们就称之为FREE_FRAG 链表。 把状态为FULL_FRAG 的区对应的XDES Entry 结构通过List Node 来连接成一个链表，这个链表我们就称之为FULL_FRAG 链表。 这样每当我们想找一个FREE_FRAG 状态的区时，就直接把FREE_FRAG 链表的头节点拿出来，从这个节点中取一些零碎的页来插入数据，当这个节点对应的区用完时，就修改一下这个节点的State 字段的值，然后从FREE_FRAG 链表中移到FULL_FRAG 链表中。同理，如果FREE_FRAG 链表中一个节点都没有，那 么就直接从FREE 链表中取一个节点移动到FREE_FRAG 链表的状态，并修改该节点的STATE 字段值为FREE_FRAG ，然后从这个节点对应的区中获取零碎的页就好了。    当段中数据已经占满了32个零散的页后，就直接申请完整的区来插入数据\n还是那个问题，我们怎么知道哪些区属于哪个段的呢？再遍历各个XDES Entry 结构？遍历是不可能遍历的，这辈子都不可能遍历的，有链表还遍历个毛线啊。所以我们把状态为FSEG 的区对应的XDES Entry 结构都加入到一个链表喽？傻呀，不同的段哪能共用一个区呢？你想把索引a的叶子节点段和索引b的叶子节点段都存储到一个区中么？显然我们想要每个段都有它独立的链表，所以可以根据段号（也就是Segment ID ）来建立链表，有多少个段就建多少个链表？好像也有点问题，因为一个段中可以有好多个区，有的区是完全空闲的，有的区还有一些页面可以用，有的区已经没有空闲页面可以用了，所以我们有必要继续细分，设计InnoDB 的大叔们为每个段中的区对应的XDES Entry 结构建立了三个链表：\n FREE 链表：同一个段中，所有页面都是空闲的区对应的XDES Entry 结构会被加入到这个链表。注意和直属于表空间的FREE 链表区别开了，此处的FREE 链表是附属于某个段的。 NOT_FULL 链表：同一个段中，仍有空闲空间的区对应的XDES Entry 结构会被加入到这个链表。 FULL 链表：同一个段中，已经没有空闲空间的区对应的XDES Entry 结构会被加入到这个链表。    再次强调一遍，每一个索引都对应两个段，每个段都会维护上述的3个链表\nCREATE TABLE t (\rc1 INT NOT NULL AUTO_INCREMENT,\rc2 VARCHAR(100),\rc3 VARCHAR(100),\rPRIMARY KEY (c1),\rKEY idx_c2 (c2)\r)ENGINE=InnoDB;\r 这个表t 共有两个索引，一个聚簇索引，一个二级索引idx_c2 ，所以这个表共有4个段，每个段都会维护上述3个链表，总共是12个链表，加上我们上边说过的直属于表空间的3个链表，整个独立表空间共需要维护15个链表。所以段在数据量比较大时插入数据的话，会先获取NOT_FULL 链表的头节点，直接把数据插入这个头节点对应的区中即可，如果该区的空间已经被用完，就把该节点移到FULL 链表中\n段的结构  我们前边说过，段其实不对应表空间中某一个连续的物理区域，而是一个逻辑上的概念，由若干个零散的页面以及一些完整的区组成。像每个区都有对应的 XDES Entry 来记录这个区中的属性一样，设计 InnoDB 的大叔为每个段都定义了一个 INODE Entry 结构来记录一下段中的属性。大家看一下示意图\n它的各个部分释义如下：\n Segment ID 就是指这个 INODE Entry 结构对应的段的编号（ID）。 NOT_FULL_N_USED 这个字段指的是在 NOT_FULL 链表中已经使用了多少个页面。下次从 NOT_FULL 链表分配空闲页面时可以直接根据这个字段的值定位到。而不用从链表中的第一个页面开始遍历着寻找空闲页面。 3个 List Base Node 分别为段的 FREE 链表、 NOT_FULL 链表、 FULL 链表定义了 List Base Node ，这样我们想查找某个段的某个链表的头节点和尾节点的时候，就可以直接到这个部分找到对应链表的 List Base Node Magic Number ： 这个值是用来标记这个 INODE Entry 是否已经被初始化了（初始化的意思就是把各个字段的值都填进去了） Fragment Array Entry 我们前边强调过无数次段是一些零散页面和一些完整的区的集合，每个 Fragment Array Entry 结构都对应着一个零散的页面，这个结构一共4个字节，表示一个零散页面的页号。  各类型页面详细情况  到现在为止我们已经大概清楚了表空间、段、区、XDES Entry、INODE Entry、各种以 XDES Enty 为节点的链表的基本概念了，但是每个区对应的 XDES Entry 结构到底存储在表空间的什么地方？直属于表空间的 FREE 、 FREE_FRAG 、 FULL_FRAG 链表的基节点到底存储在表空间的什么地方？每个段对应的 INODE Entry 结构到底存在表空间的什么地方？我们前边介绍了每256个连续的区算是一个组，想解决刚才提出来的这些个疑问还得从每个组开头的一些类型相同的页面说起\nFSP_HDR 类型 首先看第一个组的第一个页面，当然也是表空间的第一个页面，页号为 0 。这个页面的类型是 FSP_HDR ，它存储了表空间的一些整体属性以及第一个组内256个区的对应的 XDES Entry 结构，直接看这个类型的页面的示意图\n总结 这部分内容比较偏理论，所以自己看的时候也没有特别仔细看，如果以后能遇到可以返回来仔细看看，最后一张图总结表空间：\n","id":0,"section":"posts","summary":"[TOC] 本篇文章是(Mysql是怎样运行的)阅读笔记，这本书网上很多人的评价都很高，看了下书也不是很厚，所以读读。 MySQL的架构 mysql 工作的整体流程","tags":["mysql"],"title":"Mysql是怎样运行的","uri":"https://wzgl998877.github.io/2022/01/mysql%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%90%E8%A1%8C%E7%9A%84/","year":"2022"},{"content":"Java 并发编程 ​\t并发编程之美的笔记\n什么是线程 ​\t进程是操作系统资源分配的最小单位，而线程是CPU任务调度和执行的最小单位\n具体参考 https://blog.csdn.net/ThinkWon/article/details/102021274\n五状态进程的主要有：\n 运行态：进程正在执行。 就绪态：进程做好了准备，随时接收调度。 阻塞态：进程在等待某些事件的发生，在事件发生前不能执行，如I/O操作。 新建态：刚刚新建的进程，操作系统还未将其加载至内存，通常是PCB已经创建但是还并未加载到内存中的新程序。 退出态：操作系统从可执行进程组中释放的进程。  Java 中对应的线程状态有：\n  new一个实例出来，线程就进入了初始状态\n  2.1. 就绪状态(RUNNABLE之READY)\n 就绪状态只是说你资格运行，调度程序没有挑选到你，你就永远是就绪状态。 调用线程的start()方法，此线程进入就绪状态 当前线程sleep()方法结束，其他线程join()结束，等待用户输入完毕，某个线程拿到对象锁，这些线程也将进入就绪状态。 当前线程时间片用完了，调用当前线程的yield()方法，当前线程进入就绪状态。锁池里的线程拿到对象锁后，进入就绪状态。    2.2. 运行中状态(RUNNABLE之RUNNING) 线程调度程序从可运行池中选择一个线程作为当前线程时线程所处的状态。这也是线程进入运行状态的唯一的一种方式。\n  阻塞状态是线程在等待获得synchronized锁。\n  等待状态（waiting）处于这种状态的线程不会被分配CPU执行时间，它们要等待被显式地唤醒，否则会处于无限期等待的状态，可以通过以下方式进入该状态\n wait() join() LockSupport.park()    超时等待(TIMED_WAITING) ,可以通过以下方式进入该状态\n Thread.sleep Object.wait with timeout Thread.join with timeout LockSupport.parkNanos LockSupport.parkUntil    终止状态(TERMINATED)\n  当线程的run()方法完成时，或者主线程的main()方法完成时，我们就认为它终止了。这个线程对象也许是活的，但是它已经不是一个单独执行的线程。线程一旦终止了，就不能复生。\n  在一个终止的线程上调用start()方法，会抛出java.lang.IllegalThreadStateException异常。\n    常用方法介绍 wait() 当一个线程调用一个共享变量的 wait() 方法时，该调用线程会被阻塞挂起，直到发生下面几件事情之一才返回：\n 其他线程调用了该共享对象的notify（）或者notifyAll（）方法； 其他线程调用了该线程的interrupt（）方法，该线程抛出InterruptedException异常返回。  如果调用wait（）方法的线程没有事先获取该对象的监视器锁，则调用wait（）方法时调用线程会抛出IllegalMonitorStateException异常。\n如何获得对象的监视器锁？\n 执行synchronized同步代码块时，使用该共享变量作为参数  synchronized (lock) {\rlock.wait();\r}\r 调用该共享变量的方法，并且该方法使用了synchronized修饰。  notify() ​\t一个线程调用共享对象的notify（）方法后，会唤醒一个在该共享变量上调用wait系列方法后被挂起的线程。一个共享变量上可能会有多个线程在等待，具体唤醒哪个等待的线程是随机的。此外，被唤醒的线程不能马上从wait方法返回并继续执行，它必须在获取了共享对象的监视器锁后才可以返回，也就是唤醒它的线程释放了共享变量上的监视器锁后，被唤醒的线程也不一定会获取到共享对象的监视器锁，这是因为该线程还需要和其他线程一起竞争该锁，只有该线程竞争到了共享变量的监视器锁后才可以继续执行。\nnotifyAll() 函数 不同于在共享变量上调用notify（）函数会唤醒被阻塞到该共享变量上的一个线程，notifyAll（）方法则会唤醒所有在该共享变量上由于调用wait系列方法而被挂起的线程。\n一个经典题目，n个线程按顺序交替打印数字\npackage com.zt.javastudy.grammar;\rimport java.util.concurrent.atomic.AtomicInteger;\r/**\r* n个线程按顺序打印从0 到N\r* @author zhengtao\r*/\rpublic class MultiThreadOrdering {\rprivate final AtomicInteger sign = new AtomicInteger(0);\rprivate static final Object lock = new Object();\rprivate int k;\rprivate int flag;\rpublic MultiThreadOrdering(int k, int flag) {\rthis.k = k;\rthis.flag = flag;\r}\rprivate void printAlpha(int num) {\rnew Thread(() -\u0026gt; {\rwhile (sign.intValue() \u0026lt; flag) {\rsynchronized (lock) {\rif (sign.intValue() % k != num) {\rtry {\rlock.wait();\r} catch (InterruptedException e) {\re.printStackTrace();\r}\r} else {\rSystem.out.print((char) (num + 'A'));\rsign.incrementAndGet();\rSystem.out.println(\u0026quot; 打印后的sign值为：\u0026quot; + sign);\rlock.notifyAll();\r}\r}\r}\r}\r).start();\r}\rpublic static void main(String[] args) throws InterruptedException {\rint k = 5;\rMultiThreadOrdering demo = new MultiThreadOrdering(k, 11);\rfor (int i = 0; i \u0026lt; k; i++) {\rdemo.printAlpha(i);\r}\r}\r}\r 信号量Semaphore Semaphore信号量也是Java中的一个同步器，与CountDownLatch和CycleBarrier不同的是，它内部的计数器是递增的，并且在一开始初始化Semaphore时可以指定一个初始值，但是并不需要知道需要同步的线程个数，而是在需要同步的地方调用acquire方法时指定需要同步的线程个数。\n主要方法\nacquire() ​\t当前线程调用该方法的目的是希望获取一个信号量资源。如果当前信号量个数大于0，则当前信号量的计数会减1，然后该方法直接返回。否则如果当前信号量个数等于0，则当前线程会被放入AQS的阻塞队列。当其他线程调用了当前线程的interrupt（）方法中断了当前线程时，则当前线程会抛出InterruptedException异常返回。\nrelease() ​\t该方法的作用是把当前Semaphore对象的信号量值增加1，如果当前有线程因为调用aquire方法被阻塞而被放入了AQS的阻塞队列，则会根据公平策略选择一个信号量个数能被满足的线程进行激活，激活的线程会尝试获取刚增加的信号量\nSemaphore是使用AQS实现的。Sync只是对AQS的一个修饰，并且Sync有两个实现类，用来指定获取信号量时是否采用公平策略，构造函数为\npublic Semaphore(int permits) {\rsync = new NonfairSync(permits);\r}\rpublic Semaphore(int permits, boolean fair) {\rsync = fair ? new FairSync(permits) : new NonfairSync(permits);\r}\r Semaphore默认采用非公平策略,其中的公平与非公平表现在，先调用aquire方法获取信号量的线程不一定比后来者先获取到信号量。考虑下面场景，如果线程A先调用了aquire（）方法获取信号量，但是当前信号量个数为0，那么线程A会被放入AQS的阻塞队列。过一段时间后线程C调用了release（）方法释放了一个信号量，如果当前没有其他线程获取信号量，那么线程A就会被激活，然后获取该信号量，但是假如线程C释放信号量后，线程C调用了aquire方法，那么线程C就会和线程A去竞争这个信号量资源。如果采用非公平策略，由nonfairTryAcquireShared的代码可知，线程C完全可以在线程A被激活前，或者激活后先于线程A获取到该信号量，也就是在这种模式下阻塞线程和当前请求的线程是竞争关系，而不遵循先来先得的策略。\n信号量解决经典题目，n个线程按顺序交替打印数字\npackage com.zt.javastudy.grammar;\rimport java.util.concurrent.Semaphore;\r/**\r* n个线程按顺序打印从0 到N 高级版\r* @author zhengtao\r*/\rpublic class LoopPrinter {\rprivate final static int THREAD_COUNT = 3;\rstatic int result = 0;\rstatic int maxNum = 10;\rpublic static void main(String[] args) throws InterruptedException {\rfinal Semaphore[] semaphores = new Semaphore[THREAD_COUNT];\rfor (int i = 0; i \u0026lt; THREAD_COUNT; i++) {\r//非公平信号量，每个信号量初始计数都为1\rsemaphores[i] = new Semaphore(1);\rif (i != THREAD_COUNT - 1) {\rSystem.out.println(i+\u0026quot;===\u0026quot;+semaphores[i].getQueueLength());\r//获取一个许可前线程将一直阻塞, for 循环之后只有 syncObjects[2] 没有被阻塞\rsemaphores[i].acquire();\r}\r}\rfor (int i = 0; i \u0026lt; THREAD_COUNT; i++) {\r// 初次执行，上一个信号量是 syncObjects[2]\rfinal Semaphore lastSemphore = i == 0 ? semaphores[THREAD_COUNT - 1] : semaphores[i - 1];\rfinal Semaphore currentSemphore = semaphores[i];\rfinal int index = i;\rnew Thread(() -\u0026gt; {\rtry {\rwhile (true) {\r// 初次执行，让第一个 for 循环没有阻塞的 syncObjects[2] 先获得令牌阻塞了\rlastSemphore.acquire();\rSystem.out.println(\u0026quot;thread\u0026quot; + index + \u0026quot;: \u0026quot; + result++);\rif (result \u0026gt; maxNum) {\rSystem.exit(0);\r}\r// 释放当前的信号量，syncObjects[0] 信号量此时为 1，下次 for 循环中上一个信号量即为syncObjects[0]\rcurrentSemphore.release();\r}\r} catch (Exception e) {\re.printStackTrace();\r}\r}).start();\r}\r}\r}\r join ​\t在项目实践中经常会遇到一个场景，就是需要等待某几件事情完成后才能继续往下执行，比如多个线程加载资源，需要等待多个线程全部加载完毕再汇总处理。Thread类中有一个join方法就可以做这个事情，前面介绍的等待通知方法是Object类中的方法，而join方法则是Thread类直接提供的。join是无参且返回值为void的方法。\npackage com.zt.javastudy.concurrent;\rimport java.util.Random;\rimport java.util.concurrent.ThreadLocalRandom;\r/**\r* 一些并发编程的源码研究\r*\r* @author zhengtao on 2021/10/29\r*/\rpublic class Day1 {\rpublic static void main(String[] args) throws InterruptedException {\rThread threadA = new Thread(() -\u0026gt; {\rtry {\rThread.sleep(2000);\r} catch (InterruptedException e) {\re.printStackTrace();\r}\rSystem.out.println(\u0026quot;Thread A 执行完了\u0026quot;);\r});\rThread threadB = new Thread(() -\u0026gt; {\rtry {\rThread.sleep(1000);\r} catch (InterruptedException e) {\re.printStackTrace();\r}\rSystem.out.println(\u0026quot;Thread B 执行完了\u0026quot;);\r});\rthreadA.start();\rthreadB.start();\rSystem.out.println(\u0026quot;123\u0026quot;);\rthreadA.join();\rSystem.out.println(\u0026quot;456\u0026quot;);\rthreadB.join();\rSystem.out.println(\u0026quot;主线程执行完了\u0026quot;);\r}\r}\r输出结果为：\r123\rThread B 执行完了\rThread A 执行完了\r456\r主线程执行完了，不太理解为什么会先输出b执行完了，而不是456\r sleep ​\tThread类中有一个静态的sleep方法，当一个执行中的线程调用了Thread的sleep方法后，调用线程会暂时让出指定时间的执行权，也就是在这期间不参与CPU的调度，但是该线程所拥有的监视器资源，比如锁还是持有不让出的。指定的睡眠时间到了后该函数会正常返回，线程就处于就绪状态，然后参与CPU的调度，获取到CPU资源后就可以继续运行了。如果在睡眠期间其他线程调用了该线程的interrupt（）方法中断了该线程，则该线程会在调用sleep方法的地方抛出InterruptedException异常而返回。\nyield ​\t当一个线程调用yield方法时，实际就是在暗示线程调度器当前线程请求让出自己的CPU使用，但是线程调度器可以无条件忽略这个暗示。我们知道操作系统是为每个线程分配一个时间片来占有CPU的，正常情况下当一个线程把分配给自己的时间片使用完后，线程调度器才会进行下一轮的线程调度，而当一个线程调用了Thread类的静态方法yield时，是在告诉线程调度器自己占有的时间片中还没有使用完的部分自己不想使用了，这暗示线程调度器现在就可以进行下一轮的线程调度。当一个线程调用yield方法时，当前线程会让出CPU使用权，然后处于就绪状态，线程调度器会从线程就绪队列里面获取一个线程优先级最高的线程，当然也有可能会调度到刚刚让出CPU的那个线程来获取CPU执行权.\n​\tsleep与yield方法的区别在于，当线程调用sleep方法时调用线程会被阻塞挂起指定的时间，在这期间线程调度器不会去调度该线程。而调用yield方法时，线程只是让出自己剩余的时间片，并没有被阻塞挂起，而是处于就绪状态，线程调度器下一次调度时就有可能调度到当前线程执行。\n并发和并行 ​\t并发是指同一个时间段内多个任务同时都在执行，并且都没有执行结束，而并行是说在单位时间内多个任务同时在执行。并发任务强调在一个时间段内同时执行，而一个时间段由多个单位时间累积而成，所以说并发的多个任务在单位时间内不一定同时在执行。在单CPU的时代多个任务都是并发执行的，这是因为单个CPU同时只能执行一个任务。\n线程死锁 ​\t死锁是指两个或两个以上的线程在执行过程中，因争夺资源而造成的互相等待的现象\n  互斥条件：指线程对已经获取到的资源进行排它性使用，即该资源同时只由一个线程占用。如果此时还有其他线程请求获取该资源，则请求者只能等待，直至占有资源的线程释放该资源。\n  请求并持有条件：指一个线程已经持有了至少一个资源，但又提出了新的资源请求，而新资源已被其他线程占有，所以当前线程会被阻塞，但阻塞的同时并不释放自己已经获取的资源。\n  不可剥夺条件：指线程获取到的资源在自己使用完之前不能被其他线程抢占，只有在自己使用完毕后才由自己释放该资源。\n  环路等待条件：指在发生死锁时，必然存在一个线程—资源的环形链，即线程集合{T0, T1, T2, …, Tn}中的T0正在等待一个T1占用的资源，T1正在等待T2占用的资源，……Tn正在等待已被T0占用的资源。\n  解决死锁 ​\t解决死锁，只需要破坏掉至少一个构造死锁的必要条件即可\n 破坏互斥条件: 我们需要允许进程同时访问某些资源，这种方法受制于实际场景，不太容易实现条件；java 中有很多类，采用了CAS的方法来实现，比如 AtomicInteger 等。 破坏请求并持有条件：这样需要允许进程强行从占有者那里夺取某些资源，或者简单一点理解，占有资源的进程不能再申请占有其他资源，必须释放手上的资源之后才能发起申请，这个其实也很难找到适用场景； 破坏不可剥夺条件: 进程在运行前申请得到所有的资源，否则该进程不能进入准备执行状态。 破坏环路等待条件: 通过对加锁的操作进行排序我们就能够破坏环路等待条件。例如当我们需要获取数组中某一个位置对应的锁来修改这个位置上保存的值时，如果需要同时获取多个位置对应的锁，那么我们就可以按位置在数组中的排列先后顺序统一从前往后加锁。  最有效的是使用资源申请的有序性原则来破坏环路等待条件解决死锁。\n内存可见性 ​\tJava 内存模型规定，将所有的变量都存放在主内存中，当线程使用变量时，会把主内存里面的变量复制到自己的工作空间或者叫作工作内存，然后对工作内存里的变量进行处理，处理完后将变量值更新到主内存，线程读写变量时操作的是自己工作内存中的变量。\n假如线程A和线程B同时处理一个共享变量，\n  线程A首先获取共享变量X的值，由于两级Cache都没有命中，所以加载主内存中X的值，假如为0。然后把X=0的值缓存到两级缓存，线程A修改X的值为1，然后将其写入两级Cache，并且刷新到主内存。线程A操作完毕后，线程A所在的CPU的两级Cache内和主内存里面的X的值都是1。\n  线程B获取X的值，首先一级缓存没有命中，然后看二级缓存，二级缓存命中了，所以返回X= 1；到这里一切都是正常的，因为这时候主内存中也是X=1。然后线程B修改X的值为2，并将其存放到线程2所在的一级Cache和共享二级Cache中，最后更新主内存中X的值为2；到这里一切都是好的。\n  线程A这次又需要修改X的值，获取时一级缓存命中，并且X=1，到这里问题就出现了，明明线程B已经把X的值修改为了2，为何线程A获取的还是1呢？这就是共享变量的内存不可见问题，也就是线程B写入的值对线程A不可见。\n  synchronized ​\tsynchronized 块是 Java 提供的一种原子性内置锁，Java 中的每个对象都可以把它当作一个同步锁来使用，这些 Java 内置的使用者看不到的锁被称为内部锁，也叫作监视器锁。线程的执行代码在进入synchronized代码块前会自动获取内部锁，这时候其他线程访问该同步代码块时会被阻塞挂起。拿到内部锁的线程会在正常退出同步代码块或者抛出异常后或者在同步块内调用了该内置锁资源的wait系列方法时释放该内置锁。内置锁是排它锁，也就是当一个线程获取这个锁后，其他线程必须等待该线程释放锁后才能获取该锁。\n由于Java中的线程是与操作系统的原生线程一一对应的，所以当阻塞一个线程时，需要从用户态切换到内核态执行阻塞操作，这是很耗时的操作，而synchronized的使用就会导致上下文切换。\n上下文切换：\n​\t在多线程编程中，线程个数一般都大于CPU个数，而每个CPU同一时刻只能被一个线程使用，为了让用户感觉多个线程是在同时执行的，CPU资源的分配采用了时间片轮转的策略，也就是给每个线程分配一个时间片，线程在时间片内占用CPU执行任务。当前线程使用完时间片后，就会处于就绪状态并让出CPU让其他线程占用，这就是上下文切换，从当前线程的上下文切换到了其他线程。那么就有一个问题，让出CPU的线程等下次轮到自己占有CPU时如何知道自己之前运行到哪里了？所以在切换线程上下文时需要保存当前线程的执行现场，当再次执行时根据保存的执行现场信息恢复执行现场。线程上下文切换时机有：当前线程的CPU时间片使用完处于就绪状态时，当前线程被其他线程中断时。\nsynchronized的内存语义 ​\t进入 synchronized 块的内存语义是把在 synchronized 块内使用到的变量从线程的工作内存中清除，这样在 synchronized 块内使用到该变量时就不会从线程的工作内存中获取，而是直接从主内存中获取。退出 synchronized 块的内存语义是把在 synchronized 块内对共享变量的修改刷新到主内存。\n​\t其实这也是加锁和释放锁的语义，当获取锁后会清空锁块内本地内存中将会被用到的共享变量，在使用这些共享变量时从主内存进行加载，在释放锁时将本地内存中修改的共享变量刷新到主内存。\n​\t除可以解决共享变量内存可见性问题外，synchronized经常被用来实现原子性操作。另外请注意，synchronized关键字会引起线程上下文切换并带来线程调度开销。\nvolatile ​\t该关键字可以确保对一个变量的更新对其他线程马上可见。当一个变量被声明为volatile时，线程在写入变量时不会把值缓存在寄存器或者其他地方，而是会把值刷新回主内存。当其他线程读取该共享变量时，会从主内存重新获取最新值，而不是使用当前线程的工作内存中的值。\nvolatile的内存语义 ​\t当线程写入了volatile变量值时就等价于线程退出synchronized同步块（把写入工作内存的变量值同步到主内存），读取volatile变量值时就相当于进入同步块（先清空本地内存变量值，再从主内存获取最新值）。volatile只能作用于变量。\nvolatile虽然提供了可见性保证，但并不保证操作的原子性。\n那么一般在什么时候才使用volatile关键字呢？\n 写入变量值不依赖变量的当前值时。因为如果依赖当前值，将是获取—计算—写入三步操作，这三步操作不是原子性的，而volatile不保证原子性。 读写变量值时没有加锁。因为加锁本身已经保证了内存可见性，这时候不需要把变量声明为volatile的。  原子性 ​\t是指执行一系列操作时，这些操作要么全部执行，要么全部不执行，不存在只执行其中一部分的情况。\n最简单的方法就是使用synchronized关键字进行同步，但是使用synchronized关键字效率比较低，有非阻塞的CAS算法可以实现原子性操作。\nCAS ​\t在Java中，锁在并发处理中占据了一席之地，但是使用锁有一个不好的地方，就是当一个线程没有获取到锁时会被阻塞挂起，这会导致线程上下文的切换和重新调度开销。Java提供了非阻塞的volatile关键字来解决共享变量的可见性问题，这在一定程度上弥补了锁带来的开销问题，但是volatile只能保证共享变量的可见性，不能解决读—改—写等的原子性问题。\n​\t而CAS即Compare and Swap，其是JDK提供的非阻塞原子性操作，它通过硬件保证了比较—更新操作的原子性，JDK里面的Unsafe类提供了一系列的compareAndSwap*方法，下面以compareAndSwapLong方法为例进行简单介绍。\n boolean compareAndSwapLong（Object obj, long valueOffset, long expect, longupdate）方法：其中compareAndSwap的意思是比较并交换。CAS有四个操作数，分别为：对象内存位置、对象中的变量的偏移量、变量预期值和新的值。其操作含义是，如果对象obj中内存偏移量为valueOffset的变量值为expect，则使用新的值update替换旧的值expect。这是处理器提供的一个原子性指令。\n ​\t关于CAS操作有个经典的ABA问题，具体如下：假如线程I使用CAS修改初始值为A的变量X，那么线程I会首先去获取当前变量X的值（为A），然后使用CAS操作尝试修改X的值为B，如果使用CAS操作成功了，那么程序运行一定是正确的吗？其实未必，这是因为有可能在线程I获取变量X的值A后，在执行CAS前，线程II使用CAS修改了变量X的值为B，然后又使用CAS修改了变量X的值为A。所以虽然线程I执行CAS时X的值是A，但是这个A已经不是线程I获取时的A了。\n有序性 ​\tJava内存模型允许编译器和处理器对指令重排序以提高运行性能，并且只会对不存在数据依赖性的指令重排序。在单线程下重排序可以保证最终执行的结果与程序顺序执行的结果一致，但是在多线程下就会存在问题。\npublic class OrderTest {\rprivate static int num = 0;\rprivate static boolean ready = false;\rpublic static void main(String[] args) throws InterruptedException {\rThread read = new Thread(new Runnable() {\r@Override\rpublic void run() {\rwhile (!Thread.currentThread().isInterrupted()) {\rif (ready) { // 1\rSystem.out.println(num + num);// 2\r}\r}\r}\r});\rThread write = new Thread(new Runnable() {\r@Override\rpublic void run() {\rnum = 2;// 3\rready = true;// 4\r}\r});\rread.start();\rwrite.start();\rThread.sleep(1);\rread.interrupt();\rSystem.out.println(\u0026quot;exit\u0026quot;);\r}\r}\r ​\t这段代码不一定输出是4，由于代码（1）（2）（3）（4）之间不存在依赖关系，所以写线程的代码（3）（4）可能被重排序为先执行（4）再执行（3），那么执行（4）后，读线程可能已经执行了（1）操作，并且在（3）执行前开始执行（2）操作，这时候输出结果为0而不是4。\n并发编程最主要的特性：原子性，有序性和可见性\nsynchronized: 具有原子性，有序性和可见性； volatile：具有有序性和可见性\n锁   乐观锁与悲观锁\n 悲观锁: 指对数据被外界修改持保守态度，认为数据很容易就会被其他线程修改，所以在数据被处理前先对数据进行加锁，并在整个数据处理过程中，使数据处于锁定状态。悲观锁的实现往往依靠数据库提供的锁机制，即在数据库中，在对数据记录操作前给记录加排它锁。如果获取锁失败，则说明数据正在被其他线程修改，当前线程则等待或者抛出异常。如果获取锁成功，则对记录进行操作，然后提交事务后释放排它锁。 乐观锁: 是相对悲观锁来说的，它认为数据在一般情况下不会造成冲突，所以在访问记录前不会加排它锁，而是在进行数据提交更新时，才会正式对数据冲突与否进行检测。乐观锁并不会使用数据库提供的锁机制，一般在表中添加version字段或者使用业务状态来实现。乐观锁直到提交时才锁定，所以不会产生任何死锁    公平锁与非公平锁\n 根据线程获取锁的抢占机制，锁可以分为公平锁和非公平锁，公平锁表示线程获取锁的顺序是按照线程请求锁的时间早晚来决定的，也就是最早请求锁的线程将最早获取到锁。而非公平锁则在运行时闯入，也就是先来不一定先得。 假设线程A已经持有了锁，这时候线程B请求该锁其将会被挂起。当线程A释放锁后，假如当前有线程C也需要获取该锁，如果采用非公平锁方式，则根据线程调度策略，线程B和线程C两者之一可能获取锁，这时候不需要任何其他干涉，而如果使用公平锁则需要把C挂起，让B获取当前锁。 在没有公平性需求的前提下尽量使用非公平锁，因为公平锁会带来性能开销。    独占锁与共享锁\n 根据锁只能被单个线程持有还是能被多个线程共同持有，锁可以分为独占锁和共享锁。 独占锁: 保证任何时候都只有一个线程能得到锁。 共享锁: 可以同时由多个线程持有，它允许一个资源可以被多线程同时进行读操作。 独占锁是一种悲观锁，由于每次访问资源都先加上互斥锁，这限制了并发性，因为读操作并不会影响数据的一致性，而独占锁只允许在同一时间由一个线程读取数据，其他线程必须等待当前线程释放锁才能进行读取。共享锁则是一种乐观锁，它放宽了加锁的条件，允许多个线程同时进行读操作。    可重入锁\n当一个线程要获取一个被其他线程持有的独占锁时，该线程会被阻塞，那么当一个线程再次获取它自己已经获取的锁时是否会被阻塞呢？如果不被阻塞，那么我们说该锁是可重入的，也就是只要该线程获取了该锁，那么可以无限次数（在高级篇中我们将知道，严格来说是有限次数）地进入被该锁锁住的代码。\nsynchronized内部锁是可重入锁。可重入锁的原理是在锁内部维护一个线程标示，用来标示该锁目前被哪个线程占用，然后关联一个计数器。一开始计数器值为0，说明该锁没有被任何线程占用。当一个线程获取了该锁时，计数器的值会变成1，这时其他线程再来获取该锁时会发现锁的所有者不是自己而被阻塞挂起。但是当获取了该锁的线程再次获取锁时发现锁拥有者是自己，就会把计数器值加+1，当释放锁后计数器值-1。当计数器值为0时，锁里面的线程标示被重置为null，这时候被阻塞的线程会被唤醒来竞争获取该锁。\n  自旋锁\n当一个线程在获取锁（比如独占锁）失败后，会被切换到内核状态而被挂起。当该线程获取到锁时又需要将其切换到用户态而唤醒该线程。而从用户状态切换到内核状态的开销是比较大的，在一定程度上会影响并发性能。自旋锁则是，当前线程在获取锁时，如果发现锁已经被其他线程占有，它不马上阻塞自己，在不放弃CPU使用权的情况下，多次尝试获取（默认次数是10，可以使用-XX:PreBlockSpinsh参数设置该值），很有可能在后面几次尝试中其他线程已经释放了锁。如果尝试指定的次数后仍没有获取到锁则当前线程才会被阻塞挂起。\n  锁的详细介绍参考博客：https://tech.meituan.com/2018/11/15/java-lock.html\nJdk 中一些并发编程的源码解析 Threadlocal ​\t它提供了线程本地变量，也就是如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的一个本地副本。当多个线程操作这个变量时，实际操作的是自己本地内存里面的变量，从而避免了线程安全问题。创建一个ThreadLocal变量后，每个线程都会复制一个变量到自己的本地内存。\n类图 ​\tThread 类中有一个 threadLocals 和一个 inheritableThreadLocals，它们都是 ThreadLocalMap 类型的变量，而ThreadLocalMap是一个定制化的Hashmap。在默认情况下，每个线程中的这两个变量都为null，只有当前线程第一次调用ThreadLocal的set或者get方法时才会创建它们。其实每个线程的本地变量不是存放在ThreadLocal实例里面，而是存放在调用线程的threadLocals变量里面。也就是说，ThreadLocal类型的本地变量存放在具体的线程内存空间中。ThreadLocal就是一个工具壳，它通过set方法把value值放入调用线程的threadLocals里面并存放起来，当调用线程调用它的get方法时，再从当前线程的threadLocals变量里面将其拿出来使用。如果调用线程一直不终止，那么这个本地变量会一直存放在调用线程的threadLocals变量里面，可能会造成内存溢出，因此使用完毕后要记得调用ThreadLocal的remove方法删除对应线程的threadLocals中的本地变量\nset public void set(T value) {\r// 获取当前线程\rThread t = Thread.currentThread();\r// 将当前线程作为key，去查找对应的线程变量\rThreadLocalMap map = getMap(t);\rif (map != null)\rmap.set(this, value);\relse\r// 第一次调用则创建当前线程对应的hashmap\rcreateMap(t, value);\r}\rThreadLocalMap getMap(Thread t) {\rreturn t.threadLocals;\r}\rvoid createMap(Thread t, T firstValue) {\rt.threadLocals = new ThreadLocalMap(this, firstValue);\r}\r get public T get() {\rThread t = Thread.currentThread();\rThreadLocalMap map = getMap(t);\rif (map != null) {\rThreadLocalMap.Entry e = map.getEntry(this);\rif (e != null) {\r@SuppressWarnings(\u0026quot;unchecked\u0026quot;)\rT result = (T)e.value;\rreturn result;\r}\r}\rreturn setInitialValue();\r}\rprivate T setInitialValue() {\rT value = initialValue();\rThread t = Thread.currentThread();\rThreadLocalMap map = getMap(t);\rif (map != null)\rmap.set(this, value);\relse\rcreateMap(t, value);\rreturn value;\r}\rprotected T initialValue() {\rreturn null;\r}\r get方法逻辑为\n 首先获取当前线程实例，如果当前线程的threadLocals变量不为null，则直接返回当前线程绑定的本地变量 否则进行初始化，如果当前线程的threadLocals变量不为空，则设置当前线程的本地变量值为null，否则调用createMap方法创建当前线程的createMap变量。   remove public void remove() {\rThreadLocalMap m = getMap(Thread.currentThread());\rif (m != null)\rm.remove(this);\r}\r 总结 在每个线程内部都有一个名为threadLocals的成员变量，该变量的类型为HashMap，其中key为我们定义的ThreadLocal变量的this引用，value则为我们使用set方法设置的值\npackage com.zt.javastudy.concurrent;\r/**\r* ThreadLocal 测试\r*\r* @author zhengtao on 2021/11/10\r*/\rpublic class ThreadLocalTest implements Runnable {\rpublic static ThreadLocal\u0026lt;Integer\u0026gt; threadLocal = new ThreadLocal\u0026lt;\u0026gt;();\rpublic static ThreadLocal\u0026lt;Integer\u0026gt; integerThreadLocal = new InheritableThreadLocal\u0026lt;\u0026gt;();\rpublic static int i = 0;\rpublic static void main(String[] args) {\rThreadLocalTest threadLocalTest = new ThreadLocalTest();\rthreadLocal.set(i++);\rintegerThreadLocal.set(i++);\rThread thread1 = new Thread(threadLocalTest);\rthread1.start();\rSystem.out.println(\u0026quot;maint中hreadLocal值为：\u0026quot; + threadLocal.get());\rSystem.out.println(\u0026quot;main中InheritableThreadLocal值为：\u0026quot; + integerThreadLocal.get());\r}\r@Override\rpublic void run() {\rSystem.out.println(Thread.currentThread().getName() + \u0026quot;threadLocal值为:\u0026quot; + threadLocal.get());\rSystem.out.println(Thread.currentThread().getName() + \u0026quot;InheritableThreadLocal值为:\u0026quot; + integerThreadLocal.get());\r}\r}\r# 结果为\rmaint中hreadLocal值为：0\rmain中InheritableThreadLocal值为：1\rThread-0threadLocal值为:null\rThread-0InheritableThreadLocal值为:1\r ​\t同一个ThreadLocal变量在父线程中被设置值后，在子线程中是获取不到的。根据上节的介绍，这应该是正常现象，因为在子线程thread里面调用get方法时当前线程为thread线程，而这里调用set方法设置线程变量的是main线程，两者是不同的线程，自然子线程访问时返回null\n而InheritableThreadLocal类解决了这个问题，流程为：\n 通过重写代码 getMap 和createMap让本地变量保存到了具体线程的inheritableThreadLocals变量里面，那么线程在通过InheritableThreadLocal类实例的set或者get方法设置变量时，就会创建当前线程的inheritableThreadLocals变量。 当父线程创建子线程时，构造函数会把父线程中inheritableThreadLocals变量里面的本地变量复制一份保存到子线程的inheritableThreadLocals变量里面。  Random 随机数正常使用为：\npublic static void main(String[] args) {\rRandom random = new Random();\rfor (int i = 0; i \u0026lt; 10; i++) {\rSystem.out.println(random.nextInt(5));\r}\r}\r public int nextInt(int bound) {\rif (bound \u0026lt;= 0)\rthrow new IllegalArgumentException(BadBound);\r// 根据旧种子生成新种子\rint r = next(31);\rint m = bound - 1;\r// 拿到新种子经过算法生成随机数\rif ((bound \u0026amp; m) == 0) // i.e., bound is a power of 2\rr = (int)((bound * (long)r) \u0026gt;\u0026gt; 31);\relse {\rfor (int u = r;\ru - (r = u % bound) + m \u0026lt; 0;\ru = next(31))\r;\r}\rreturn r;\r}\r 由此可见，新的随机数的生成需要两个步骤：\n  首先根据老的种子生成新的种子。\n  然后根据新的种子来计算新的随机数。\n在单线程情况下每次调用nextInt都是根据老的种子计算出新的种子，这是可以保证随机数产生的随机性的。但是在多线程下多个线程可能都拿同一个老的种子去计算新的种子，这会导致多个线程产生的新种子是一样的，由于算法是固定的，所以会导致多个线程产生相同的随机值。那就不随机了，jdk是怎么解决的呢？\n  protected int next(int bits) {\rlong oldseed, nextseed;\rAtomicLong seed = this.seed;\rdo {\roldseed = seed.get();\rnextseed = (oldseed * multiplier + addend) \u0026amp; mask;\r} while (!seed.compareAndSet(oldseed, nextseed));\rreturn (int)(nextseed \u0026gt;\u0026gt;\u0026gt; (48 - bits));\r}\r 每个Random实例里面都有一个原子性的种子变量用来记录当前的种子值，当要生成新的随机数时需要根据当前种子计算新的种子并更新回原子变量。在多线程下使用单个Random实例生成随机数时，当多个线程同时计算随机数来计算新的种子时，多个线程会竞争同一个原子变量的更新操作，由于原子变量的更新是CAS操作，同时只有一个线程会成功。这样每次的种子都是新的。但会造成大量线程进行自旋重试，这会降低并发性能。所以 ThreadLocalRandom 应运而生。\nThreadLocalRandom Random的缺点是多个线程会使用同一个原子性种子变量，从而导致对原子变量更新的竞争，流程如图所示\n而 ThreadLocalRandom 每个线程都维护一个种子变量，则每个线程生成随机数时都根据自己老的种子计算新的种子，并使用新种子更新老的种子，再根据新种子计算随机数，就不会存在竞争问题了，这会大大提高并发性能。\n明白了这个道理，看源码其实就很简单了。使用\nThreadLocalRandom threadLocalRandom = ThreadLocalRandom.current();\rfor (int i = 0; i \u0026lt; 10; i++) {\rSystem.out.println(threadLocalRandom.nextInt(5));\r}\r public int nextInt(int bound) {\rif (bound \u0026lt;= 0)\rthrow new IllegalArgumentException(BadBound);\rint r = mix32(nextSeed());\rint m = bound - 1;\rif ((bound \u0026amp; m) == 0) // power of two\rr \u0026amp;= m;\relse { // reject over-represented candidates\rfor (int u = r \u0026gt;\u0026gt;\u0026gt; 1;\ru + m - (r = u % bound) \u0026lt; 0;\ru = mix32(nextSeed()) \u0026gt;\u0026gt;\u0026gt; 1)\r;\r}\rreturn r;\r}\r nextInt 和 Random 基本一致，主要区别在生成种子这一步\nfinal long nextSeed() {\rThread t; long r; // read and update per-thread seed\rUNSAFE.putLong(t = Thread.currentThread(), SEED,\rr = UNSAFE.getLong(t, SEED) + GAMMA);\rreturn r;\r}\r 首先使用r = UNSAFE.getLong（t, SEED）获取当前线程中threadLocalRandomSeed变量的值，然后在种子的基础上累加GAMMA值作为新种子，而后使用UNSAFE的putLong方法把新种子放入当前线程的threadLocalRandomSeed变量中。这样就是每个线程维护了自己的种子，提高了并发性能。\nCopyOnWriteArrayList ​\t学习一样东西，先要知道它是为了什么而出现的。先看一段代码\npublic static void main(String[] args) {\rList\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;();\rfor (int i = 0; i \u0026lt; 10; i++) {\rlist.add(i);\r}\rlist.forEach(i -\u0026gt; {\rif (i == 1) {\rlist.remove(i);\r}\r});\r}\r 这段代码，遍历时删除元素很明显会抛出异常，主要原因为list中有个属性为modCount，再进行增删时此值会加1，而进行遍历时会对比modcount是否发生了变化如果发了变化则抛出异常。\n​\t那么如果在并发情况下就有可能出现 一个线程在遍历而另一个线程确在删除，出现生产问题，类似于：\npackage com.zt.javastudy.concurrent;\rimport java.util.ArrayList;\rimport java.util.List;\r/**\r* copyonwritelist 学习\r*\r* @author zhengtao on 2021/11/26\r*/\rpublic class CopyOnWriteTest {\rpublic static void main(String[] args) {\r// 初始化一个list，放入5个元素\rfinal List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;();\r// 使用CopyOnWriteArrayList就不会报错，原因看过后面就知道啦\r// final CopyOnWriteArrayList\u0026lt;Integer\u0026gt; list = new CopyOnWriteArrayList\u0026lt;\u0026gt;();\rfor(int i = 0; i \u0026lt; 5; i++) {\rlist.add(i);\r}\r// 线程一：通过Iterator遍历List\rnew Thread(new Runnable() {\r@Override\rpublic void run() {\rlist.forEach(item -\u0026gt; {\rSystem.out.println(\u0026quot;遍历元素：\u0026quot; + item);\r// 由于程序跑的太快，这里sleep了1秒来调慢程序的运行速度\rtry {\rThread.sleep(1000);\r} catch (InterruptedException e) {\re.printStackTrace();\r}\r});\r}\r}).start();\r// 线程二：remove一个元素\rnew Thread(new Runnable() {\r@Override\rpublic void run() {\r// 由于程序跑的太快，这里sleep了1秒来调慢程序的运行速度\rtry {\rThread.sleep(1000);\r} catch (InterruptedException e) {\re.printStackTrace();\r}\rlist.remove(4);\rSystem.out.println(\u0026quot;list.remove(4)\u0026quot;);\r}\r}).start();\r}\r}\r 所以才有并发List CopyOnWriteArrayList\n概念 CopyOnWriteArrayList是一个线程安全的ArrayList，对其进行的修改操作都是在底层的一个复制的数组（快照）上进行的，也就是使用了写时复制策略。\n每个CopyOnWriteArrayList对象里面有一个array数组对象用来存放具体元素，ReentrantLock独占锁对象用来保证同时只有一个线程对array进行修改。\nadd public boolean add(E e) {\r// 获取独占锁\rfinal ReentrantLock lock = this.lock;\rlock.lock();\rtry {\r// 获取array\rObject[] elements = getArray();\r// 复制array到新数组\rint len = elements.length;\rObject[] newElements = Arrays.copyOf(elements, len + 1);\r// 添加元素到新数组\rnewElements[len] = e;\r// 使用新数组替换添加前的数组\rsetArray(newElements);\rreturn true;\r} finally {\r// 释放独占锁\rlock.unlock();\r}\r}\r 调用add方法的线程会去获取独占锁，如果多个线程都调用add方法则只有一个线程会获取到该锁，其他线程会被阻塞挂起直到锁被释放。所以一个线程获取到锁后，就保证了在该线程添加元素的过程中其他线程不会对array进行修改。线程获取锁后获取array，然后复制array到一个新数组（从这里可以知道新数组的大小是原来数组大小增加1，所以CopyOnWriteArrayList是无界list），并把新增的元素添加到新数组。然后使用新数组替换原数组，并在返回前释放锁。由于加了锁，所以整个add过程是个原子性操作。需要注意的是，在添加元素时，首先复制了一个快照，然后在快照上进行添加，而不是直接在原来数组上进行。\nget public E get(int index) {\rreturn get(getArray(), index);\r}\rfinal Object[] getArray() {\rreturn array;\r} private E get(Object[] a, int index) {\rreturn (E) a[index];\r}\r 当线程x调用get方法获取指定位置的元素时，分两步走，首先获取array数组（这里命名为步骤A），然后通过下标访问指定位置的元素（这里命名为步骤B），这是两步操作，但是在整个过程中并没有进行加锁同步。\n由于执行步骤A和步骤B没有加锁，这就可能导致在线程x执行完步骤A后执行步骤B前，另外一个线程y进行了remove操作，假设要删除元素1。remove操作首先会获取独占锁，然后进行写时复制操作，也就是复制一份当前array数组，然后在复制的数组里面删除线程x通过get方法要访问的元素1，之后让array指向复制的数组。而这时候array之前指向的数组的引用计数为1而不是0，因为线程x还在使用它，这时线程x开始执行步骤B，步骤B操作的数组是线程y删除元素之前的数组。\n所以，虽然线程y已经删除了index处的元素，但是线程x的步骤B还是会返回index处的元素，这其实就是写时复制策略产生的弱一致性问题\nset public E set(int index, E element) {\rfinal ReentrantLock lock = this.lock;\rlock.lock();\rtry {\rObject[] elements = getArray();\rE oldValue = get(elements, index);\rif (oldValue != element) {\rint len = elements.length;\rObject[] newElements = Arrays.copyOf(elements, len);\rnewElements[index] = element;\rsetArray(newElements);\r} else {\r// Not quite a no-op; ensures volatile write semantics\rsetArray(elements);\r}\rreturn oldValue;\r} finally {\rlock.unlock();\r}\r}\r set方法和add方法基本一样，步骤为先拿到锁，复制数组，替换数据，重新set数组值，释放锁。remove方法也一样。\n总结 CopyOnWriteArrayList使用写时复制的策略来保证list的一致性，而获取—修改—写入三步操作并不是原子性的，所以在增删改的过程中都使用了独占锁，来保证在某个时间只有一个线程能对list数组进行修改。另外CopyOnWriteArrayList提供了弱一致性的迭代器，从而保证在获取迭代器后，其他线程对list的修改是不可见的，迭代器遍历的数组是一个快照。\nAQS 概念介绍 AbstractQueuedSynchronizer抽象同步队列简称AQS，它是实现同步器的基础组件，并发包中锁的底层就是使用AQS实现的。\nAQS是一个FIFO的双向队列，其内部通过节点head和tail记录队首和队尾元素，队列元素的类型为Node。\n类图为：\n其中Node中的结构为：\nstatic final class Node {\r/** SHARED用来标记该线程是获取共享资源时被阻塞挂起后放入AQS队列的 */\rstatic final Node SHARED = new Node();\r/** EXCLUSIVE用来标记线程是获取独占资源时被挂起后放入AQS队列的 */\rstatic final Node EXCLUSIVE = null;\r/** waitStatus value to indicate thread has cancelled */\rstatic final int CANCELLED = 1;\r/** waitStatus value to indicate successor's thread needs unparking */\rstatic final int SIGNAL = -1;\r/** waitStatus value to indicate thread is waiting on condition */\rstatic final int CONDITION = -2;\r/**\r* waitStatus value to indicate the next acquireShared should\r* unconditionally propagate\r*/\rstatic final int PROPAGATE = -3;\r/**\rwaitStatus记录当前线程等待状态，可以为CANCELLED（线程被取消了）、SIGNAL（线程需要被唤醒）、CONDITION（线程在条件队列里面等待）、PROPAGATE（释放共享资源时需要通知其他节点）\r*/\rvolatile int waitStatus;\r/**\r* prev记录当前节点的前驱节点\r*/\rvolatile Node prev;\r/**\r* next记录当前节点的后继节点\r*/\rvolatile Node next;\r/**\r* thread变量用来存放进入AQS队列里面的线程\r*/\rvolatile Thread thread;\r/**\r* Link to next node waiting on condition, or the special\r* value SHARED. Because condition queues are accessed only\r* when holding in exclusive mode, we just need a simple\r* linked queue to hold nodes while they are waiting on\r* conditions. They are then transferred to the queue to\r* re-acquire. And because conditions can only be exclusive,\r* we save a field by using special value to indicate shared\r* mode.\r*/\rNode nextWaiter;\r/**\r* Returns true if node is waiting in shared mode.\r*/\rfinal boolean isShared() {\rreturn nextWaiter == SHARED;\r}\r/**\r* Returns previous node, or throws NullPointerException if null.\r* Use when predecessor cannot be null. The null check could\r* be elided, but is present to help the VM.\r*\r* @return the predecessor of this node\r*/\rfinal Node predecessor() throws NullPointerException {\rNode p = prev;\rif (p == null)\rthrow new NullPointerException();\relse\rreturn p;\r}\rNode() { // Used to establish initial head or SHARED marker\r}\rNode(Thread thread, Node mode) { // Used by addWaiter\rthis.nextWaiter = mode;\rthis.thread = thread;\r}\rNode(Thread thread, int waitStatus) { // Used by Condition\rthis.waitStatus = waitStatus;\rthis.thread = thread;\r}\r}\r 对于AQS来说，线程同步的关键是对状态值state进行操作。根据state是否属于一个线程，操作state的方式分为独\n占方式和共享方式。\n使用独占方式获取的资源是与具体线程绑定的，就是说如果一个线程获取到了资源，就会标记是这个线程获取到了，其他线程再尝试操作state获取资源时会发现当前该资源不是自己持有的，就会在获取失败后被阻塞。\n在独占方式下，获取与释放资源的流程如下：\n（1）当一个线程调用acquire（int arg）方法获取独占资源时，会首先使用tryAcquire方法尝试获取资源，具体是设置状态变量state的值，成功则直接返回，失败则将当前线程封装为类型为Node.EXCLUSIVE的Node节点后插入到AQS阻塞队列的尾部，并调用LockSupport.park（this）方法挂起自己。\n（2）当一个线程调用release（int arg）方法时会尝试使用tryRelease操作释放资源，这里是设置状态变量state的值，然后调用LockSupport.unpark（thread）方法激活AQS队列里面被阻塞的一个线程（thread）。被激活的线程则使用tryAcquire尝试，看当前状态变量state的值是否能满足自己的需要，满足则该线程被激活，然后继续向下运行，否则还是会被放入AQS队列并被挂起。\n在共享方式下，获取与释放资源的流程如下：\n（1）当线程调用acquireShared（int arg）获取共享资源时，会首先使用tryAcquireShared尝试获取资源，具体是设置状态变量state的值，成功则直接返回，失败则将当前线程封装为类型为Node.SHARED的Node节点后插入到AQS阻塞队列的尾部，并使用LockSupport.park（this）方法挂起自己。\n（2）当一个线程调用releaseShared（int arg）时会尝试使用tryReleaseShared操作释放资源，这里是设置状态变量state的值，然后使用LockSupport.unpark（thread）激活AQS队列里面被阻塞的一个线程（thread）。被激活的线程则使用tryReleaseShared查看当前状态变量state的值是否能满足自己的需要，满足则该线程被激活，然后继续向下运行，否则还是会被放入AQS队列并被挂起。\nAQS怎么实现双向队列的？ ● 入队操作：当一个线程获取锁失败后该线程会被转换为Node节点，然后就会使用enq（final Node node）方法将该节点插入到AQS的阻塞队列。\nprivate Node enq(final Node node) {\rfor (;;) {\rNode t = tail;\rif (t == null) { // Must initialize\rif (compareAndSetHead(new Node()))\rtail = head;\r} else {\rnode.prev = t;\rif (compareAndSetTail(t, node)) {\rt.next = node;\rreturn t;\r}\r}\r}\r}\r 下面结合代码和节点图（见图6-2）来讲解入队的过程。如上代码在第一次循环中，当要在AQS队列尾部插入元素时，AQS队列状态如图6-2中（default）所示。也就是队列头、尾节点都指向null；当执行代码（1）后节点t指向了尾部节点，这时候队列状态如图6-2中（I）所示。这时候t为null，故执行代码（2），使用CAS算法设置一个哨兵节点为头节点，如果CAS设置成功，则让尾部节点也指向哨兵节点，这时候队列状态如图6-2中（II）所示。到现在为止只插入了一个哨兵节点，还需要插入node节点，所以在第二次循环后执行到代码（1），这时候队列状态如图6-2（III）所示；然后执行代码（3）设置node的前驱节点为尾部节点，这时候队列状态如图6-2中（IV）所示；然后通过CAS算法设置node节点为尾部节点，CAS成功后队列状态如图6-2中（V）所示；CAS成功后再设置原来的尾部节点的后驱节点为node，这时候就完成了双向链表的插入，此时队列状态如图6-2中（VI）所示。\n条件变量 AQS有个内部类ConditionObject，用来结合锁实现线程同步。ConditionObject可以直接访问AQS对象内部的变量，比如state状态值和AQS队列。ConditionObject是条件变量，每个条件变量对应一个条件队列（单向链表队列），其用来存放调用条件变量的await方法后被阻塞的线程，条件变量本质上还是一个等待队列，AQS 中使用单向链表来实现，成员变量如下：\npublic class ConditionObject implements Condition, java.io.Serializable {\rprivate static final long serialVersionUID = 1173984872572414699L;\r/** First node of condition queue. */\rprivate transient Node firstWaiter;\r/** Last node of condition queue. */\rprivate transient Node lastWaiter;\r// ...\r}\r ​\tnotify和wait，是配合synchronized内置锁实现线程间同步的基础设施一样，条件变量的signal和await方法也是用来配合锁（使用AQS实现的锁）实现线程间同步的基础设施。synchronized同时只能与一个共享变量的notify或wait方法实现同步，而AQS的一个锁可以对应多个条件变量。也就是说 一个Lock对象可以创建多个条件变量\n​\t当线程调用条件变量的await（）方法时（必须先调用锁的lock（）方法获取锁），在内部会构造一个类型为Node.CONDITION的node节点，然后将该节点插入条件队列末尾，之后当前线程会释放获取的锁（也就是会操作锁对应的state变量的值），并被阻塞挂起。这时候如果有其他线程调用lock.lock（）尝试获取锁，就会有一个线程获取到锁，如果获取到锁的线程调用了条件变量的await（）方法，则该线程也会被放入条件变量的阻塞队列，然后释放获取到的锁，在await（）方法处阻塞。\npublic final void await() throws InterruptedException {\rif (Thread.interrupted())\rthrow new InterruptedException();\r// 创建新的node节点，并插入到条件队列末尾\rNode node = addConditionWaiter();\r// 释放当前线程获取的锁\rint savedState = fullyRelease(node);\rint interruptMode = 0;\r// 阻塞挂起当前线程\rwhile (!isOnSyncQueue(node)) {\rLockSupport.park(this);\rif ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\rbreak;\r}\rif (acquireQueued(node, savedState) \u0026amp;\u0026amp; interruptMode != THROW_IE)\rinterruptMode = REINTERRUPT;\rif (node.nextWaiter != null) // clean up if cancelled\runlinkCancelledWaiters();\rif (interruptMode != 0)\rreportInterruptAfterWait(interruptMode);\r}\rprivate Node addConditionWaiter() {\rNode t = lastWaiter;\r// If lastWaiter is cancelled, clean out.\rif (t != null \u0026amp;\u0026amp; t.waitStatus != Node.CONDITION) {\runlinkCancelledWaiters();\rt = lastWaiter;\r}\rNode node = new Node(Thread.currentThread(), Node.CONDITION);\rif (t == null)\rfirstWaiter = node;\relse\rt.nextWaiter = node;\rlastWaiter = node;\rreturn node;\r}\r ​\t当另外一个线程调用条件变量的signal方法时（必须先调用锁的lock（）方法获取锁），在内部会把条件队列里面队头的一个线程节点从条件队列里面移除并放入AQS的阻塞队列里面，然后激活这个线程。\npublic final void signal() {\r// 判断是否获取锁\rif (!isHeldExclusively())\rthrow new IllegalMonitorStateException();\rNode first = firstWaiter;\rif (first != null)\r// 将条件队列头元素移动到aqs队列\rdoSignal(first);\r}\r 总结 ​\t当多个线程同时调用lock.lock（）方法获取锁时，只有一个线程获取到了锁，其他线程会被转换为Node节点插入到lock锁对应的AQS阻塞队列里面，并做自旋CAS尝试获取锁。如果获取到锁的线程又调用了对应的条件变量的await（）方法，则该线程会释放获取到的锁，并被转换为Node节点插入到条件变量对应的条件队列里面。这时候因为调用lock.lock（）方法被阻塞到AQS队列里面的一个线程会获取到被释放的锁，如果该线程也调用了条件变量的await（）方法则该线程也会被放入条件变量的条件队列里面。当另外一个线程调用条件变量的signal（）或者signalAll（）方法时，会把条件队列里面的一个或者全部Node节点移动到AQS的阻塞队列里面，等待时机获取锁。\naqs实现锁的原理为，aqs双向阻塞队列用于存放待获取锁的线程(调用lock.lock()没有获取到锁而被阻塞的线程，被signal，signalAll唤醒的线程), 条件变量的条件队列(单向链表队列),用来存放调用条件变量的await方法后被阻塞的线程\nReentrantLock 定义 ​\tReentrantLock 是可重入的独占锁，同时只能有一个线程可以获取该锁，其他获取该锁的线程会被阻塞而被放入该锁的 AQS 阻塞队列里面。\nReentrantLock最终还是使用AQS来实现，既然是基于aqs实现，实际上ReentrantLock只需要做到以下三步\n  明确state的定义\n  重写acquire（int arg）方法，用于获取资源\n  重写release方法，用于释放资源\n  state ​\tAQS的state状态值表示线程获取该锁的可重入次数，在默认情况下，state的值为0表示当前锁没有被任何线程持有。当一个线程第一次获取该锁时会尝试使用CAS设置state的值为1，如果CAS成功则当前线程获取了该锁，然后记录该锁的持有者为当前线程。在该线程没有释放锁的情况下第二次获取该锁后，状态值被设置为2，这就是可重入次数。在该线程释放该锁时，会尝试使用CAS让状态值减1，如果减1后状态值为0，则当前线程释放该锁\n获取锁 ​\tReentrantLock根据参数来决定其内部是一个公平还是非公平锁，默认是非公平锁。\n非公平锁获取锁的过程：\nfinal void lock() {\r// cas 设置状态值\rif (compareAndSetState(0, 1))\r// 设置该锁的持有者是当前线程\rsetExclusiveOwnerThread(Thread.currentThread());\relse\racquire(1);\r}\r 因为默认AQS的状态值为0，所以第一个调用Lock的线程会通过CAS设置状态值为1, CAS成功则表示当前线程获取到了锁，然后setExclusiveOwnerThread设置该锁持有者是当前线程。如果这时候有其他线程调用lock方法企图获取该锁，CAS会失败，然后会调用AQS的acquire方法。\npublic final void acquire(int arg) {\rif (!tryAcquire(arg) \u0026amp;\u0026amp;\r// 没有拿到锁，则放入aqs阻塞队列\racquireQueued(addWaiter(Node.EXCLUSIVE), arg))\rselfInterrupt();\r}\rprotected final boolean tryAcquire(int acquires) {\rreturn nonfairTryAcquire(acquires);\r}\rfinal boolean nonfairTryAcquire(int acquires) {\rfinal Thread current = Thread.currentThread();\rint c = getState();\r// 当前锁还没被占用\rif (c == 0) {\r// 直接更新为state为1，并设置该锁持有者是当前线程\rif (compareAndSetState(0, acquires)) {\rsetExclusiveOwnerThread(current);\rreturn true;\r}\r}\r// 锁已被占用，判断当前线程是否是该锁持有者\relse if (current == getExclusiveOwnerThread()) {\rint nextc = c + acquires;\rif (nextc \u0026lt; 0) // overflow\rthrow new Error(\u0026quot;Maximum lock count exceeded\u0026quot;);\rsetState(nextc);\rreturn true;\r}\rreturn false;\r}\r 公平锁的实现策略为：\nprotected final boolean tryAcquire(int acquires) {\rfinal Thread current = Thread.currentThread();\rint c = getState();\rif (c == 0) {\r// 唯一的不同就是先有个公平性检查\rif (!hasQueuedPredecessors() \u0026amp;\u0026amp;\rcompareAndSetState(0, acquires)) {\rsetExclusiveOwnerThread(current);\rreturn true;\r}\r}\relse if (current == getExclusiveOwnerThread()) {\rint nextc = c + acquires;\rif (nextc \u0026lt; 0)\rthrow new Error(\u0026quot;Maximum lock count exceeded\u0026quot;);\rsetState(nextc);\rreturn true;\r}\rreturn false;\r}\r/**\r公平性策略，主要是检查是否有该线程是否是最先来的获取锁的线程\r*/\rpublic final boolean hasQueuedPredecessors() {\r// The correctness of this depends on head being initialized\r// before tail and on head.next being accurate if the current\r// thread is first in queue.\rNode t = tail; // Read fields in reverse initialization order\rNode h = head;\rNode s;\rreturn h != t \u0026amp;\u0026amp;\r((s = h.next) == null || s.thread != Thread.currentThread());\r}\r 释放锁 尝试释放锁，如果当前线程持有该锁，则调用该方法会让该线程对该线程持有的AQS状态值减1，如果减去1后当前状态值为0，则当前线程会释放该锁，否则仅仅减1而已。如果当前线程没有持有该锁而调用了该方法则会抛出IllegalMonitorStateException异常。\nprotected final boolean tryRelease(int releases) {\rint c = getState() - releases;\r// 如果不是锁持有者抛异常\rif (Thread.currentThread() != getExclusiveOwnerThread())\rthrow new IllegalMonitorStateException();\rboolean free = false;\r// 如果可重入次数为0，则清空锁持有线程\rif (c == 0) {\rfree = true;\rsetExclusiveOwnerThread(null);\r}\r// state减1\rsetState(c);\rreturn free;\r}\r 总结 ​\tReentrantLock的底层是使用AQS实现的可重入独占锁。在这里AQS状态值为0表示当前锁空闲，为大于等于1的值则说明该锁已经被占用。该锁内部有公平与非公平实现，默认情况下是非公平的实现。另外，由于该锁是独占锁，所以某时只有一个线程可以获取该锁。\nReentrantReadWriteLock 解决线程安全问题使用ReentrantLock就可以，但是ReentrantLock是独占锁，某时只有一个线程可以获取该锁，而实际中会有写少读多的场景，显然ReentrantLock满足不了这个需求，所以ReentrantReadWriteLock应运而生。ReentrantReadWriteLock采用读写分离的策略，允许多个线程可以同时获取读锁。\n读写锁的内部维护了一个ReadLock和一个WriteLock，它们依赖Sync实现具体功能。而Sync继承自AQS，并且也提供了公平和非公平的实现。我们知道AQS中只维护了一个state状态，而ReentrantReadWriteLock则需要维护读状态和写状态，一个state怎么表示写和读两种状态呢？ReentrantReadWriteLock巧妙地使用state的高16位表示读状态，也就是获取到读锁的次数；使用低16位表示获取到写锁的线程的可重入次数。\n获取写锁 public void lock() {\rsync.acquire(1);\r}\r// aqs内部实现\rpublic final void acquire(int arg) {\rif (!tryAcquire(arg) \u0026amp;\u0026amp;\racquireQueued(addWaiter(Node.EXCLUSIVE), arg))\rselfInterrupt();\r}\rprotected final boolean tryAcquire(int acquires) {\r/*\r* Walkthrough:\r* 1. If read count nonzero or write count nonzero\r* and owner is a different thread, fail.\r* 2. If count would saturate, fail. (This can only\r* happen if count is already nonzero.)\r* 3. Otherwise, this thread is eligible for lock if\r* it is either a reentrant acquire or\r* queue policy allows it. If so, update state\r* and set owner.\r*/\rThread current = Thread.currentThread();\r// 获取锁状态\rint c = getState();\r// 获取低16位状态，即写锁状态\rint w = exclusiveCount(c);\rif (c != 0) {\r// (Note: if c != 0 and w == 0 then shared count != 0)\r// 如果w==0说明状态值的低16位为0，而AQS状态值不为0，则说明高16位不为0，这暗示已经有线程获取了读锁，所以直接返回false\r// 如果w! =0则说明当前已经有线程获取了该写锁，再看当前线程是不是该锁的持有者，如果不是则返回false\rif (w == 0 || current != getExclusiveOwnerThread())\rreturn false;\rif (w + exclusiveCount(acquires) \u0026gt; MAX_COUNT)\rthrow new Error(\u0026quot;Maximum lock count exceeded\u0026quot;);\r// Reentrant acquire\rsetState(c + acquires);\rreturn true;\r}\r// 锁标志位为0，则没有线程获取到读锁和写锁\rif (writerShouldBlock() ||\r!compareAndSetState(c, c + acquires))\rreturn false;\rsetExclusiveOwnerThread(current);\rreturn true;\r}\r 其中公平锁与非公平锁在writerShouldBlock这里体现\n// 非公平锁实现,抢占式执行CAS尝试获取写锁，获取成功则设置当前锁的持有者为当前线程并返回true，否则返回false 非公平锁，直接返回false，\rfinal boolean writerShouldBlock() {\rreturn false; // writers can always barge\r}\r// 公平锁实现，使用hasQueuedPredecessors来判断当前线程节点是否有前驱节点，如果有则当前线程放弃获取写锁的权限，直接返回false\rfinal boolean writerShouldBlock() {\rreturn hasQueuedPredecessors();\r}\rfinal boolean readerShouldBlock() {\rreturn hasQueuedPredecessors();\r}\r 获取写锁的步骤为:\n  如果读锁和写锁都没有被另一个线程持有，则获取写锁并立即返回，将写锁持有计数设置为 1。\n  如果当前线程已经持有写锁，那么持有计数加一并且该方法立即返回。\n  如果该锁由另一个线程持有，则当前请求写锁的线程会被阻塞挂起。\n  释放写锁 protected final boolean tryRelease(int releases) {\rif (!isHeldExclusively())\rthrow new IllegalMonitorStateException();\rint nextc = getState() - releases;\rboolean free = exclusiveCount(nextc) == 0;\rif (free)\rsetExclusiveOwnerThread(null);\rsetState(nextc);\rreturn free;\r}\r 释放锁，感觉都千篇一律，都是\n 先判断是否当前线程持有该锁 判断可重入次数 如果可重入次数大于0，则可重入次数减一，如果可重入次数等于0则释放锁  获取读锁 public void lock() {\rsync.acquireShared(1);\r}\rpublic final void acquireShared(int arg) {\rif (tryAcquireShared(arg) \u0026lt; 0)\rdoAcquireShared(arg);\r}\rprotected final int tryAcquireShared(int unused) {\r/*\r* Walkthrough:\r* 1. If write lock held by another thread, fail.\r* 2. Otherwise, this thread is eligible for\r* lock wrt state, so ask if it should block\r* because of queue policy. If not, try\r* to grant by CASing state and updating count.\r* Note that step does not check for reentrant\r* acquires, which is postponed to full version\r* to avoid having to check hold count in\r* the more typical non-reentrant case.\r* 3. If step 2 fails either because thread\r* apparently not eligible or CAS fails or count\r* saturated, chain to version with full retry loop.\r*/\rThread current = Thread.currentThread();\rint c = getState();\r// 判断写锁是否被占用\rif (exclusiveCount(c) != 0 \u0026amp;\u0026amp;\rgetExclusiveOwnerThread() != current)\rreturn -1;\r// 获取读锁计数\rint r = sharedCount(c);\rif (!readerShouldBlock() \u0026amp;\u0026amp;\rr \u0026lt; MAX_COUNT \u0026amp;\u0026amp;\rcompareAndSetState(c, c + SHARED_UNIT)) {\rif (r == 0) {\rfirstReader = current;\rfirstReaderHoldCount = 1;\r} else if (firstReader == current) {\rfirstReaderHoldCount++;\r} else {\rHoldCounter rh = cachedHoldCounter;\rif (rh == null || rh.tid != getThreadId(current))\rcachedHoldCounter = rh = readHolds.get();\relse if (rh.count == 0)\rreadHolds.set(rh);\rrh.count++;\r}\rreturn 1;\r}\rreturn fullTryAcquireShared(current);\r}\r 总结 ​\t本节介绍了读写锁ReentrantReadWriteLock的原理，它的底层是使用AQS实现的。ReentrantReadWriteLock巧妙地使用AQS的状态值的高16位表示获取到读锁的个数，低16位表示获取写锁的线程的可重入次数，并通过CAS对其进行操作实现了读写分离，这在读多写少的场景下比较适用。\nStampedLock StampedLock是并发包里面JDK8版本新增的一个锁，该锁提供了三种模式的读写控制，当调用获取锁的系列函数时，会返回一个long型的变量，我们称之为戳记（stamp），这个戳记代表了锁的状态。其中try系列获取锁的函数，当获取锁失败后会返回为0的stamp值。当调用释放锁和转换锁的方法时需要传入获取锁时返回的stamp值。StampedLock提供的三种读写模式的锁分别如下。\n 写锁writeLock：是一个排它锁或者独占锁，某时只有一个线程可以获取该锁，当一个线程获取该锁后，其他请求读锁和写锁的线程必须等待，这类似于ReentrantReadWriteLock的写锁（不同的是这里的写锁是不可重入锁）；当目前没有线程持有读锁或者写锁时才可以获取到该锁。请求该锁成功后会返回一个stamp变量用来表示该锁的版本，当释放该锁时需要调用unlockWrite方法并传递获取锁时的stamp参数。并且它提供了非阻塞的tryWriteLock方法。 悲观读锁readLock：是一个共享锁，在没有线程获取独占写锁的情况下，多个线程可以同时获取该锁。如果已经有线程持有写锁，则其他线程请求获取该读锁会被阻塞，这类似于ReentrantReadWriteLock的读锁（不同的是这里的读锁是不可重入锁）。这里说的悲观是指在具体操作数据前其会悲观地认为其他线程可能要对自己操作的数据进行修改，所以需要先对数据加锁，这是在读少写多的情况下的一种考虑。请求该锁成功后会返回一个stamp变量用来表示该锁的版本，当释放该锁时需要调用unlockRead方法并传递stamp参数。并且它提供了非阻塞的tryReadLock方法。 乐观读锁tryOptimisticRead：它是相对于悲观锁来说的，在操作数据前并没有通过CAS设置锁的状态，仅仅通过位运算测试。如果当前没有线程持有写锁，则简单地返回一个非0的stamp版本信息。获取该stamp后在具体操作数据前还需要调用validate方法验证该stamp是否已经不可用，也就是看当调用tryOptimisticRead返回stamp后到当前时间期间是否有其他线程持有了写锁，如果是则validate会返回0，否则就可以使用该stamp版本的锁对数据进行操作。由于tryOptimisticRead并没有使用CAS设置锁状态，所以不需要显式地释放该锁。该锁的一个特点是适用于读多写少的场景，因为获取读锁只是使用位操作进行检验，不涉及CAS操作，所以效率会高很多，但是同时由于没有使用真正的锁，在保证数据一致性上需要复制一份要操作的变量到方法栈，并且在操作数据时可能其他写线程已经修改了数据，而我们操作的是方法栈里面的数据，也就是一个快照，所以最多返回的不是最新的数据，但是一致性还是得到保障的  总结 StampedLock提供的读写锁与ReentrantReadWriteLock类似，只是前者提供的是不可重入锁。但是前者通过提供乐观读锁在多线程多读的情况下提供了更好的性能，这是因为获取乐观读锁时不需要进行CAS操作设置锁的状态，而只是简单地测试状态。没看懂这个哈哈。\n并发队列 ​\tJDK中提供了一系列场景的并发安全队列。总的来说，按照实现方式的不同可分为阻塞队列和非阻塞队列，前者使用锁实现，而后者则使用CAS非阻塞算法实现。\nConcurrentLinkedQueue 定义 ​\tConcurrentLinkedQueue是线程安全的无界非阻塞队列，其底层数据结构使用单向链表实现，对于入队和出队操作使用CAS来实现线程安全\n​\tConcurrentLinkedQueue内部的队列使用单向链表方式实现，其中有两个volatile类型的Node节点分别用来存放队列的首、尾节点。默认头、尾节点都是指向item为null的哨兵节点。新元素会被插入队列末尾，出队时从队列头部获取一个元素。在Node节点内部则维护一个使用volatile修饰的变量item，用来存放节点的值；next用来存放链表的下一个节点，从而链接为一个单向无界链表。其内部则使用UNSafe工具类提供的CAS算法来保证出入队时操作链表的原子性。\noffer public boolean offer(E e) {\rcheckNotNull(e);\r// 构造新的node节点\rfinal Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;E\u0026gt;(e);\r// 从尾结点开始插入\rfor (Node\u0026lt;E\u0026gt; t = tail, p = t;;) {\rNode\u0026lt;E\u0026gt; q = p.next;\r// 如果q==null说明p是尾结点，则执行插入\rif (q == null) {\r// 使用cas设置p节点的next节点\rif (p.casNext(null, newNode)) {\r// cas成功，说明新增节点已经被放入链表，设置当前节点为尾节点\rif (p != t) // hop two nodes at a time\rcasTail(t, newNode); // Failure is OK.\rreturn true;\r}\r// Lost CAS race to another thread; re-read next\r}\relse if (p == q)\r// 多线程操作时，由于poll操作移除元素后可能会把head变为自引用，重新找新的head\rp = (t != (t = tail)) ? t : head;\relse\r//寻找尾节点\rp = (p != t \u0026amp;\u0026amp; t != (t = tail)) ? t : q;\r}\r}\r ​\t通过原子CAS操作来控制某时只有一个线程可以追加元素到队列末尾。进行CAS竞争失败的线程会通过循环一次次尝试进行CAS操作，直到CAS成功才会返回，也就是通过使用无限循环不断进行CAS尝试方式来替代阻塞算法挂起调用线程。相比阻塞算法，这是使用CPU资源换取阻塞所带来的开销。\n注意：创建队列时头、尾节点指向一个item为null的哨兵节点，第一次执行offer后head指向的是哨兵节点\npoll poll操作是在队列头部获取并移除一个元素，如果队列为空则返回null\npublic E poll() {\r// 1\rrestartFromHead:\r// 2 无限循环\rfor (;;) {\rfor (Node\u0026lt;E\u0026gt; h = head, p = h, q;;) {\r// 3保存当前节点\rE item = p.item;\r// 4当前节点有值则cas变为null\rif (item != null \u0026amp;\u0026amp; p.casItem(item, null)) {\r// 5cas成功则标记当前节点并从链表中移除\rif (p != h) // hop two nodes at a time\rupdateHead(h, ((q = p.next) != null) ? q : p);\rreturn item;\r}\r// 6当前队列为空则返回null\relse if ((q = p.next) == null) {\rupdateHead(h, p);\rreturn null;\r}\r// 7如果当前节点被自引用了，则重新寻找新的队列头节点\relse if (p == q)\rcontinue restartFromHead;\relse\rp = q;\r}\r}\r}\rfinal void updateHead(Node\u0026lt;E\u0026gt; h, Node\u0026lt;E\u0026gt; p) {\rif (h != p \u0026amp;\u0026amp; casHead(h, p))\rh.lazySetNext(h);\r}\r 具体流程分析看书吧。\npoll方法在移除一个元素时，只是简单地使用CAS操作把当前节点的item值设置为null，然后通过重新设置头节点将该元素从队列里面移除，被移除的节点就成了孤立节点，这个节点会在垃圾回收时被回收掉。另外，如果在执行分支中发现头节点被修改了，要跳到外层循环重新获取新的头节点\npeek peek操作是获取队列头部一个元素（只获取不移除），如果队列为空则返回null\npublic E peek() {\r// 1\rrestartFromHead:\rfor (;;) {\rfor (Node\u0026lt;E\u0026gt; h = head, p = h, q;;) {\r// 2\rE item = p.item;\rif (item != null || (q = p.next) == null) {\r// 3\rupdateHead(h, p);\rreturn item;\r}\r// 4\relse if (p == q)\rcontinue restartFromHead;\relse\r// 5\rp = q;\r}\r}\r}\r ​\tPeek操作的代码结构与poll操作类似，不同之处在于少了castItem操作。即peek只获取队列头元素但是并不从队列里将它删除，而poll获取后需要从队列里面将它删除。另外，在第一次调用peek操作时，会删除哨兵节点，并让队列的head节点指向队列里面第一个元素或者null。\nLinkedBlockingQueue 定义 LinkedBlockingQueue是使用独占锁实现的阻塞队列\n​\tLinkedBlockingQueue也是使用单向链表实现的，其也有两个Node，分别用来存放首、尾节点，并且还有一个初始值为0的原子变量count，用来记录队列元素个数。另外还有两个ReentrantLock的实例，分别用来控制元素入队和出队的原子性，其中takeLock用来控制同时只有一个线程可以从队列头获取元素，其他线程必须等待，putLock控制同时只能有一个线程可以获取锁，在队列尾部添加元素，其他线程必须等待。另外，notEmpty是takeLock（出队）的条件变量和notFull是putLock（入队）的条件变量，它们内部都有一个条件队列用来存放进队和出队时被阻塞的线程，其实这是生产者—消费者模型\noffer public boolean offer(E e) {\rif (e == null) throw new NullPointerException();\rfinal AtomicInteger count = this.count;\r// 2,如果当前队列满则丢弃将要放入的元素，然后返回false\rif (count.get() == capacity)\rreturn false;\rint c = -1;\rNode\u0026lt;E\u0026gt; node = new Node\u0026lt;E\u0026gt;(e);\rfinal ReentrantLock putLock = this.putLock;\r// 3 获取独占锁\rputLock.lock();\rtry {\r// 4 队列不满则进入队列，并递增元素计数\rif (count.get() \u0026lt; capacity) {\renqueue(node);\rc = count.getAndIncrement();\r// 5\rif (c + 1 \u0026lt; capacity)\r// 唤醒入队线程\rnotFull.signal();\r}\r} finally {\r// 6 释放锁\rputLock.unlock();\r}\r// 7\rif (c == 0)\rsignalNotEmpty();\r// 8\rreturn c \u0026gt;= 0;\r}\r// 唤醒出队线程\rprivate void signalNotEmpty() {\rfinal ReentrantLock takeLock = this.takeLock;\rtakeLock.lock();\rtry {\rnotEmpty.signal();\r} finally {\rtakeLock.unlock();\r}\r}\r ​\toffer方法通过使用putLock锁保证了在队尾新增元素操作的原子性。另外，调用条件变量的方法前一定要记得获取对应的锁，并且注意进队时只操作队列链表的尾节点。\nput public void put(E e) throws InterruptedException {\rif (e == null) throw new NullPointerException();\r// Note: convention in all put/take/etc is to preset local var\r// holding count negative to indicate failure unless set.\rint c = -1;\rNode\u0026lt;E\u0026gt; node = new Node\u0026lt;E\u0026gt;(e);\rfinal ReentrantLock putLock = this.putLock;\rfinal AtomicInteger count = this.count;\rputLock.lockInterruptibly();\rtry {\r/*\r* Note that count is used in wait guard even though it is\r* not protected by lock. This works because count can\r* only decrease at this point (all other puts are shut\r* out by lock), and we (or some other waiting put) are\r* signalled if it ever changes from capacity. Similarly\r* for all other uses of count in other wait guards.\r*/\rwhile (count.get() == capacity) {\rnotFull.await();\r}\renqueue(node);\rc = count.getAndIncrement();\rif (c + 1 \u0026lt; capacity)\rnotFull.signal();\r} finally {\rputLock.unlock();\r}\rif (c == 0)\rsignalNotEmpty();\r}\r ThreadPoolExecutor 定义 ​\t线程池主要解决两个问题：一是当执行大量异步任务时线程池能够提供较好的性能。在不使用线程池时，每当需要执行异步任务时直接new一个线程来运行，而线程的创建和销毁是需要开销的。线程池里面的线程是可复用的，不需要每次执行异步任务时都重新创建和销毁线程。二是线程池提供了一种资源限制和管理的手段，比如可以限制线程的个数，动态新增线程等。每个ThreadPoolExecutor也保留了一些基本的统计数据，比如当前线程池完成的任务数目等。\nExecutors其实是个工具类，里面提供了好多静态方法，这些方法根据用户选择返回不同的线程池实例。ThreadPoolExecutor继承了AbstractExecutorService，成员变量ctl是一个Integer的原子变量，用来记录线程池状态和线程池中线程个数，类似于ReentrantReadWriteLock使用一个变量来保存两种信息。其中高3位用来表示线程池状态，后面29位用来记录线程池线程个数。\n线程池状态含义如下：\n  RUNNING：接受新任务并且处理阻塞队列里的任务。\n  SHUTDOWN：拒绝新任务但是处理阻塞队列里的任务。\n  STOP：拒绝新任务并且抛弃阻塞队列里的任务，同时会中断正在处理的任务。\n  TIDYING：所有任务都执行完（包含阻塞队列里面的任务）后当前线程池活动线程数为0，将要调用terminated方法。\n  TERMINATED：终止状态。terminated方法调用完成以后的状态。\n  线程池状态转换列举如下：\n  RUNNING -\u0026gt; SHUTDOWN ：显式调用shutdown（）方法，或者隐式调用了finalize（）方法里面的shutdown（）方法。\n  RUNNING或SHUTDOWN）-\u0026gt; STOP ：显式调用shutdownNow（）方法时。\n  SHUTDOWN -\u0026gt; TIDYING ：当线程池和任务队列都为空时。\n  STOP -\u0026gt; TIDYING ：当线程池为空时。\n  TIDYING -\u0026gt; TERMINATED：当terminated（）hook方法执行完成时。\n  线程池参数如下：\n  corePoolSize：线程池核心线程个数。\n  workQueue：用于保存等待执行的任务的阻塞队列，比如基于数组的有界ArrayBlockingQueue、基于链表的无界LinkedBlockingQueue、最多只有一个元素的同步队列SynchronousQueue及优先级队列PriorityBlockingQueue等。\n  maximunPoolSize：线程池最大线程数量。\n  ThreadFactory：创建线程的工厂。\n  RejectedExecutionHandler：饱和策略，当队列满并且线程个数达到maximunPoolSize后采取的策略，比如AbortPolicy（抛出异常）、CallerRunsPolicy（使用调用者所在线程来运行任务）、DiscardOldestPolicy（调用poll丢弃一个任务，执行当前任务）及DiscardPolicy（默默丢弃，不抛出异常）\n  keeyAliveTime：存活时间。如果当前线程池中的线程数量比核心线程数量多，并且是闲置状态，则这些闲置的线程能存活的最大时间。\n  TimeUnit：存活时间的时间单位。\n实际配置：\n  @Bean(\u0026quot;httpWorkThreadPool\u0026quot;)\rpublic ThreadPoolTaskExecutor flowThreadPool(){\rThreadPoolTaskExecutor threadPoolTaskExecutor = new ThreadPoolTaskExecutor();\r// 线程池核心线程个数\rthreadPoolTaskExecutor.setCorePoolSize(threadPoolTaskProperties.getCorePoolSize());\r// 线程池最大线程数量\rthreadPoolTaskExecutor.setMaxPoolSize(threadPoolTaskProperties.getMaxPoolSize());\r// 阻塞队列大小\rthreadPoolTaskExecutor.setQueueCapacity(threadPoolTaskProperties.getQueueCapacity());\r// 饱和策略 使用调用者所在线程来运行任务\rthreadPoolTaskExecutor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());\r// 前缀\rthreadPoolTaskExecutor.setThreadNamePrefix(threadPoolTaskProperties.getThreadNamePrefix());\r// 存活时间。如果当前线程池中的线程数量比核心线程数量多，并且是闲置状态，则这些闲置的线程能存活的最大时间\rthreadPoolTaskExecutor.setKeepAliveSeconds(threadPoolTaskProperties.getKeepAliveSeconds());\rthreadPoolTaskExecutor.initialize();\rthreadPoolTaskProperties.printExecutorInfo(\u0026quot;httpWorkThreadPool\u0026quot;);\rreturn threadPoolTaskExecutor;\r}\r 线程池类型如下：\n newFixedThreadPool ：创建一个核心线程个数和最大线程个数都为nThreads的线程池，并且阻塞队列长度为Integer.MAX_VALUE。keeyAliveTime=0说明只要线程个数比核心线程个数多并且当前空闲则回收。 newSingleThreadExecutor：创建一个核心线程个数和最大线程个数都为1的线程池，并且阻塞队列长度为Integer.MAX_VALUE。keeyAliveTime=0说明只要线程个数比核心线程个数多并且当前空闲则回收。 newCachedThreadPool ：创建一个按需创建线程的线程池，初始线程个数为0，最多线程个数为Integer.MAX_VALUE，并且阻塞队列为同步队列。keeyAliveTime=60说明只要当前线程在60s内空闲则回收。这个类型的特殊之处在于，加入同步队列的任务会被马上执行，同步队列里面最多只有一个任务。  execute execute方法的作用是提交任务command到线程池进行执行，ThreadPoolExecutor的实现实际是一个生产消费模型，当用户添加任务到线程池时相当于生产者生产元素，workers线程工作集中的线程直接执行任务或者从任务队列里面获取任务时则相当于消费者消费元素。\npublic void execute(Runnable command) {\rif (command == null)\rthrow new NullPointerException();\r/*\r* Proceed in 3 steps:\r*\r* 1. If fewer than corePoolSize threads are running, try to\r* start a new thread with the given command as its first\r* task. The call to addWorker atomically checks runState and\r* workerCount, and so prevents false alarms that would add\r* threads when it shouldn't, by returning false.\r*\r* 2. If a task can be successfully queued, then we still need\r* to double-check whether we should have added a thread\r* (because existing ones died since last checking) or that\r* the pool shut down since entry into this method. So we\r* recheck state and if necessary roll back the enqueuing if\r* stopped, or start a new thread if there are none.\r*\r* 3. If we cannot queue task, then we try to add a new\r* thread. If it fails, we know we are shut down or saturated\r* and so reject the task.\r*/\r// 获取当前线程池的状态+线程个数变量的组合值\rint c = ctl.get();\r// 当前线程池中线程个数是否小于corePoolSize，小于则开启新线程运行\rif (workerCountOf(c) \u0026lt; corePoolSize) {\rif (addWorker(command, true))\rreturn;\rc = ctl.get();\r}\r// 如果线程池处于running状态，则添加任务到阻塞队列\rif (isRunning(c) \u0026amp;\u0026amp; workQueue.offer(command)) {\rint recheck = ctl.get();\rif (! isRunning(recheck) \u0026amp;\u0026amp; remove(command))\rreject(command);\relse if (workerCountOf(recheck) == 0)\raddWorker(null, false);\r}\relse if (!addWorker(command, false))\rreject(command);\r}\r 总体步骤为：\n 如果当前线程池中线程个数小于corePoolSize，会向workers里面新增一个核心线程（core线程）执行该任务 当当前线程池中线程个数大于等于corePoolSize时,如果当前线程池处于RUNNING状态则添加当前任务到任务队列。如果在非RUNNING状态下则抛弃新任务。 如果向任务队列添加任务成功，则对线程池状态进行二次校验，这是因为添加任务到任务队列后，执行代码（4.2）前有可能线程池的状态已经变化了。这里进行二次校验，如果当前线程池状态不是RUNNING了则把任务从任务队列移除，移除后执行拒绝策略；如果二次校验通过，则重新判断当前线程池里面是否还有线程，如果没有则新增一个线程 如果添加任务失败，则说明任务队列已满，那尝试新开启线程来执行该任务，如果当前线程池中线程个数\u0026gt;maximumPoolSize则执行拒绝策略  addWorker private boolean addWorker(Runnable firstTask, boolean core) {\rretry:\rfor (;;) {\rint c = ctl.get();\rint rs = runStateOf(c);\r// Check if queue empty only if necessary.\rif (rs \u0026gt;= SHUTDOWN \u0026amp;\u0026amp;\r! (rs == SHUTDOWN \u0026amp;\u0026amp;\rfirstTask == null \u0026amp;\u0026amp;\r! workQueue.isEmpty()))\rreturn false;\rfor (;;) {\rint wc = workerCountOf(c);\rif (wc \u0026gt;= CAPACITY ||\rwc \u0026gt;= (core ? corePoolSize : maximumPoolSize))\rreturn false;\rif (compareAndIncrementWorkerCount(c))\rbreak retry;\rc = ctl.get(); // Re-read ctl\rif (runStateOf(c) != rs)\rcontinue retry;\r// else CAS failed due to workerCount change; retry inner loop\r}\r}\rboolean workerStarted = false;\rboolean workerAdded = false;\rWorker w = null;\rtry {\rw = new Worker(firstTask);\rfinal Thread t = w.thread;\rif (t != null) {\rfinal ReentrantLock mainLock = this.mainLock;\rmainLock.lock();\rtry {\r// Recheck while holding lock.\r// Back out on ThreadFactory failure or if\r// shut down before lock acquired.\rint rs = runStateOf(ctl.get());\rif (rs \u0026lt; SHUTDOWN ||\r(rs == SHUTDOWN \u0026amp;\u0026amp; firstTask == null)) {\rif (t.isAlive()) // precheck that t is startable\rthrow new IllegalThreadStateException();\rworkers.add(w);\rint s = workers.size();\rif (s \u0026gt; largestPoolSize)\rlargestPoolSize = s;\rworkerAdded = true;\r}\r} finally {\rmainLock.unlock();\r}\rif (workerAdded) {\rt.start();\rworkerStarted = true;\r}\r}\r} finally {\rif (! workerStarted)\raddWorkerFailed(w);\r}\rreturn workerStarted;\r}\r 第一部分双重循环的目的是通过CAS操作增加线程数\n第二部分主要是使用全局的独占锁来把新增的Worker添加到工作集workers中,如果新增工作线程成功，则启动工作线程\n总结 ​\t线程池巧妙地使用一个Integer类型的原子变量来记录线程池状态和线程池中的线程个数。通过线程池状态来控制任务的执行，每个Worker线程可以处理多个任务。线程池通过线程的复用减少了线程创建和销毁的开销。\n原理其实就是，当用户添加任务到线程池，通过判断看是直接添加到核心线程workers中，还是添加到任务队列，还是队列已满执行拒绝策略，workers线程池则执行线程。\n","id":1,"section":"posts","summary":"Java 并发编程 ​ 并发编程之美的笔记 什么是线程 ​ 进程是操作系统资源分配的最小单位，而线程是CPU任务调度和执行的最小单位 具体参考 https://blog.csdn.net/ThinkWon/article/details/102021274 五状态进程的主要","tags":["Java并发"],"title":"Java 并发编程","uri":"https://wzgl998877.github.io/2022/01/java-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","year":"2022"},{"content":"Java 编程思想学习 第1章 对象导论 好像看不下去，。。。\n第2章 一切都是对象   用引用操作对象：每种编程语言都有自己的操纵内存中元素的方式。java中操纵的标识符是对象的一个“引用”，可以理解为用遥控器（引用）来操作电视机（对象），只要握住这个遥控器就能保持与电视机的连接，没有电视机，遥控器也可以存在，也就是说你拥有一个引用，并不一定需要有对象与他相关联。\n  存储到什么地方\n  寄存器：这是最快的存储区，位于处理器内部数量极其有限，不能直接控制\n  堆栈：位于通用 RAM（随机访问存储器）中，但通过堆栈指针可以从处理器那里获得直接支持，堆栈指针若向下移动则分配新的内存，向上移动则释放那些内存，创建程序时，Java 系统必须知道存储在堆栈内所有项的确切生命周期，所以虽然某些 Java 数据存储于堆栈中，特别是对象引用，但Java对象并不存储于其中\n  堆:一种通用的内存池（位于 RAM 中），用于存放所有的 Java 对象，相对于堆栈，编译器不需要知道存储的数据在堆里存活多久，需要一个对象时，只需要 new 一个对象，便会自动在堆里进行存储分配\n  常量存储：常量值通常被直接存放在程序代码内部，这样做是安全的，因为它们永远不会被改变\n  非 RAM 存储：如果数据完全存活于程序之外，那么它可以不受程序的任何控制，在程序没有运行时也可以存在，典型例子流对象和持久化对象，流对象转化为字节流，通常被发送给另一台机器，持久化对象被存放于磁盘上\n    特例：基本类型。在程序设计中经常要用到一系列类型，它们需要特殊对待，可以把它们想象成基本类型，之所以特殊对待，是因为 new 将对象存储在堆中，故用 new 创建一个对象特别是小的简单的变量，往往不是很有效，因此对于这些类型，Java 采用了和 c 相同的方法，也就是说不用 new 来创建变量，而是创建一个并非是引用的自动变量，这个变量直接存储值，并置于堆栈中，因此更加高效。Java 要确定每种基本类型所占存储空间的大小，它们的大小并不像其他大多数语言那样随机器硬件架构的变化而变化，这种所占存储空间大小的不变性是 Java 程序比其他程序更具有可移植性的原因之一。但boolean类型所占存储空间的大小没有明确指定，仅定义为能够取字面值true或false\n  基本成员默认值。 若类的某个成员是基本数据类型，即使没有进行初始化，Java 也会确保它获得一个默认值\n   基本类型 默认值     boolean false   char \u0026lsquo;\\uoooo\u0026rsquo;(null)   byte (byte)0   short (short)0   int 0   long oL   float 0.0f   double 0.0d      static 关键字。当声明一个事物是 static 时，就意味着这个域或者方法不会与包含它的那个类的任何对象实例关联在一起，所以，即使从未创建某个类的任何对象，也可以调用其 static 方法或访问其 static 域，使用类名是引用 static 变量的首选，这不仅强调变量的 static 结构，而且还为编译器进行优化提供了更好的机会，尽管当 static 作用于某个字段时，肯定会改变数据创建的方式（因为一个 static 字段对于每个类来说都只有一份存储空间，而非 static 字段是每一个对象就有一个存储空间）\n  第3章 操作符   赋值操作符=，它的意思是取右边的值复制给左边，在为对象赋值时，我们真正操作的是对对象的引用，所以倘若将一个对象赋值给另一个对象，实际上是将引用从一个地方复制到另一个地方，这意味着若对对象使用c=d，那么c和d都将指向原本d指向的那个对象，此时改变c属性的值，d中属性也会发生变化（指向同一个对象）\npackage com.zt.activemq_springboot.config;\rpublic class Example {\rint i;\rpublic int getI() {\rreturn i;\r}\rpublic void setI(int i) {\rthis.i = i;\r}\r}\r@Test\rvoid test9(){\rExample a=new Example();\rExample b=new Example();\ra.setI(1);\rb.setI(2);\rSystem.out.println(\u0026quot;a: \u0026quot;+a.getI()+\u0026quot; b: \u0026quot;+b.getI());\ra=b;\rSystem.out.println(\u0026quot;a: \u0026quot;+a.getI()+\u0026quot; b: \u0026quot;+b.getI());\ra.setI(3);\rSystem.out.println(\u0026quot;a: \u0026quot;+a.getI()+\u0026quot; b: \u0026quot;+b.getI());\rint i=0;\rf(i);\rd(a);\rSystem.out.println(\u0026quot;常量： \u0026quot;+i+\u0026quot; 对象：\u0026quot;+a.getI());\r}\rstatic void f(int i){\ri=4;\r}\rstatic void d(Example example){\rexample.setI(4);\r}\r//结果\ra: 1 b: 2\ra: 2 b: 2\ra: 3 b: 3\r常量： 0 对象：4\r   自动递增和自动递减。++ 就意味则增加一个单位，\u0026ndash; 就意味着减少一个单位，( ++a , \u0026ndash;a )先执行运算再生成值，( a++, a\u0026ndash; )先生成值，再执行运算\n  逻辑操作符：与（\u0026amp;\u0026amp;）、或（||) 、非（ ！），当时用逻辑操作符时，会出现短路现象，即一旦能够明确无误地确定整个表达式的值后面就不再计算表达式余下部分了。\n  按位操作符：按位操作符是用来操作整数基本数据类型中的单个bit的，即二进制位，按位操作符会对两个参数中对应的位执行布尔代数运算，并最终生成一个结果，按位与（\u0026amp;）、按位或（|）、按位非（~），按位异或（^）,按位操作符与逻辑操作符有同样的效果，只是不会短路\n  第4章 控制执行流程 noting\n第5章 初始化与清理   方法重载。构造器 (构造方法) 是强制重载方法名的一个原因，构造器的名字已经由类名所决定，所以就只能有一个构造器名，那么如果想要多种方式创建一个对象该怎么办呢？ 为了让方法名相同而形式参数不同的构造器同时存在，必须要有方法重载。\n 区分重载方法。通过参数列表区分，为什么不能以返回值区分重载方法？因为有时你并不关心方法的返回值，你想要的是方法调用的其他效果。    this 关键字。如果有同一个类型的两个对象，分别是 a 和 b ，那么如何才能让这两个对象都能调用 peel() 方法呢？\npackage com.zt.activemq_springboot.config;\rpublic class Example {\rvoid peel(int i){}\r}\r@Test\rvoid test13(){\rExample a=new Example();\rExample b=new Example();\ra.peel(1);\rb.peel(2);\r}\r//在java中他暗自把所操作对象的引用作为参数传递给peel();\r//即java内部为\rExample.peel(a,1)\rExample.peel(b,2)\r 如果要在方法的内部获得对当前对象的引用，由于这个引用是由编译器 “偷偷” 传入的，所以没有标识符可以用，为此有个专门的关键字： this。this关键字只能在方法内部使用 ,表示对 “调用方法的那个对象” 的引用 但是如果在方法内部调用同一个类的另一个方法，就不必使用 this，直接调用即可，这是因为方法中的this引用会自动应用于同一个类中的其他方法。\n  static 的含义。static 方法就是没有this的方法。 在 static 方法的内部不能调用非静态方法，反过来则可以。\n  清理：终结处理和垃圾回收。一旦垃圾回收器准备好释放对象占用的存储空间，将首先调用其 finalize() 方法，并且在下一次垃圾回收动作发生时，才会真正回收对象占用的内存。与 c++ 相比，Java 中：对象可能不被垃圾回收；垃圾回收并不等于析构 。这意味着在你不再需要某个对象之前，如果必须执行某些动作，那么你得自己去做，要做类似的清理工作，必须自己动手创建一个执行清理工作的普通方法。例如，假设某个对象在创建过程中会将自己绘制到屏幕上，如果不是明确地从屏幕上将其檫除，它有可能永远得不到清理，想要将其檫除应该定义一个檫除的普通方法，如果在 finalize() 中加入某种檫除的话，只有当垃圾回收发生时（不能保证一定会发生）finalize() 得到了调用图像才会被檫除。所以不该将 finalize()作为通用的清理方法。\n  finalize() 的用途何在。垃圾回收只与内存有关 也就是说，使用垃圾回收器的唯一原因是为了回收程序不再使用的内存。无论对象是如何创建的（对象中含有其他对象或者是其他情况）垃圾回收器都会负责释放对象所占据的所有内存。这就将 finalize() 的需求限制到一种特殊情况，即通过某种创建对象方式以外的方式为对象分配了存储空间，这种情况主要发生在使用 “本地方法” 的情况下，本地方法是一种在 Java 中调用非 Java 代码的方式，在非 Java 代码中，也许会调用 C 的 malloc() 函数系列来分配存储空间，而且除非调用了 free() 方法，否则存储空间得不到释放，从而造成内存泄漏，当然 free() 是非 Java 代码，所以需要在 finalize() 中用 “本地方法” 调用。\n  垃圾回收器如何工作。有点复杂。。。。\n  初始化顺序。在类的内部，变量定义的先后顺序决定了初始化的顺序。即使变量定义散布于方法定义间，它们仍旧会在任何方法（包括构造方法）被调用之前得到初始化。\n  静态数据的初始化。static 关键字不能应用于局部变量，因此它只能作用于域。如果一个域是静态的基本类型域，且没有初始化，那么它就会获得基本类型的标准初值，如果它是一个对象的引用，那么默认初始化值则为 null，静态初始化只有在必要时刻才会进行，并且静态初始化只会进行一次，在首次生成这个类的一个对象时或者首次访问属于这个类的静态变量或方法时。\n初始化的顺序是 父类静态变量 \u0026ndash;\u0026gt; 子类静态变量 \u0026ndash;\u0026gt; 父类实例变量 \u0026ndash;\u0026gt; 子类实例变量 \u0026ndash;\u0026gt; 父类构造函数 \u0026ndash;\u0026gt; 子类构造函数\n  对象的创建过程，假设有个Dog类\n  即使没有显示地使用 static 关键字，构造器实际上也是静态方法。当首次创建类型为 Dog 的对象时（构造器可以看成静态方法），或者 Dog 类的静态方法/静态域首次被访问时 Java 解释器必须查找类路径，以定位 Dog.class 文件。\n  然后载入 Dog.class (这将创建一个 Class 对象)，有关静态初始化的所有动作都会执行。因此，静态初始化只在 Class 对象首次加载的时候进行一次。\n  当用 new Dog() 创建对象时，首先在堆上为 Dog 对象分配足够的存储空间。\n  这块存储空间将会被清零，这就自动地将 Dog 对象中的所有基本类型数据都设置成了默认值，而引用则被设置成了 null。\n  执行所有出现于字段定义处的初始化动作。\n  执行构造器。\n    数组初始化。数组只是相同类型的、用一个标识符名称封装到一起的一个对象序列或基本类型数据序列。\nvoid test14(){\r// 这两种是等价的\rint[] a=new int[]{1,2,3};\rint[] a1={1,2,3};\r}\r 可变参数列表，应用于参数个数或类型未知的场合。\n@Test\rvoid test14(){\rprintArray(1,2,3);\rprintArray(\u0026quot;可变\u0026quot;,\u0026quot;参数\u0026quot;,\u0026quot;列表\u0026quot;);\r}\r/**\r*\r* @param args 类型加... 就代表了可变参数列表,可以使用任何类型的参数，包括基本类型\r*/\rstatic void printArray(Object... args){\rfor(Object object:args){\rSystem.out.print(object+\u0026quot; \u0026quot;);\r}\r}\r   枚举类。在你创建 enum 时，编译器会自动添加一些有用的特性。例如，它会创建 toString() 方法，以便你可以很方便地显示某个 enum 实例的name，编译器还会创建 ordinal() 方法，用来表示某个特定 enum 常量的声明顺序，以及 static values() 方法，用来按照 enum 常量的声明顺序，产生由这些常量值构成的数组。\npublic enum Fruit {\rAPPLE,BANANA,PEAR;\r}\r@Test\rvoid test16(){\rSystem.out.println(Fruit.APPLE);//默认的toString 打印出他的name\rfor(Fruit fruit:Fruit.values()){\rSystem.out.println(fruit+\u0026quot;, ordinal \u0026quot;+fruit.ordinal());\r}\r}\r/**\r结果\rAPPLE\rAPPLE, ordinal 0\rBANANA, ordinal 1\rPEAR, ordinal 2\r**/\r   第6章 访问权限控制   当编写一个 Java 源代码文件时，此文件通常被称为编译单元（转译单元）。每个编译单元必须有后缀名 .java,在编译单元内可以有一个 public 类，该类的名称必须与文件的名称相同，每一个编译单元只能有一个 public 类。\n  当编译一个 .java 文件时，在 .java 文件中的每个类都会有一个后缀名为 .class 的输出文件。\n  第7章 复用类 tips: foreach 的一些注意事项，结论：foreach 循环迭代数组元素时，不能改变“基本数组类型元素”的值，因此不要对 foreach 的循环变量进行赋值，引用类型数组（除 String 类型）可以改变。 举例：\n​\tforeach 不可以改变变量，即使使用集合存变量也不可以，foreach 循环中，是把容器中的数据交给了\t那个element相当于一个临时变量，系统会把数组元素依次赋给这个临时变量，而这个临时变量并不是\t数组元素，它只是保存了数组元素的值。因此当容器中装的是变量时，foreach是改变不了元数据的，\t想改变只能通过for循环\n@Test\rvoid test15(){\rint[] a={1,2,3};\rfor(int i:a){\ri++;\r}\rfor(int i:a){\rSystem.out.print(i+\u0026quot; \u0026quot;);\r}\rSystem.out.println();\r}\r//结果\r//1 2 3  ​\tforeach可以改变对象的值，但不能删除或添加对象（ foreach 循环中，是把容器中的数据交给了那个element，当容器中装的是对象时，对象的赋值（赋的是引用，即给的是原对象所在的地址））\n为什么不能删除或者添加变量，因为每次进入foreach是，就会调用java.util.LinkedList.Listltr.next()方法，方法对集合的长度进行了判断，所以会出现异常。\n@Test\rvoid test15(){\rList\u0026lt;Value\u0026gt; list=new ArrayList();\rlist.add(new Value(1));\rlist.add(new Value(2));\rlist.add(new Value(3));\rfor(Value value:list){\rvalue.setI(value.getI()+1);\r}\rfor (Value value:list){\rSystem.out.print(value.getI()+\u0026quot; \u0026quot;);\r}\r//结果\r//2 3 4\rfor(Value value:list){\rlist.remove(value);//报ConcurrentModificationException错\r}\r}\r   final 关键字。通常它指的是“这是无法改变的”，一个既是 static 又是 final 的 域只占据一段不能被改变的存储空间。\n final 数据。对于基本类型，final 使数值恒定不变；而对于对象，final 使引用恒定不变，一旦引用被初始化指向一个对象，就无法再把它改为指向另一个对象，然而，对象其自身却是可以被修改的，这一限制同样适用于数组，它也是对象。  package com.zt.activemq_springboot.config;\rimport java.util.Random;\rpublic class FinalData {\rprivate static Random random=new Random(47);\rprivate String id;\rpublic FinalData(String id){\rthis.id=id;\r}\rprivate final int valueOne=9;\rprivate static final int ValueTwo=99;\rpublic static final int ValueThree=39;\rprivate final int i4= random.nextInt(20);\rstatic final int INT_5=random.nextInt(20);\rprivate Value v1=new Value(11);\rprivate final Value v2=new Value(22);\rpublic static final Value VAL_3=new Value(33);\rprivate final int[] a={1,2,3};\r@Override\rpublic String toString(){\rreturn id+\u0026quot;:\u0026quot;+\u0026quot;i4:\u0026quot;+i4+\u0026quot;,INT_5=\u0026quot;+INT_5;\r}\rpublic static void main(String[] args) {\rFinalData fd1=new FinalData(\u0026quot;fd1\u0026quot;);\r// final的基本类型不能改变\r// fd1.valueOne++;\rfd1.v2.i++;\rfd1.v1=new Value(9);\rfor (int i=0;i\u0026lt;fd1.a.length;i++) {\rfd1.a[i]++;\r}\rfor(int i:fd1.a) {\rSystem.out.print(i+\u0026quot; \u0026quot;);\r}\rSystem.out.println();\rSystem.out.println(fd1.v2.i);\rSystem.out.println(fd1.toString());\rFinalData fd2=new FinalData(\u0026quot;fd2\u0026quot;);\rSystem.out.println(fd1.toString());\rSystem.out.println(fd2.toString());\r}\r}\r/**\r结果\r2 3 4 证明final类型的数组，值可以改变\r23\rfd1:i4:15,INT_5=18 因为i4 是final 的所以是不变的，只针对于当前对象，而对于INT_5是static的所以只会初始化一次所以不变，static可以参考第5章\rfd1:i4:15,INT_5=18\rfd2:i4:13,INT_5=18\r**/\r 对于 valueOne，ValueTwo 都是带有编译时数值的 final 基本类型，称为编译期常量，对于 ValueThree 定义为 public ，则可以被用于包之外；定义为 static，强调只有一份；定义为 final 说明是个常量。我们不能因为某数据是 final 的就认为在编译时可以知道它的值\n final 方法。使用 final 方法的原因：1、把方法锁定，以防任何继承类修改它的含义；2、出于效率，现在已经慢慢不用这种方式提高效率了。类中所有的 private 方法都隐式地指定为是 final 的。final 类 就表明了你不打算继承该类，而且也不允许别人这么做。final 类中的所有方法都隐式指定为 final 的。\n  初始化及类的加载。因为 Java 中的所有事物都是对象，每个类的编译代码都存在于它自己的独立文件中。该文件只在需要使用程序代码时 才会被加载。可以说，类的代码在初次使用时才加载，这通常是指加载发生于创建类的第一个对象之时，但是当访问 static 域 或方法时，也会发生加载，**初次使用之处也是 static 初始化发生之处。所有的 static 对象和 static 代码段都会在加载时，依程序的顺序（即，定义类时的书写顺序）而依次初始化。当然定义为 static 的东西只会被初始化一次。**构造器也是 static 方法，所以准确讲类是在其任何 static 成员被访问时加载的。\n  初始化全过程。\npackage com.zt.activemq_springboot.config;\rclass Insect {\rprivate int i=9;//4初始化父类实例变量，此时i=9，而j还是0\rprotected int j;\rInsect(){//5执行父类构造方法\rSystem.out.println(\u0026quot;我是父类构造方法\u0026quot;);\rSystem.out.println(\u0026quot;i= \u0026quot;+i+\u0026quot;, j= \u0026quot;+j);\rj=39;\r}\rprivate static int x1=printInit(\u0026quot;我是父类静态变量\u0026quot;);//1父类static初始化\rstatic int printInit(String s){\rSystem.out.println(s);\rreturn 47;\r}\r}\rpublic class Bettle extends Insect{\rprivate int k=printInit(\u0026quot;我是子类变量\u0026quot;);//6初始化子类实例变量\rpublic Bettle(){//7执行子类构造方法\rSystem.out.println(\u0026quot;我是子类构造方法\u0026quot;);\rSystem.out.println(\u0026quot;k= \u0026quot;+k);\rSystem.out.println(\u0026quot;j= \u0026quot;+j);\r}\rprivate static int x2=printInit(\u0026quot;我是子类静态变量\u0026quot;);//2 子类static初始化\r//3 将所有基本类型设为默认值，对象引用被设为null，这里是k，j，i都被初始化为0\rpublic static void main(String[] args) {\rSystem.out.println(\u0026quot;请开始你的表演\u0026quot;);\rBettle b=new Bettle();\r}\r}\r/**\r结果\r我是父类静态变量\r我是子类静态变量\r请开始你的表演\r我是父类构造方法\ri= 9, j= 0\r我是子类变量\r我是子类构造方法\rk= 47\rj= 39\r**/\r     第8章 多态   将一个方法调用同一个方法主体关联起来被称为绑定，若在程序执行前进行绑定，叫前期绑定，后期绑定：在运行时根据对象的类型进行绑定，后期绑定也叫做动态绑定或运行时绑定 编译器一直不知道对象的类型，但是方法调用机制能找到正确的方法。Java 中除了 static 方法和 final 方法（private 方法属于final方法）之外，所有方法都是后期绑定。\n  覆盖私有方法。由于 private 方法被自动认为就是一个全新的方法，而且对导出类是屏蔽的，如果在子类中覆盖 private 方法此时此方法就是一个全新的方法,\n如果某个方法是静态的，它的行为就不具有多态性。\n  通过组合和继承方法来创建新类时，永远不必担心对象的清理问题，子对象通常都会留给垃圾回收器进行处理，所以万一某个子对象要依赖于其他对象，销毁的顺序应该和初始化顺序相反，对于字段，则意味着于声明的顺序相反，对于基类应该先对其导出类进行清理然后才是基类。\n  第 9章 接口   包含抽象方法的类叫做抽象类。如果一个类包含一个或多个抽象方法，该类必须被限定为抽象的。从一个抽象类继承，并想创建该新类的对象，那么就必须为基类中的所有抽象方法提供方法定义。如果不这样做，那么导出类也是抽象类，抽象类可以不包含抽象方法。\n  interface 这个关键字产生一个完全抽象的类，没有提供任何具体实现，接口被用来建立类与类之间的协议。接口是实现多重继承的途径。\n  生成遵循某个接口的对象的典型方式就是工厂方法设计模式\n  第10章 内部类   可以将一个类的定义放在另一个类的定义内部，这就是内部类。内部类他能访问其外围对象的所有成员。当某个外围类的对象创建了一个内部类对象时，此内部类对象必定会秘密的捕获一个指向那个外围类对象的引用。在拥有外部类对象之前是不可能创建内部类对象的，这是因为内部类对象会暗暗的连接到创建它的外部类对象上，但是如果是静态内部类，则不需要对外部类对象的引用。\n  在方法的作用域内创建一个完整的类，称为局部内部类：\n//用到的类\rpublic class Wrapping {\rprivate int i;\rpublic Wrapping(int x){ i = x ;}\rpublic int value(){ return i;}\r}\rpublic interface Destination {\rString readLabel();\r}\rpublic interface Contents {\rint value();\r}\r public class InnerClass {\rpublic Destination destination(String s){\rclass PDestionation implements Destination{\rprivate String label;\rprivate PDestionation(String whereTo){\rlabel = whereTo;\r}\r@Override\rpublic String readLabel(){return label;}\r}\rreturn new PDestionation(s);\r}\rpublic static void main(String[] args) {\rInnerClass p = new InnerClass();\rDestination d = p.destination(\u0026quot;bob\u0026quot;);\rSystem.out.println(d.readLabel());\r}\r}\r PDestionation 是 destination 方法的一部分，而不是类的一部分，所以在方法外不能访问该类。\n  匿名内部类，将返回值的生成与表示这个返回值的类的定义结合在一起\n  package com.zt.activemq_springboot;\r/**\r* @author zhengtao\r* @description 内部类测试\r* @date 2020/10/13\r*/\rpublic class InnerClass {\r// 匿名内部类\rpublic Contents contents(){\rreturn new Contents() {\rprivate int i=11;\r@Override\rpublic int value() {\rreturn i;\r}\r};\r}\r// 相当于以下两段代码\rclass Mycontents implements Contents{\rprivate int i=11;\r@Override\rpublic int value() {\rreturn i;\r}\r}\rpublic Contents contents1(){\rreturn new Mycontents();\r}\rpublic static void main(String[] args) {\rInnerClass p = new InnerClass();\rContents c = p.contents();\rSystem.out.println(c.value());\rDestination d = p.destination(\u0026quot;bob\u0026quot;);\rSystem.out.println(d.readLabel());\r}\r}\r 有参数的构造器使用匿名内部类\npackage com.zt.activemq_springboot;\r/**\r* @author zhengtao\r* @description 内部类测试\r* @date 2020/10/13\r*/\rpublic class InnerClass {\rpublic Wrapping wrapping(int x){\rreturn new Wrapping(x){\r@Override\rpublic int value(){\rreturn super.value()*10;\r}\r};\r}\rpublic static void main(String[] args) {\rInnerClass p = new InnerClass();\rWrapping w = p.wrapping(10);\rSystem.out.println(w.value());//100\r}\r}\r 如果定义一个匿名内部类，并且希望它使用一个在其外部定义的对象，那么编译器会要求其参数引用是 final 的。匿名内部类不能同时实现接口，继承类，而且如果是实现接口也只能实现一个接口\npackage com.zt.activemq_springboot;\r/**\r* @author zhengtao\r* @description 内部类测试\r* @date 2020/10/13\r*/\rpublic class InnerClass {\r//在JDK8之前，如果我们在匿名内部类中需要访问局部变量，那么这个局部变量必须用final修饰符修饰\r//在JDK8中如果我们在匿名内部类中需要访问局部变量，那么这个局部变量不需要用final修饰符修饰。看似是一种编译机制的改变，实际上就是一个语法糖（底层还是帮你加了final）。但通过反编译没有看到底层为我们加上final，但我们无法改变这个局部变量的引用值，如果改变就会编译报错。\rpublic Destination destination1( final String dest){\rreturn new Destination() {\rprivate String label=dest;\r@Override\rpublic String readLabel() {\rreturn label;\r}\r};\r}\rpublic static void main(String[] args) {\rInnerClass p = new InnerClass();\rDestination D=p.destination1(\u0026quot;alice\u0026quot;);\rSystem.out.println(D.readLabel()); }\r}\r 为什么需要内部类。 内部类有效的实现了 多重继承 它允许继承多个非接口类型 (类或抽象类)。  package com.zt.activemq_springboot;\r/**\r* @author zhengtao\r* @description 测试内部类解决多继承\r* @date 2020/10/13\r*/\rclass D{}\rabstract class E{}\rclass Z extends D{\rE makeE(){\rreturn new E() {\r};\r}\r}\rpublic class MultiImplementation {\rstatic void takesD(D d){}\rstatic void takesE(E e){}\rpublic static void main(String[] args) {\rZ z=new Z();\rtakesD(z);\rtakesE(z.makeE());\r}\r}\r  由于每个类都会产生一个.class文件，其中包含了如何创建该类型的对象的全部信息（此信息产生一个 “meta-class”，叫做 Class 对象）内部类也必须生成一个 .class 文件以包含它们的 Class 对象信息。这些类文件的命名有严格的规则： 外围类的名字，加上 $ 再加上内部类的名字。如果是匿名内部类，就产生一个数字作为其标识符。\npackage com.zt.activemq_springboot;\r/**\r* @author zhengtao\r* @description 测试内部类解决多继承\r* @date 2020/10/13\r*/\rclass Egg2{\rprotected class Yolk{\rpublic Yolk(){\rSystem.out.println(\u0026quot;egg2.yolk\u0026quot;);\r}\rpublic void f(){\rSystem.out.println(\u0026quot;egg2.yolk.f\u0026quot;);\r}\r}\rprivate Yolk y = new Yolk();\rpublic Egg2(){\rSystem.out.println(\u0026quot;new Egg2\u0026quot;);\r}\rpublic void insertYolk(Yolk y) {\rthis.y = y;\r}\rpublic void g(){\ry.f();\r}\r}\rpublic class MultiImplementation extends Egg2{\rpublic class Yolk extends Egg2.Yolk{\rpublic Yolk(){\rSystem.out.println(\u0026quot;newegg2.yolk\u0026quot;);\r}\rpublic void f(){\rSystem.out.println(\u0026quot;newegg2.yolk.f\u0026quot;);\r}\r}\rpublic MultiImplementation(){\rinsertYolk(new Yolk());\r}\rpublic static void main(String[] args) {\rEgg2 egg2=new MultiImplementation();\regg2.g();\r}\r}\r/*\r打印出来为\regg2.yolk\rnew Egg2\regg2.yolk\rnewegg2.yolk\rnewegg2.yolk.f\r生成的class文件为 Egg2.class Egg2$Yolk.class MultiImplementation$Yolk.class MultiImplementation.class\r*/\r   第11章 持有对象  迭代器是一个对象，它的工作是遍历并选择序列中的对象，而不需要知道或关心该序列底层的结构。  @Test\rvoid test34(){\rList\u0026lt;Integer\u0026gt; list = new ArrayList();\rlist.add(1);\rlist.add(2);\rlist.add(3);\rIterator\u0026lt;Integer\u0026gt; iterator=list.iterator();// iterator()要求容器返回一个Iterator\rwhile (iterator.hasNext()){// 检查序列中是否还有元素\rInteger a = iterator.next();// 获得序列中的下一个元素\riterator.remove();// 将迭代器新近返回的元素删除,必须先调用next方法\rSystem.out.println(a);\r}\r}\r Stack 栈 后进先出，peek() 方法提供栈顶元素，pop() 将移除并返回栈顶元素。不能使用基本类型的容器。  第12章 通过异常处理错误   Java 的基本理念是 “结构不佳的代码不能运行”\n  异常情形是指阻止当前方法或作用域继续执行的问题。异常情形在当前环境下无法获得必要的信息来解决问题。你所能做的就是从当前环境跳出，并且把问题提交给上一级，这就是抛出异常的时候所发生的事情。当抛出异常后，有几件事情会随之发生。首先，同 Java 中其他对象的创建一样，将使用 new 在堆上创建异常对象，然后当前的执行路劲被终止，并且从当前的环境中弹出对异常对象的引用。此时，异常处理机制接管程序，并开始寻找一个恰当的地方来继续执行程序。这个恰当的地方就是异常处理程序，它的任务是将程序从错误状态中恢复，以使程序要么能换一种方式运行，要么继续运行下去。\n  try块。如果在方法内部抛出了异常（或者在方法内部调用的其他方法抛出了异常），这个方法将在抛出异常的过程中结束，要是不希望方法就此结束，可以在方法内设置一个特殊的块来捕获异常。因为在这个块里尝试各种可能产生异常的方法调用，所以称为 try 块。\n  异常处理程序。当然，抛出的异常必须在某处得到处理。这个地点就是异常处理程序，就是catch内的内容，每个 catch 子句看起来就像是接受一个且仅接受一个特殊类型的参数的方法，异常处理程序必须紧跟在 try 块之后，当异常被抛出时，异常处理机制将负责搜寻参数与异常类型相匹配的第一个处理程序，然后进入 catch 子句执行，此时认为异常得到了处理，一旦 catch 子句结束，则处理程序的查找过程结束。\n  终止与恢复。异常处理理论上有两种基本模型，终止模型，将假设错误非常关键，以至于程序无法返回到异常发生的地方继续执行。一旦异常被抛出，就表明错误已经无法挽回，也不难回来执行。恢复模型，意思是异常处理程序的工作是修订错误，通常希望异常被处理之后能继续执行程序。\n  自定义异常。printStackTrace方法将打印“从方法调用处直到异常抛出处”的方法调用序列，将被输出到标准错误流。\npackage com.zt.activemq_springboot;\r/**\r* @author zhengtao\r* @description 自定义异常类\r* @date 2020/10/15\r*/\rpublic class MyException extends Exception{\rprivate String code;\rpublic MyException(String code,String msg){\rsuper(msg);\rthis.code=code;\r}\rpublic MyException(){\r}\rpublic String getCode() {\rreturn code;\r}\rpublic void setCode(String code) {\rthis.code = code;\r}\r}\r@Test\rvoid test36(){\rtry {\rint a = 1/0;\r} catch (Exception e) {\rMyException myException = new MyException(\u0026quot;zz\u0026quot;,e.getMessage());\rSystem.out.println(myException.getMessage());\rmyException.printStackTrace(System.out);//将其发送到了标准输出流：System.out，所以不会报错\rmyException.printStackTrace();\r}\r}\r 结果\n   异常说明， java 鼓励人们把方法可能会抛出的异常告知使用此方法的调用者，java 提供了相应的语法（并强制使用这个语法），它属于方法声明的一部分，紧跟在形式参数列表之后，使用附加的关键字 throws，后面接一个所有潜在异常类型的列表。代码必须与异常说明保持一致。如果方法里的代码产生了异常却没有进行处理，编译器会发现问题并提醒你：要么处理这个异常，要么就在异常说明中表明此方法将产生异常。但可以声明方法将抛出异常，实际上却不抛出，编译器相信这个声明，并强制此方法的用户像真的抛出异常那样使用这个方法。这样做的好处是，为异常先占个位置，以后就可以抛出这种异常而不用修改已有的代码，在定义抽象基类和接口时这种能力很重要，这样派生类或接口实现就能够抛出这些预先声明的异常。\n  异常链，常常会想要在捕获一个异常后抛出另一个异常，并且希望把原始异常的信息保存下来，这被称为异常链，JDK 1.4 后 所有 Throwable 的子类在构造器中都可以接受一个cause对象作为参数，这个cause就表示原始异常，这样通过把原始异常传递给新的异常，使得即使在当前位置创建并抛出了新的异常，也能通过这个异常链追踪到异常最初发生的地方。只有Error，Exception，RuntimeException这三个类提供了带cause的构造方法。\n  java 标准异常，RuntimeException 运行时异常，它们会自动被 Java 虚拟机抛出，所以不必在异常说明中把它们列出来。但是可以在代码中抛出RuntimeException 异常而且不需要异常说明，因为它直接到达了main方法,再程序退出前将调用异常的printStackTrace方法。\n@Test\rvoid test36() throws MyException {\r// throw new MyException();//必须要异常说明或处理异常\rthrow new RuntimeException();//不需要\r}\r   第13章\t字符串   String 类中每一个看起来会修改 String 值的方法，实际上都是创建了一个全新的 String 对象，以包含修改后的字符串内容。而最初的 String 对象则丝毫未动\n  重载的 “+” 操作符，重载操作符的意思是，一个操作符在应用于特定的类时，被赋予了特殊的意义（用于 String 的 “+” 和 “+=” 是 Java 中仅有的两个重载过的操作符，而 Java 不允许程序员重载任何操作符）重载 + 操作符其实是使用了 StringBuilder的 append() 方法，然后在 toString，但是在循环体中使用 “+” 每次循环都会 new 出一个 StringBuilder 对象， 然后进行 append 操作，最后通过 toString 方法返回 String 对象，造成内存资源浪费。 所有循环体中建议直接使用 StringBuilder。\n  第15章\t泛型 ​\t只有知道了某个技术不能做到什么，你才能更好的做到所能做到的。\n  泛型类，我们更喜欢暂时不指定类型，而是稍后再决定具体使用什么类型，要达到这个目的，需要使用类型参数，用尖括号括住，放在类名后，然后在使用这个类的时候，再用实际的类型替换此参数类型。\npackage com.zt.activemq_springboot;\r/**\r* @author zhengtao\r* @description 泛型\r* @date 2020/10/20\r*/\rclass Automobile{\r}\rpublic class Holder\u0026lt;T\u0026gt; {// T 为类型参数\rprivate T a;\rpublic Holder(T a){\rthis.a=a;\r}\rpublic T getA() {\rreturn a;\r}\rpublic void setA(T a) {\rthis.a = a;\r}\rpublic static void main(String[] args) {\rHolder\u0026lt;Automobile\u0026gt; holder = new Holder\u0026lt;\u0026gt;(new Automobile());//创建对象时必须要指定想持有什么类型的对象，然后就只能在其中存入该类型或其子类，这就是 java 泛型的核心概念: 告诉编译器想使用什么类型，然后编译器帮你处理一切细节。\r}\r}\r   泛型接口， Java 泛型的局限性：基本类型无法作为类型参数。\n  泛型方法，是否拥有泛型方法，与其所在的类是不是泛型类没有关系，要定义泛型方法，只需将泛型参数列表置于返回值之前\npackage com.zt.activemq_springboot;\rimport sun.nio.cs.Surrogate;\r/**\r* @author zhengtao\r* @description 泛型\r* @date 2020/10/20\r*/\rclass Automobile{\r}\rpublic class Holder\u0026lt;T\u0026gt; {// T 为类型参数\rprivate T a;\rpublic Holder(T a){\rthis.a=a;\r}\rpublic T getA() {\rreturn a;\r}\rpublic void setA(T a) {\rthis.a = a;\r}\rpublic static void main(String[] args) {\rHolder\u0026lt;Automobile\u0026gt; holder = new Holder\u0026lt;\u0026gt;(new Automobile());\rholder.f(new Automobile());\rholder.f(holder);\rholder.f(1);\r}\rpublic \u0026lt;s\u0026gt; void f(s x){// s是泛型参数，可用任何字符代替,一般用T\rSystem.out.println(x.getClass().getName());\r}\r}\r   可变参数与泛型方法\npublic static \u0026lt;T\u0026gt; List\u0026lt;T\u0026gt; makeList(T... args){\rList\u0026lt;T\u0026gt; result = new ArrayList\u0026lt;\u0026gt;();\rfor(T t:args){\rresult.add(t);\r}\rreturn result;\r}\r   檫除，在泛型代码内部，无法获得任何有关泛型参数类型的信息，Java的泛型是通过擦除来实现的，这意味着当你使用泛型时，任何具体的类型信息都被擦除了，你唯一知道的就是你在使用一个对象。\nList\u0026lt;String\u0026gt; l1 = new ArrayList\u0026lt;String\u0026gt;();\rList\u0026lt;Integer\u0026gt; l2 = new ArrayList\u0026lt;Integer\u0026gt;();\r// 这两种形式都被檫除成它们的原生类型，即List\rSystem.out.println(l1.getClass() == l2.getClass());// true\r package com.zt.activemq_springboot;\r/**\r* @author zhengtao\r* @description 擦除\r* @date 2020/10/20\r*/\rclass HasF{\rpublic void f(){\rSystem.out.println(\u0026quot;HasF.f()\u0026quot;);\r}\r}\rclass Manipulator\u0026lt;T\u0026gt;{\rprivate T obj;\rpublic Manipulator(T x){\robj=x;\r}\rpublic void manipulate(){\robj.f(); //因为擦除所以不知道这里是什么类型。\r}\r}\rclass Manipulator2\u0026lt;T extends HasF\u0026gt;{ // 指定了T 必须是HasF或者从HasF导出的类\rprivate T obj;\rpublic Manipulator2(T x){\robj=x;\r}\rpublic void manipulate(){\robj.f(); // 可以正确调用\r}\r}\rpublic class Manipulation {\r}\r   在基于檫除的实现中，泛型类型被当作第二类类型处理，即不能在某些重要的上下文环境中使用的类型，泛型类型只有在静态类型检查期间才出现，在此之后，程序中的所有泛型类型都将被檫除，替换为他们的非泛型上界，例如 List被檫除为 List。\n  檫除的问题，泛型不能用于显式地引用运行时类型的操作之中，例如转型、instanceof、new等，因为所有关于参数的类型信息都丢失了。\n  泛型数组，不能创建泛型的数组（T[] array = new T[10] 错滴） ，解决方案是在任何想要创建泛型数组的地方都是用 ArrayList\n  边界，因为檫除移除了类型信息，所以，可以用无界泛型参数调用的方法只是那些可以用 Object 调用的方法，但是，如果能够将这个参数限制为某个类型子集，那么你就可以用这些类型子集来调用方法，为了执行这种限制，Java 泛型重用了 extends 关键字。\n  通配符，数组的一种特殊行为：可以向导出类型的数组赋予其类型的数组引用\npackage com.zt.activemq_springboot.config;\rclass Fruit1{}\rclass Apple extends Fruit1{}\rclass Jonathan extends Apple{}\rclass Orange extends Fruit1{}\rpublic class Example {\rpublic static void main(String[] args) {\rFruit1[] fruit = new Apple[10];// 此时创建了一个 Apple 数组，并将其赋值给一个 Fruit 数组引用\rfruit[0] = new Apple();// 可以放置Apple或Apple的子类型\rfruit[1] = new Jonathan();\rfruit[2] = new Fruit1();// Apple有一个 Fruit[] 引用，所以编译器允许你将 fruit或fruit的子类 放置到这个数组中所以不会报错，但在运行时，数组机制知道它处理的是 Apple[] 所以就会抛出异常\rfruit[3] = new Orange();\r}\r}\r 使用泛型的主要目标之一是将这种错误检测移入到编译期。\nList\u0026lt;Fruit1\u0026gt; fruits = new ArrayList\u0026lt;Apple\u0026gt;();//直接报错，\r// 不能将一个涉及 Apple的泛型赋值给一个涉及 Fruit1的泛型。如果就像在数组中的情况一样，编译器对代码的了解足够多，可以确定所涉及到的容器，但是它不知道任何有关这方面的信息，因此它拒绝向上转型。但是这根本不是向上转型，Apple的list将持有Apple和apple的子类型;fruit的list将持有任何类型的fruit，虽然他包括apple，真正的问题在于我们是在谈论容器的类型而不是容器持有的类型，所以 fruit的list 在类型上不等价于Apple的list\r 但是，有时你想在两个类型之间建立某种类型的向上转型关系，这正是通配符所允许的\n//你可以将其读作 : 具有任何从 Fruit继承的类型的列表。但是,这实际上并不意味着这个List 将持有任何类型的 Fruit。\r//通配符引用的是明确的类型,因此它意味着 某种fruit引用没有指定的具体类型。因此这个被复制的List 必须持有诸如 Fruit 或 Apple 这样的某种执行类型,但是为了向上转型为 list ,这个类型是什么并没有人关心\rList\u0026lt;? extends Fruit1\u0026gt; fruit = new ArrayList\u0026lt;Apple\u0026gt;();\r// 你可能会认为,事情变得有点走极端了,因为现在你甚至不能向刚刚声明过将持有 Apple 对对象的List 中放置一个 Apple 对象了。是的,但是编译器并不知道这一点。 List\u0026lt;? extends Fruit\u0026gt; 可以合法地指向一个 List\u0026lt;Orange\u0026gt; 。一旦执行这种类型的向上转型,你就将丢失掉向其中传递任何对象的能力,甚至是传递Object 也不行。\rfruit.add(new Apple());// 错误\rfruit.add(new Fruit1());// 错误\rfruit.add(new Object());// 错误\rfruit.add(null);\r// 另一方面,如果你调用一个返回Fruit 的方法,则是安全的,因为你知道在这个List中的任何对象至少具有Fruit 类型,因此编译器将允许这么做。\rFruit1 fruit1 = fruit.get(0);\rApple apple = fruit.get(0);\r public class Holder\u0026lt;T\u0026gt; {\rprivate T t;\rpublic Holder(T t) {\rthis.t = t;\r}\rpublic Holder() {\r}\rpublic T getT() {\rreturn t;\r}\rpublic void setT(T t) {\rthis.t = t;\r}\r@Override\rpublic boolean equals(Object object) {\rreturn t.equals(object);\r}\rpublic static void main(String[] args) {\rHolder\u0026lt;Apple\u0026gt; holder = new Holder\u0026lt;\u0026gt;(new Apple());\rApple apple = holder.getT();\rholder.setT(apple);\r//Holder\u0026lt;Fruit\u0026gt; fruitHolder=holder; 无法向上转型\rHolder\u0026lt;? extends Fruit\u0026gt; fruit = holder;\rFruit fruit1 = fruit.getT();// 如果调用 getT() ,它只会返回一个 Fruit 这就是在给定任何扩展自Fruit的对象这一边界之后,它所能知道的一切了\r//返回的结果是 object\rapple= (Apple) fruit.getT();\rtry {\rOrange orange = (Orange) fruit.getT();\r}catch (Exception e){\rSystem.out.println(e);\r}\r//fruit.setT(new Apple()); setT() 方法不能工作于 Apple 或 Fruit ,因为 setT() 的参数也是 ? extends Fruit 这意味着它可以是任何事物,而编译器无法验证任何事物的类型安全性\r//fruit.setT(new Fruit());\rSystem.out.println(fruit.equals(apple));\r}\r}\r//运行结果为\rjava.lang.ClassCastException: generic.Apple cannot be cast to generic.Orange\rtrue\r 逆变，使用超类型通配符，可以声明通配符是由某个特定类的任何基类来界定的如\u0026lt;? super Fruit\u0026gt; 无界通配符，List 实际上表示持有任何 Object 类型的原生 List ，而 List\u0026lt;?\u0026gt; 表示 具有某种特定类型的非原生List，只是我们不知道那种类型是什么。    第16章 数组  Java 中数组是一种效率最高的存储和随机访问对象引用序列的方式 数组是第一级对象，无论使用哪种类型的数组，数组标识符其实只是一个引用，指向在堆中创建的一个真实对象，这个数组对象用以保存指向其他对象的引用，可以作为数组初始化语法的一部分隐式地创建此对象，或者用 new 表达式显示地创建。只读成员 length 是数组对象的一部分，事实上，这是唯一一个可以访问的字段或方法，表示此数组对象可以存储多少元素，“[]” 语法是访问对象唯一的方式。对象数组保存的是引用，基本类型数组直接保存基本类型的值。  第17章\t容器深入研究 第18章\tJava I/O系统 第19章\t枚举类型  编译器为你创建的 enum 类都继承自 Enum 类， 所以枚举类不能继承其他类，编译器会将枚举类标记为 final 类，所以无法继承自 enum。但枚举类仍然可以实现一个或多个接口。  第21章\t并发  线程可以驱动任务，因此你需要一种描述任务的方式，这可以由 Runnable 接口来提供，要想定义任务，只需实现 Runnable 接口并编写 run() 方法 将 Runnable 对象转变为工作任务的传统方式是把它提交给一个 Thread 构造器。  注解 注解的本质 注解的本质就是一个继承了 Annotation 接口的接口。\n「java.lang.annotation.Annotation」接口中有这么一句话，用来描述『注解』。\n The common interface extended by all annotation types\n所有的注解类型都继承自这个普通的接口（Annotation）\n @Override 的源码为：\n@Target(ElementType.METHOD)\r@Retention(RetentionPolicy.SOURCE)\rpublic @interface Override {\r}\r 本质上就相当于：\npublic interface Override extends Annotation{\r}\r 一个注解准确意义上来说，只不过是一种特殊的注释而已，如果没有解析它的代码，它可能连注释都不如。\n而解析一个类或者方法的注解往往有两种形式，一种是编译期直接的扫描，一种是运行期反射。反射的事情我们待会说，而编译器的扫描指的是编译器在对 java 代码编译字节码的过程中会检测到某个类或者方法被一些注解修饰，这时它就会对于这些注解进行某些处理。\n典型的就是注解 @Override，一旦编译器检测到某个方法被修饰了 @Override 注解，编译器就会检查当前方法的方法签名是否真正重写了父类的某个方法，也就是比较父类中是否具有一个同样的方法签名。\n这一种情况只适用于那些编译器已经熟知的注解类，比如 JDK 内置的几个注解，而你自定义的注解，编译器是不知道你这个注解的作用的，当然也不知道该如何处理，往往只是会根据该注解的作用范围来选择是否编译进字节码文件，仅此而已。\n元注解 『元注解』是用于修饰注解的注解，通常用在注解的定义上，JAVA 中有以下几个『元注解』：\n @Target：注解的作用目标，@Target 用于指明被修饰的注解最终可以作用的目标是谁，也就是指明，你的注解到底是用来修饰方法的？修饰类的？还是用来修饰字段属性的。具体取值为：  ElementType.TYPE：允许被修饰的注解作用在类、接口和枚举上 ElementType.FIELD：允许作用在属性字段上 ElementType.METHOD：允许作用在方法上 ElementType.PARAMETER：允许作用在方法参数上 ElementType.CONSTRUCTOR：允许作用在构造器上 ElementType.LOCAL_VARIABLE：允许作用在本地局部变量上 ElementType.ANNOTATION_TYPE：允许作用在注解上 ElementType.PACKAGE：允许作用在包上   @Retention：注解的生命周期。具体取值为：  RetentionPolicy.SOURCE：当前注解编译期可见，不会写入 class 文件 RetentionPolicy.CLASS：类加载阶段丢弃，会写入 class 文件 RetentionPolicy.RUNTIME：永久保存，可以反射获取   @Documented：注解是否应当被包含在 JavaDoc 文档中 @Inherited：是否允许子类继承该注解  注解工作流程 自定义注解：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\rpublic @interface Fruit {\rString genName() default \u0026quot;\u0026quot;;\rString genColor() default \u0026quot;\u0026quot;;\r}\r 作用于类：\n@Data\r@Fruit(genName = \u0026quot;富士康苹果\u0026quot;, genColor = \u0026quot;红色\u0026quot;)\rpublic class Apple {\rprivate String name;\rprivate String color;\r}\r 测试使用：\npublic class AnnotationTest {\rpublic static void main(String[] args) {\rApple apple = new Apple();\r// 通过动态代理生成实现注解的代理类, 将注解的值加入到map中\rFruit fruit = apple.getClass().getAnnotation(Fruit.class);\r// 实际上是根据方法名从map中将值取出\rSystem.out.println(fruit.genName());\rSystem.out.println(fruit.genColor());\r}\r}\r 对于一个类或者接口来说，Class 类中提供了以下一些方法用于反射注解。\n getAnnotation：返回指定的注解 isAnnotationPresent：判定当前元素是否被指定注解修饰 getAnnotations：返回所有的注解 getDeclaredAnnotation：返回本元素的指定注解 getDeclaredAnnotations：返回本元素的所有注解，不包含父类继承而来的   当使用反射获取到注解时即调用 getAnnotation() 方法后， JDK 通过动态代理机制生成一个实现我们注解（接口）的代理类。其构造方法执行的是，AnnotationInvocationHandler 这个类中  private static final long serialVersionUID = 6182022883658399397L;\rprivate final Class\u0026lt;? extends Annotation\u0026gt; type;\r// key为注解的方法名，value为属性的值。\rprivate final Map\u0026lt;String, Object\u0026gt; memberValues;\rprivate transient volatile Method[] memberMethods = null;\rAnnotationInvocationHandler(Class\u0026lt;? extends Annotation\u0026gt; var1, Map\u0026lt;String, Object\u0026gt; var2) {\rClass[] var3 = var1.getInterfaces();\rif (var1.isAnnotation() \u0026amp;\u0026amp; var3.length == 1 \u0026amp;\u0026amp; var3[0] == Annotation.class) {\rthis.type = var1;\rthis.memberValues = var2;\r} else {\rthrow new AnnotationFormatError(\u0026quot;Attempt to create proxy for a non-annotation type.\u0026quot;);\r}\r}\r 执行完构造方法后，memberValues map 中就有注解的所有方法名与值。\n 执行注解的任何方法都会调用 invoke 方法\npublic Object invoke(Object var1, Method var2, Object[] var3) {\rString var4 = var2.getName();\rClass[] var5 = var2.getParameterTypes();\rif (var4.equals(\u0026quot;equals\u0026quot;) \u0026amp;\u0026amp; var5.length == 1 \u0026amp;\u0026amp; var5[0] == Object.class) {\rreturn this.equalsImpl(var3[0]);\r} else if (var5.length != 0) {\rthrow new AssertionError(\u0026quot;Too many parameters for an annotation method\u0026quot;);\r} else {\rbyte var7 = -1;\rswitch(var4.hashCode()) {\rcase -1776922004:\rif (var4.equals(\u0026quot;toString\u0026quot;)) {\rvar7 = 0;\r}\rbreak;\rcase 147696667:\rif (var4.equals(\u0026quot;hashCode\u0026quot;)) {\rvar7 = 1;\r}\rbreak;\rcase 1444986633:\rif (var4.equals(\u0026quot;annotationType\u0026quot;)) {\rvar7 = 2;\r}\r}\rswitch(var7) {\rcase 0:\rreturn this.toStringImpl();\rcase 1:\rreturn this.hashCodeImpl();\rcase 2:\rreturn this.type;\rdefault:\r// 主要就是这个地方，根据方法名将值从map中取出来\rObject var6 = this.memberValues.get(var4);\rif (var6 == null) {\rthrow new IncompleteAnnotationException(this.type, var4);\r} else if (var6 instanceof ExceptionProxy) {\rthrow ((ExceptionProxy)var6).generateException();\r} else {\rif (var6.getClass().isArray() \u0026amp;\u0026amp; Array.getLength(var6) != 0) {\rvar6 = this.cloneArray(var6);\r}\rreturn var6;\r}\r}\r}\r}\r   ","id":2,"section":"posts","summary":"Java 编程思想学习 第1章 对象导论 好像看不下去，。。。 第2章 一切都是对象 用引用操作对象：每种编程语言都有自己的操纵内存中元素的方式。java中操纵","tags":["Java基础"],"title":"Java 编程思想学习","uri":"https://wzgl998877.github.io/2022/01/java-%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3%E5%AD%A6%E4%B9%A0/","year":"2022"},{"content":"LeetCode 链表 链表（Linked list）是一种常见的基础数据结构，是一种线性表，但是并不会按线性的顺序存储数据，而是在每一个节点里存到下一个节点的指针(Pointer)。由于不必须按顺序存储，链表在插入的时候可以达到O(1)的复杂度，比另一种线性表顺序表快得多，但是查找一个节点或者访问特定编号的节点则需要O(n)的时间，而顺序表相应的时间复杂度分别是O(logn)和O(1)。\n使用链表结构可以克服数组链表需要预先知道数据大小的缺点，链表结构可以充分利用计算机内存空间，实现灵活的内存动态管理。但是链表失去了数组随机读取的优点，同时链表由于增加了结点的指针域，空间开销比较大。\n在计算机科学中，链表作为一种基础的数据结构可以用来生成其它类型的数据结构。链表通常由一连串节点组成，每个节点包含任意的实例数据（data fields）和一或两个用来指向上一个/或下一个节点的位置的链接（\u0026ldquo;links\u0026rdquo;）。链表最明显的好处就是，常规数组排列关联项目的方式可能不同于这些数据项目在记忆体或磁盘上顺序，数据的访问往往要在不同的排列顺序中转换。而链表是一种自我指示数据类型，因为它包含指向另一个相同类型的数据的指针（链接）。链表允许插入和移除表上任意位置上的节点，但是不允许随机存取。链表有很多种不同的类型：单向链表，双向链表以及循环链表\n单向链表 链表中最简单的一种是单向链表，它包含两个域，一个信息域和一个指针域。这个链接指向列表中的下一个节点，而最后一个节点则指向一个空值。\n 一个单向链表包含两个值: 当前节点的值和一个指向下一个节点的链接\n一个单向链表的节点被分成两个部分。第一个部分保存或者显示关于节点的信息，第二个部分存储下一个节点的地址。单向链表只可向一个方向遍历。\n链表最基本的结构是在每个节点保存数据和到下一个节点的地址，在最后一个节点保存一个特殊的结束标记，另外在一个固定的位置保存指向第一个节点的指针，有的时候也会同时储存指向最后一个节点的指针。一般查找一个节点的时候需要从第一个节点开始每次访问下一个节点，一直访问到需要的位置。但是也可以提前把一个节点的位置另外保存起来，然后直接访问。当然如果只是访问数据就没必要了，不如在链表上储存指向实际数据的指针。这样一般是为了访问链表中的下一个或者前一个（需要储存反向的指针，见下面的双向链表）节点。\n相对于下面的双向链表，这种普通的，每个节点只有一个指针的链表也叫单向链表，或者单链表，通常用在每次都只会按顺序遍历这个链表的时候（例如图的邻接表，通常都是按固定顺序访问的）。\n链表也有很多种不同的变化：\n双向链表 一种更复杂的链表是“双向链表”或“双面链表”。每个节点有两个连接：一个指向前一个节点，（当此“连接”为第一个“连接”时，指向空值或者空列表）；而另一个指向下一个节点，（当此“连接”为最后一个“连接”时，指向空值或者空列表）\n 一个双向链表有三个整数值: 数值, 向后的节点链接, 向前的节点链接\n在一些低级语言中, XOR-linking 提供一种在双向链表中通过用一个词来表示两个链接（前后），我们通常不提倡这种做法。\n双向链表也叫双链表。双向链表中不仅有指向后一个节点的指针，还有指向前一个节点的指针。这样可以从任何一个节点访问前一个节点，当然也可以访问后一个节点，以至整个链表。一般是在需要大批量的另外储存数据在链表中的位置的时候用。双向链表也可以配合下面的其他链表的扩展使用。\n由于另外储存了指向链表内容的指针，并且可能会修改相邻的节点，有的时候第一个节点可能会被删除或者在之前添加一个新的节点。这时候就要修改指向首个节点的指针。有一种方便的可以消除这种特殊情况的方法是在最后一个节点之后、第一个节点之前储存一个永远不会被删除或者移动的虚拟节点，形成一个下面说的循环链表。这个虚拟节点之后的节点就是真正的第一个节点。这种情况通常可以用这个虚拟节点直接表示这个链表，对于把链表单独的存在数组里的情况，也可以直接用这个数组表示链表并用第0个或者第-1个（如果编译器支持）节点固定的表示这个虚拟节点。\n循环链表 在一个 循环链表中, 首节点和末节点被连接在一起。这种方式在单向和双向链表中皆可实现。要转换一个循环链表，你开始于任意一个节点然后沿着列表的任一方向直到返回开始的节点。再来看另一种方法，循环链表可以被视为“无头无尾”。这种列表很利于节约数据存储缓存， 假定你在一个列表中有一个对象并且希望所有其他对象迭代在一个非特殊的排列下。\n指向整个列表的指针可以被称作访问指针。\n 用单向链表构建的循环链表\n循环链表中第一个节点之前就是最后一个节点，反之亦然。循环链表的无边界使得在这样的链表上设计算法会比普通链表更加容易。对于新加入的节点应该是在第一个节点之前还是最后一个节点之后可以根据实际要求灵活处理，区别不大(详见下面实例代码)。当然，如果只会在最后插入数据（或者只会在之前），处理也是很容易的。\n另外有一种模拟的循环链表，就是在访问到最后一个节点之后的时候，手工的跳转到第一个节点。访问到第一个节点之前的时候也一样。这样也可以实现循环链表的功能，在直接用循环链表比较麻烦或者可能会出现问题的时候可以用。\n动态规划 动态规划问题的一般形式就是求最值。动态规划其实是运筹学的一种最优化方法，只不过在计算机问题上应用比较多，比如说让你求最长递增子序列呀，最小编辑距离呀等等。\n既然是要求最值，核心问题是什么呢？求解动态规划的核心问题是穷举。因为要求最值，肯定要把所有可行的答案穷举出来，然后在其中找最值呗。\n首先，动态规划的穷举有点特别，因为这类问题存在「重叠子问题」，如果暴力穷举的话效率会极其低下，所以需要「备忘录」或者「DP table」来优化穷举过程，避免不必要的计算。\n而且，动态规划问题一定会具备「最优子结构」，才能通过子问题的最值得到原问题的最值。\n另外，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解其实并不是一件容易的事，只有列出 正确的「状态转移方程」实际上就是描述问题结构的数学形式，才能正确地穷举。\n以上提到的 重叠子问题、最优子结构、状态转移方程 就是动态规划三要素。\n如何列出正确的状态转移方程？\n  先确定「状态」，也就是原问题和子问题中变化的变量。\n  确定dp函数的定义\n  确定「选择」并择优，也就是对于每个状态，可以做出什么选择改变当前状态。\n  最后明确 base case\n  回溯算法 回溯法（back tracking）（探索与回溯法）是一种选优搜索法，又称为试探法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。\n\u0026gt; 加空格可以达到下面的效果\r  白话：回溯法可以理解为通过选择不同的岔路口寻找目的地，一个岔路口一个岔路口的去尝试找到目的地。如果走错了路，继续返回来找到岔路口的另一条路，直到找到目的地。\n 解决一个回溯问题，实际上就是一个决策树的遍历过程。你只需要思考 3 个问题：\n 路径：也就是已经做出的选择。 选择列表：也就是你当前可以做的选择。 结束条件：也就是到达决策树底层，无法再做选择的条件。  代码框架:\nresult = []\rdef backtrack(路径, 选择列表):\rif 满足结束条件:\rresult.add(路径)\rreturn\rfor 选择 in 选择列表:\r做选择\rbacktrack(路径, 选择列表)\r撤销选择\r 我们在高中的时候就做过排列组合的数学题，我们也知道n个不重复的数，全排列共有 n! 个。\nPS：为了简单清晰起见，我们这次讨论的全排列问题不包含重复的数字。\n那么我们当时是怎么穷举全排列的呢？比方说给三个数[1,2,3]，你肯定不会无规律地乱穷举，一般是这样：\n先固定第一位为 1，然后第二位可以是 2，那么第三位只能是 3；然后可以把第二位变成 3，第三位就只能是 2 了；然后就只能变化第一位，变成 2，然后再穷举后两位……\n其实这就是回溯算法，我们高中无师自通就会用，或者有的同学直接画出如下这棵回溯树：\n只要从根遍历这棵树，记录路径上的数字，其实就是所有的全排列。我们不妨把这棵树称为回溯算法的「决策树」。\n为啥说这是决策树呢，因为你在每个节点上其实都在做决策。比如说你站在下图的红色节点上：\n你现在就在做决策，可以选择 1 那条树枝，也可以选择 3 那条树枝。为啥只能在 1 和 3 之中选择呢？因为 2 这个树枝在你身后，这个选择你之前做过了，而全排列是不允许重复使用数字的。\n现在可以解答开头的几个名词：[2]就是「路径」，记录你已经做过的选择；[1,3]就是「选择列表」，表示你当前可以做出的选择；「结束条件」就是遍历到树的底层，在这里就是选择列表为空的时候。\n如果明白了这几个名词，可以把「路径」和「选择列表」作为决策树上每个节点的属性，比如下图列出了几个节点的属性：\n我们定义的backtrack函数其实就像一个指针，在这棵树上游走，同时要正确维护每个节点的属性，每当走到树的底层，其「路径」就是一个全排列。\n","id":3,"section":"posts","summary":"LeetCode 链表 链表（Linked list）是一种常见的基础数据结构，是一种线性表，但是并不会按线性的顺序存储数据，而是在每一个节点里存到下一个节点的","tags":["LeetCode"],"title":"LeetCode","uri":"https://wzgl998877.github.io/2022/01/leetcode/","year":"2022"},{"content":"Linux工作日常命令 jps 命令 jps 查看全部的jvm进程，可以带上grep命令一起使用 jps |grep -e ×××\nfind命令 基本格式：find path expression\n1. 按照文件名查找 　(1)find / -name httpd.conf　#在根目录下查找文件httpd.conf，表示在整个硬盘查找 (2)find /etc -name httpd.conf　#在/etc目录下文件httpd.conf (3)find /etc -name \u0026lsquo;srm\u0026rsquo;　#使用通配符*(0或者任意多个)。表示在/etc目录下查找文件名中含有字符串‘srm’的文件 (4)find . -name \u0026lsquo;srm*\u0026rsquo; #表示当前目录下查找文件名开头是字符串‘srm’的文件\n2.按照文件特征查找  　(1)find / -amin -10 # 查找在系统中最后10分钟访问的文件(access time) (2)find / -atime -2　# 查找在系统中最后48小时访问的文件 (3)find / -empty # 查找在系统中为空的文件或者文件夹 (4)find / -group cat # 查找在系统中属于 group为cat的文件 (5)find / -mmin -5 # 查找在系统中最后5分钟里修改过的文件(modify time) (6)find / -mtime -1 #查找在系统中最后24小时里修改过的文件 (7)find / -user fred #查找在系统中属于fred这个用户的文件 (8)find / -size +10000c　#查找出大于10000000字节的文件(c:字节，w:双字，k:KB，M:MB，G:GB) (9)find / -size -1000k #查找出小于1000KB的文件\n3.使用混合查找方式查找文件 　参数有： ！，-and(-a)，-or(-o)。\n　(1)find /tmp -size +10000c -and -mtime +2 #在/tmp目录下查找大于10000字节并在最后2分钟内修改的文件 (2)find / -user fred -or -user george #在/目录下查找用户是fred或者george的文件文件 (3)find /tmp ! -user panda　#在/tmp目录中查找所有不属于panda用户的文件\n文件大小排序 du -sh * 可以将文件夹下按顺序排序\nmv account_confirm.log.2* /log/logs/tms 移动文件可以直接使用正则表达式\ndf -h 查看磁盘使用情况\nfree -h 查看内存使用情况\nip命令 比较高深，没参透，常用的有 ip a\ngrep   在文件中搜索一个单词，命令会返回一个包含 “match_pattern” 的文本行\ngrep \u0026quot;match_pattern\u0026quot; file_name\r如：grep \u0026quot;taifungChangeAssignTaskRpc\u0026quot; manage_service_workflow.log\r匹配多个 grep \u0026quot;match_pattern\u0026quot; file_name1 file_name2\r 匹配同时满足多个条件的\n# | grep \u0026quot;bb\u0026quot; 同时满足多少就写多少\rgrep \u0026quot;aaa\u0026quot; log.log | grep \u0026quot;bb\u0026quot;\r 相反的\ngrep -v \u0026quot;match_pattern\u0026quot; file_name\r输出不匹配的所有行\r   正则匹配\ngrep -E \u0026quot;[1-9]+\u0026quot; file_name\reg: grep -E *.06151000064240 manage_service_workflow.log  忽略大小写\ngrep -i \u0026quot;match_pattern\u0026quot; file_name\reg:grep -i \u0026quot;tAIfungChangeAssignTaskRpc\u0026quot; manage_service_workflow.log    打印规则\n# 显示匹配某个结果之后的3行，使用 -A 选项：\rgrep \u0026quot;5\u0026quot; file_name -A 3\r# 显示匹配某个结果之前的3行，使用 -B 选项：\rgrep \u0026quot;5\u0026quot; file_name -B 3\r# 显示匹配某个结果的前三行和后三行，使用 -C 选项：\rgrep \u0026quot;5\u0026quot; file_name -C 3\r   统计包含指定字符的行数\ncat test.log | grep -c test\r   ","id":4,"section":"posts","summary":"Linux工作日常命令 jps 命令 jps 查看全部的jvm进程，可以带上grep命令一起使用 jps |grep -e ××× find命令 基本格式：find path expression 1. 按照文件名查","tags":["Linux命令"],"title":"Linux工作日常命令","uri":"https://wzgl998877.github.io/2022/01/linux%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%B8%B8%E5%91%BD%E4%BB%A4/","year":"2022"},{"content":"mybatis 技术内幕学习 Jdbc 复习 通过JDBC查询数据库数据，一般需要以下七个步骤：\n  加载JDBC驱动； 建立并获取数据库连接； 创建 JDBC Statements 对象； 设置SQL语句的传入参数； 执行SQL语句并获得查询结果； 对查询结果进行转换处理并将处理结果返回； 释放相关资源（关闭Connection，关闭Statement，关闭ResultSet）；   代码如下：\npackage com.zt.javastudy.mybatis;\rimport com.alibaba.fastjson.JSONObject;\rimport lombok.extern.slf4j.Slf4j;\rimport java.sql.*;\rimport java.util.ArrayList;\rimport java.util.HashMap;\rimport java.util.List;\rimport java.util.Map;\r/**\r* jdbc连接数据库\r*\r* @author zhengtao on 2021/9/16\r*/\r@Slf4j\rpublic class JdbcTest {\rpublic static List\u0026lt;Map\u0026lt;String,Object\u0026gt;\u0026gt; queryForList(){\rConnection connection = null;\rResultSet rs = null;\rPreparedStatement stmt = null;\rList\u0026lt;Map\u0026lt;String,Object\u0026gt;\u0026gt; resultList = new ArrayList\u0026lt;\u0026gt;();\rtry {\r// 加载JDBC驱动\rClass.forName(\u0026quot;com.mysql.jdbc.Driver\u0026quot;).newInstance();\rString url = \u0026quot;jdbc:mysql://172.20.2.131:3506/journey?allowMultiQueries=true\u0026amp;Unicode=true\u0026amp;characterEncoding=UTF-8\u0026amp;useSSL=false\u0026quot;;\rString user = \u0026quot;loan\u0026quot;;\rString password = \u0026quot;JLpaymysql8.0!\u0026quot;;\r// 获取数据库连接\rconnection = DriverManager.getConnection(url,user,password);\rString sql = \u0026quot;select * from t_user where user_id = ? \u0026quot;;\r// 创建Statement对象（每一个Statement为一次数据库执行请求）\rstmt = connection.prepareStatement(sql);\r// 设置传入参数\rstmt.setString(1, \u0026quot;1027604989\u0026quot;);\r// 执行SQL语句\rrs = stmt.executeQuery();\r// 处理查询结果（将查询结果转换成List\u0026lt;Map\u0026gt;格式）\rResultSetMetaData rsmd = rs.getMetaData();\rint num = rsmd.getColumnCount();\rwhile(rs.next()){\rMap map = new HashMap();\rfor(int i = 0;i \u0026lt; num;i++){\rString columnName = rsmd.getColumnName(i+1);\rmap.put(columnName,rs.getString(columnName));\r}\rresultList.add(map);\r}\r} catch (Exception e) {\re.printStackTrace();\r} finally {\rtry {\r// 关闭结果集\rif (rs != null) {\rrs.close();\r}\r// 关闭执行\rif (stmt != null) {\rstmt.close();\r}\rif (connection != null) {\rconnection.close();\r}\r} catch (SQLException e) {\re.printStackTrace();\r}\r}\rreturn resultList;\r}\rpublic static void main(String[] args) {\rList\u0026lt;Map\u0026lt;String,Object\u0026gt;\u0026gt; list = queryForList();\rlog.info(\u0026quot;jdbc查询结果为:{}\u0026quot;, JSONObject.toJSONString(list));\r}\r}\r Mybatis MyBatis 是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。MyBatis 免除了几乎所有的 JDBC 代码以及设置参数和获取结果集的工作。MyBatis 可以通过简单的 XML 或注解来配置和映射原始类型、接口和 Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。\n使用 mybatis 一般有以下几步：\n  ","id":5,"section":"posts","summary":"mybatis 技术内幕学习 Jdbc 复习 通过JDBC查询数据库数据，一般需要以下七个步骤： 加载JDBC驱动； 建立并获取数据库连接； 创建 JDBC Statements 对象； 设置SQL语句的","tags":["mybatis"],"title":"mybatis 技术内幕学习","uri":"https://wzgl998877.github.io/2022/01/mybatis-%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E5%AD%A6%E4%B9%A0/","year":"2022"},{"content":"Netty 学习 虽然说netty，用的少但是感觉比较流行，值得研究！！！\nNetty 是一个 NIO 客户端-服务器框架，可以快速轻松地开发网络应用程序，例如协议服务器和客户端。它极大地简化和精简了网络编程，比如TCP和UDP 套接字服务器。\n那么什么是NIO？或者说什么是IO？\nIO I/O 其实就是 input 和 output 的缩写，即输入/输出。比如我们用键盘来敲代码其实就是输入，那显示器显示图案就是输出，这其实就是 I/O。\n  磁盘 I/O 指的是硬盘和内存之间的输入输出。读取本地文件的时候，要将磁盘的数据拷贝到内存中，修改本地文件的时候，需要把修改后的数据拷贝到磁盘中。\n  网络 I/O 指的是网卡与内存之间的输入输出。当网络上的数据到来时，网卡需要将数据拷贝到内存中。当要发送数据给网络上的其他人时，需要将数据从内存拷贝到网卡里。\n  那为什么都要跟内存交互呢?\n我们的指令最终是由 CPU 执行的，究其原因是 CPU 与内存交互的速度远高于 CPU 和这些外部设备直接交互的速度。\n因此都是和内存交互，当然假设没有内存，让 CPU 直接和外部设备交互，那也算 I/O。\n总结下：I/O 就是指内存与外部设备之间的交互（数据拷贝）。\n根据UNIX网络编程对I/O模型的分类，UNIX提供了5种I/O模型，阻塞I/O模型、非阻塞I/O模型、I/O复用模型、信号驱动I/O模型、异步I/O\n","id":6,"section":"posts","summary":"Netty 学习 虽然说netty，用的少但是感觉比较流行，值得研究！！！ Netty 是一个 NIO 客户端-服务器框架，可以快速轻松地开发网络应用程序，例如协议服务器和","tags":["Netty"],"title":"Netty 学习","uri":"https://wzgl998877.github.io/2022/01/netty-%E5%AD%A6%E4%B9%A0/","year":"2022"},{"content":"spring源码学习 ​\t对于学习spring源码肯定最重要的学习spring的一些理念，比如控制翻转ioc，依赖注入di，面向切面编程aop等等。\n​\tBeanFactory、BeanDefinition、ApplicationContext\n​\tioc容器的初始化是通过refresh() 方法启动的，这个方法标志着ioc容器的正式启动，这个启动包括了BeanDefinition的Resource定位、载入和注册三个基本过程。在这个过程中一般不包括Bean依赖的注入，在spring ioc中bean定义的载入和依赖的注入是两个独立的过程，依赖注入一般发生在应用第一次通过getBean向容器索取Bean的时候。但如果对某个Bean设置了lazyinit属性，那么这个bean的依赖注入在ioc初始化时就完成了。@Lazy注解可能就是这个原理。\nspring 整体架构 核心类介绍 DefaultListableBeanFactory ​\tXmlBeanFactory继承自DefaultListableBeanFactory，而DefaultListableBeanFactory是整个bean加载的核心部分，是Spring注册及加载bean的默认实现，而对于XmlBeanFactory与DefaultListableBeanFactory不同的地方其实是在XmlBeanFactory中使用了自定义的XML读取器XmlBeanDefinitionReader，实现了个性化的BeanDefinitionReader读取，DefaultListableBeanFactory继承了AbstractAutowireCapableBeanFactory并实现了ConfigurableListableBeanFactory以及BeanDefinitionRegistry接口。\nXmlBeanDefinitionReader ​\tXML配置文件的读取是Spring中重要的功能。整个XML配置文件读取的大致流程为：\n1. 通过继承自AbstractBeanDefinitionReader中的方法，来使用ResourLoader将资源文件路径转换为对应的Resource文件。\r2. 通过DocumentLoader对Resource文件进行转换，将Resource文件转换为Document文件。\r3. 通过实现接口BeanDefinitionDocumentReader的DefaultBeanDefinitionDocumentReader类对Document进行解析，并使用BeanDefinitionParserDelegate对Element进行解析。\r 从配置文件到bean 获取bean总代码\nBeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(\u0026quot;applicationContext.xml\u0026quot;));\r public XmlBeanFactory(Resource resource, BeanFactory parentBeanFactory) throws BeansException {\rsuper(parentBeanFactory);\r// 加载bean\rthis.reader.loadBeanDefinitions(resource);\r}\r loadBeanDefinition() 方法具体实现\npublic int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException {\rAssert.notNull(encodedResource, \u0026quot;EncodedResource must not be null\u0026quot;);\rif (logger.isInfoEnabled()) {\rlogger.info(\u0026quot;Loading XML bean definitions from \u0026quot; + encodedResource.getResource());\r}\r// 记录已经加载的资源\rSet\u0026lt;EncodedResource\u0026gt; currentResources = this.resourcesCurrentlyBeingLoaded.get();\rif (currentResources == null) {\rcurrentResources = new HashSet\u0026lt;EncodedResource\u0026gt;(4);\rthis.resourcesCurrentlyBeingLoaded.set(currentResources);\r}\rif (!currentResources.add(encodedResource)) {\rthrow new BeanDefinitionStoreException(\r\u0026quot;Detected cyclic loading of \u0026quot; + encodedResource + \u0026quot; - check your import definitions!\u0026quot;);\r}\rtry {\rInputStream inputStream = encodedResource.getResource().getInputStream();\rtry {\rInputSource inputSource = new InputSource(inputStream);\rif (encodedResource.getEncoding() != null) {\rinputSource.setEncoding(encodedResource.getEncoding());\r}\r// 核心部分\rreturn doLoadBeanDefinitions(inputSource, encodedResource.getResource());\r}\rfinally {\rinputStream.close();\r}\r}\rcatch (IOException ex) {\rthrow new BeanDefinitionStoreException(\r\u0026quot;IOException parsing XML document from \u0026quot; + encodedResource.getResource(), ex);\r}\rfinally {\rcurrentResources.remove(encodedResource);\rif (currentResources.isEmpty()) {\rthis.resourcesCurrentlyBeingLoaded.remove();\r}\r}\r}\r doLoadBeanDefinitions 方法具体实现\nprotected int doLoadBeanDefinitions(InputSource inputSource, Resource resource)\rthrows BeanDefinitionStoreException {\rtry {\r// 获取document\rDocument doc = doLoadDocument(inputSource, resource);\r// 注册bean\rreturn registerBeanDefinitions(doc, resource);\r}\rcatch (BeanDefinitionStoreException ex) {\rthrow ex;\r}\rcatch (SAXParseException ex) {\rthrow new XmlBeanDefinitionStoreException(resource.getDescription(),\r\u0026quot;Line \u0026quot; + ex.getLineNumber() + \u0026quot; in XML document from \u0026quot; + resource + \u0026quot; is invalid\u0026quot;, ex);\r}\rcatch (SAXException ex) {\rthrow new XmlBeanDefinitionStoreException(resource.getDescription(),\r\u0026quot;XML document from \u0026quot; + resource + \u0026quot; is invalid\u0026quot;, ex);\r}\rcatch (ParserConfigurationException ex) {\rthrow new BeanDefinitionStoreException(resource.getDescription(),\r\u0026quot;Parser configuration exception parsing XML from \u0026quot; + resource, ex);\r}\rcatch (IOException ex) {\rthrow new BeanDefinitionStoreException(resource.getDescription(),\r\u0026quot;IOException parsing XML document from \u0026quot; + resource, ex);\r}\rcatch (Throwable ex) {\rthrow new BeanDefinitionStoreException(resource.getDescription(),\r\u0026quot;Unexpected exception parsing XML document from \u0026quot; + resource, ex);\r}\r}\r 在上面冗长的代码中假如不考虑异常类的代码，其实只做了三件事，这三件事的每一件都必不可少。\n 获取对XML文件的验证模式。 加载XML文件，并得到对应的Document。 根据返回的Document注册Bean信息。  1. 获取XML的验证模式 ​\t如果设定了验证模式则使用设定的验证模式（可以通过对调用XmlBeanDefinitionReader中的setValidationMode方法进行设定），否则使用自动检测的方式,Spring用来自动检测验证模式的办法就是判断是否包含DOCTYPE，如果包含就是DTD，否则就是XSD。这里主要是验证xml是否符合规范从而保证了XML文件的正确性。\n2. 获取Document ​\t读取 xml 文件并返回 Document 对象\n3. 解析及注册BeanDefinitions ​\t提取和注册 bean\n注册bean的主要代码为\n/**\r* Register each bean definition within the given root {@code \u0026lt;beans/\u0026gt;} element.\r*/\rprotected void doRegisterBeanDefinitions(Element root) {\r// Any nested \u0026lt;beans\u0026gt; elements will cause recursion in this method. In\r// order to propagate and preserve \u0026lt;beans\u0026gt; default-* attributes correctly,\r// keep track of the current (parent) delegate, which may be null. Create\r// the new (child) delegate with a reference to the parent for fallback purposes,\r// then ultimately reset this.delegate back to its original (parent) reference.\r// this behavior emulates a stack of delegates without actually necessitating one.\rBeanDefinitionParserDelegate parent = this.delegate;\rthis.delegate = createDelegate(getReaderContext(), root, parent);\rif (this.delegate.isDefaultNamespace(root)) {\rString profileSpec = root.getAttribute(PROFILE_ATTRIBUTE);\rif (StringUtils.hasText(profileSpec)) {\rString[] specifiedProfiles = StringUtils.tokenizeToStringArray(\rprofileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS);\rif (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) {\rreturn;\r}\r}\r}\r// 模版方法模式，如果继承自DefaultBeanDefinitionDocumentReader的子类需要在Bean解析前后做一些处理的话，那么只需要重写这两个方法就可以了\r// 解析前处理，留给子类实现\rpreProcessXml(root);\r// 解析并注册BeanDefinition\rparseBeanDefinitions(root, this.delegate);\r// 解析后处理，留给子类实现\rpostProcessXml(root);\r parseBeanDefinitions 方法具体实现\nprotected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) {\r// 处理beans\rif (delegate.isDefaultNamespace(root)) {\rNodeList nl = root.getChildNodes();\rfor (int i = 0; i \u0026lt; nl.getLength(); i++) {\rNode node = nl.item(i);\rif (node instanceof Element) {\rElement ele = (Element) node;\rif (delegate.isDefaultNamespace(ele)) {\r// 处理bean默认标签\rparseDefaultElement(ele, delegate);\r}\relse {\r// 处理bean自定义标签\rdelegate.parseCustomElement(ele);\r}\r}\r}\r}\relse {\rdelegate.parseCustomElement(root);\r}\r}\r parseDefaultElement()具体实现\nprivate void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) {\r// 处理import标签\rif (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) {\rimportBeanDefinitionResource(ele);\r}\r// 处理alias标签\relse if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) {\rprocessAliasRegistration(ele);\r}\r// 处理bean标签\relse if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) {\rprocessBeanDefinition(ele, delegate);\r}\r// 处理beans标签\relse if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) {\r// recurse\rdoRegisterBeanDefinitions(ele);\r}\r}\r bean标签的解析及注册 /**\r* Process the given bean element, parsing the bean definition\r* and registering it with the registry.\r*/\rprotected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) {\r// 解析BeanDefinition\rBeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele);\rif (bdHolder != null) {\r// 还需要再次对自定义标签进行解析\rbdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder);\rtry {\r// Register the final decorated instance.\r// 注册bean\rBeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry());\r}\rcatch (BeanDefinitionStoreException ex) {\rgetReaderContext().error(\u0026quot;Failed to register bean definition with name '\u0026quot; +\rbdHolder.getBeanName() + \u0026quot;'\u0026quot;, ele, ex);\r}\r// Send registration event.发出响应事件\rgetReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder));\r}\r}\r bean标签的解析及注册主要分为如下几步：\n 解析BeanDefinition。首先委托BeanDefinitionDelegate类的parseBeanDefinitionElement方法进行元素解析，返回BeanDefinitionHolder类型的实例bdHolder，经过这个方法后，bdHolder实例已经包含我们配置文件中配置的各种属性了，例如class、name、id、alias之类的属性。 **对自定义标签进行解析。**当返回的bdHolder不为空的情况下若存在默认标签的子节点下再有自定义属性，还需要再次对自定义标签进行解析。 注册解析的BeanDefinition。解析完成后，需要对解析后的bdHolder进行注册，同样，注册操作委托给了Bean DefinitionReaderUtils的registerBeanDefinition方法。 发出响应事件。最后发出响应事件，通知想关的监听器，这个bean已经加载完成了。  主要分析bean的注册：\n注册解析的BeanDefinition beanDefinition的注册就是使用beanDefinition作为value，使用beanName作为key、然后放入map中。\n/**\r* Register the given bean definition with the given bean factory.\r* @param definitionHolder the bean definition including name and aliases\r* @param registry the bean factory to register with\r* @throws BeanDefinitionStoreException if registration failed\r*/\rpublic static void registerBeanDefinition(\rBeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry)\rthrows BeanDefinitionStoreException {\r// Register bean definition under primary name. 使用beanName做唯一标识注册\rString beanName = definitionHolder.getBeanName();\rregistry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());\r// Register aliases for bean name, if any.所有其他的别名\rString[] aliases = definitionHolder.getAliases();\rif (aliases != null) {\rfor (String alias : aliases) {\rregistry.registerAlias(beanName, alias);\r}\r}\r}\r 1.通过beanName注册BeanDefinition /** Map of bean definition objects, keyed by bean name */\r// 使用ConcurrentHashMap解决并发\rprivate final Map\u0026lt;String, BeanDefinition\u0026gt; beanDefinitionMap = new ConcurrentHashMap\u0026lt;String, BeanDefinition\u0026gt;(64);\r/** List of bean definition names, in registration order */\rprivate final List\u0026lt;String\u0026gt; beanDefinitionNames = new ArrayList\u0026lt;String\u0026gt;(64);\r/** List of names of manually registered singletons, in registration order */\rprivate final Set\u0026lt;String\u0026gt; manualSingletonNames = new LinkedHashSet\u0026lt;String\u0026gt;(16);\r/** Cached array of bean definition names in case of frozen configuration */\rprivate String[] frozenBeanDefinitionNames;\rpublic void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException {\rAssert.hasText(beanName, \u0026quot;Bean name must not be empty\u0026quot;);\rAssert.notNull(beanDefinition, \u0026quot;BeanDefinition must not be null\u0026quot;);\rif (beanDefinition instanceof AbstractBeanDefinition) {\rtry {\r// 注册前的最后一次校验\r((AbstractBeanDefinition)beanDefinition).validate();\r} catch (BeanDefinitionValidationException var4) {\rthrow new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, \u0026quot;Validation of bean definition failed\u0026quot;, var4);\r}\r}\rBeanDefinition oldBeanDefinition = (BeanDefinition)this.beanDefinitionMap.get(beanName);\r// 处理已经注册过的bean\rif (oldBeanDefinition != null) {\rif (!this.isAllowBeanDefinitionOverriding()) {\rthrow new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, \u0026quot;Cannot register bean definition [\u0026quot; + beanDefinition + \u0026quot;] for bean '\u0026quot; + beanName + \u0026quot;': There is already [\u0026quot; + oldBeanDefinition + \u0026quot;] bound.\u0026quot;);\r}\rif (oldBeanDefinition.getRole() \u0026lt; beanDefinition.getRole()) {\rif (this.logger.isWarnEnabled()) {\rthis.logger.warn(\u0026quot;Overriding user-defined bean definition for bean '\u0026quot; + beanName + \u0026quot;' with a framework-generated bean definition: replacing [\u0026quot; + oldBeanDefinition + \u0026quot;] with [\u0026quot; + beanDefinition + \u0026quot;]\u0026quot;);\r}\r} else if (this.logger.isInfoEnabled()) {\rthis.logger.info(\u0026quot;Overriding bean definition for bean '\u0026quot; + beanName + \u0026quot;': replacing [\u0026quot; + oldBeanDefinition + \u0026quot;] with [\u0026quot; + beanDefinition + \u0026quot;]\u0026quot;);\r}\r} else {\r// 记录beanName\rthis.beanDefinitionNames.add(beanName);\r// 在单例set中删除改bean，因为这是二次注册了\rthis.manualSingletonNames.remove(beanName);\rthis.frozenBeanDefinitionNames = null;\r}\r// 注册bean，也就是放入map中\rthis.beanDefinitionMap.put(beanName, beanDefinition);\rif (oldBeanDefinition != null || this.containsSingleton(beanName)) {\r// 重置所有beanName对应的缓存\rthis.resetBeanDefinition(beanName);\r}\r}\r 通过beanName注册bean主要流程\n 对AbstractBeanDefinition的校验。在解析XML文件的时候我们提过校验，但是此校验非彼校验，之前的校验时针对于XML格式的校验，而此时的校验时针是对于AbstractBean Definition的methodOverrides属性的。 对beanName已经注册的情况的处理。如果设置了不允许bean的覆盖，则需要抛出异常，如果oldBeanDefinition.getRole() \u0026lt; beanDefinition.getRole() 则打日志提醒，否则直接覆盖。 注册bean，也就是放入map中。 清除解析之前留下的对应beanName的缓存。  2. 通过别名注册BeanDefinition /** Map from alias to canonical name */\rprivate final Map\u0026lt;String, String\u0026gt; aliasMap = new ConcurrentHashMap\u0026lt;String, String\u0026gt;(16);\r@Override\rpublic void registerAlias(String name, String alias) {\rAssert.hasText(name, \u0026quot;'name' must not be empty\u0026quot;);\rAssert.hasText(alias, \u0026quot;'alias' must not be empty\u0026quot;);\r// 如果beanName与alias相同不记录alias，并删除对应的alias\rif (alias.equals(name)) {\rthis.aliasMap.remove(alias);\r}\relse {\rif (!allowAliasOverriding()) {\rString registeredName = this.aliasMap.get(alias);\rif (registeredName != null \u0026amp;\u0026amp; !registeredName.equals(name)) {\rthrow new IllegalStateException(\u0026quot;Cannot register alias '\u0026quot; + alias + \u0026quot;' for name '\u0026quot; +\rname + \u0026quot;': It is already registered for name '\u0026quot; + registeredName + \u0026quot;'.\u0026quot;);\r}\r}\r// 检查给定的名称是否指向另一个方向的别名，捕获一个循环引用并抛出相应的IllegalStateException。\r// 当b是a的别名，如果这时候有c是a的别名，b是c的别名，那么a就有引用指向了b，这时候就有两个指向b所以报错，if a-\u0026gt;b,exist a-\u0026gt;c-\u0026gt;b 报错\rcheckForAliasCircle(name, alias);\rthis.aliasMap.put(alias, name);\r}\r}\r 主要流程：\n alias与beanName相同情况处理。若alias与beanName并名称相同则不需要处理并删除掉原有alias。 alias覆盖处理。若aliasName已经使用并已经指向了另一beanName则需要用户的设置进行处理。 alias循环检查。当A-\u0026gt;B存在时，若再次出现A-\u0026gt;C-\u0026gt;B时候则会抛出异常。 注册alias。  bean 的加载 protected \u0026lt;T\u0026gt; T doGetBean(\rfinal String name, final Class\u0026lt;T\u0026gt; requiredType, final Object[] args, boolean typeCheckOnly)\rthrows BeansException {\rfinal String beanName = transformedBeanName(name);\rObject bean;\r// Eagerly check singleton cache for manually registered singletons.\r// 从三级缓存中获取单例bean\rObject sharedInstance = getSingleton(beanName);\rif (sharedInstance != null \u0026amp;\u0026amp; args == null) {\rif (logger.isDebugEnabled()) {\rif (isSingletonCurrentlyInCreation(beanName)) {\rlogger.debug(\u0026quot;Returning eagerly cached instance of singleton bean '\u0026quot; + beanName +\r\u0026quot;' that is not fully initialized yet - a consequence of a circular reference\u0026quot;);\r}\relse {\rlogger.debug(\u0026quot;Returning cached instance of singleton bean '\u0026quot; + beanName + \u0026quot;'\u0026quot;);\r}\r}\r// 从bean的实例中获取对象\rbean = getObjectForBeanInstance(sharedInstance, name, beanName, null);\r}\relse {\r// Fail if we're already creating this bean instance:\r// We're assumably within a circular reference.\r// 原型模式的bean 存在循环依赖直接报错\rif (isPrototypeCurrentlyInCreation(beanName)) {\rthrow new BeanCurrentlyInCreationException(beanName);\r}\r// Check if bean definition exists in this factory.\rBeanFactory parentBeanFactory = getParentBeanFactory();\rif (parentBeanFactory != null \u0026amp;\u0026amp; !containsBeanDefinition(beanName)) {\r// Not found -\u0026gt; check parent.\rString nameToLookup = originalBeanName(name);\rif (args != null) {\r// Delegation to parent with explicit args.\rreturn (T) parentBeanFactory.getBean(nameToLookup, args);\r}\relse {\r// No args -\u0026gt; delegate to standard getBean method.\rreturn parentBeanFactory.getBean(nameToLookup, requiredType);\r}\r}\rif (!typeCheckOnly) {\rmarkBeanAsCreated(beanName);\r}\rtry {\rfinal RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);\rcheckMergedBeanDefinition(mbd, beanName, args);\r// Guarantee initialization of beans that the current bean depends on.\rString[] dependsOn = mbd.getDependsOn();\rif (dependsOn != null) {\rfor (String dependsOnBean : dependsOn) {\rif (isDependent(beanName, dependsOnBean)) {\rthrow new BeanCreationException(mbd.getResourceDescription(), beanName,\r\u0026quot;Circular depends-on relationship between '\u0026quot; + beanName + \u0026quot;' and '\u0026quot; + dependsOnBean + \u0026quot;'\u0026quot;);\r}\rregisterDependentBean(dependsOnBean, beanName);\rgetBean(dependsOnBean);\r}\r}\r// Create bean instance.\rif (mbd.isSingleton()) {\r// 创建 bean 实例\rsharedInstance = getSingleton(beanName, new ObjectFactory\u0026lt;Object\u0026gt;() {\r@Override\rpublic Object getObject() throws BeansException {\rtry {\rreturn createBean(beanName, mbd, args);\r}\rcatch (BeansException ex) {\r// Explicitly remove instance from singleton cache: It might have been put there\r// eagerly by the creation process, to allow for circular reference resolution.\r// Also remove any beans that received a temporary reference to the bean.\rdestroySingleton(beanName);\rthrow ex;\r}\r}\r});\rbean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);\r}\relse if (mbd.isPrototype()) {\r// It's a prototype -\u0026gt; create a new instance.\rObject prototypeInstance = null;\rtry {\rbeforePrototypeCreation(beanName);\rprototypeInstance = createBean(beanName, mbd, args);\r}\rfinally {\rafterPrototypeCreation(beanName);\r}\rbean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);\r}\relse {\rString scopeName = mbd.getScope();\rfinal Scope scope = this.scopes.get(scopeName);\rif (scope == null) {\rthrow new IllegalStateException(\u0026quot;No Scope registered for scope '\u0026quot; + scopeName + \u0026quot;'\u0026quot;);\r}\rtry {\rObject scopedInstance = scope.get(beanName, new ObjectFactory\u0026lt;Object\u0026gt;() {\r@Override\rpublic Object getObject() throws BeansException {\rbeforePrototypeCreation(beanName);\rtry {\rreturn createBean(beanName, mbd, args);\r}\rfinally {\rafterPrototypeCreation(beanName);\r}\r}\r});\rbean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd);\r}\rcatch (IllegalStateException ex) {\rthrow new BeanCreationException(beanName,\r\u0026quot;Scope '\u0026quot; + scopeName + \u0026quot;' is not active for the current thread; \u0026quot; +\r\u0026quot;consider defining a scoped proxy for this bean if you intend to refer to it from a singleton\u0026quot;,\rex);\r}\r}\r}\rcatch (BeansException ex) {\rcleanupAfterBeanCreationFailure(beanName);\rthrow ex;\r}\r}\r// Check if required type matches the type of the actual bean instance.\rif (requiredType != null \u0026amp;\u0026amp; bean != null \u0026amp;\u0026amp; !requiredType.isAssignableFrom(bean.getClass())) {\rtry {\rreturn getTypeConverter().convertIfNecessary(bean, requiredType);\r}\rcatch (TypeMismatchException ex) {\rif (logger.isDebugEnabled()) {\rlogger.debug(\u0026quot;Failed to convert bean '\u0026quot; + name + \u0026quot;' to required type [\u0026quot; +\rClassUtils.getQualifiedName(requiredType) + \u0026quot;]\u0026quot;, ex);\r}\rthrow new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());\r}\r}\rreturn (T) bean;\r}\r 缓存中获取单例bean ​\t单例在Spring的同一个容器内只会被创建一次，后续再获取bean直接从单例缓存中获取，当然这里也只是尝试加载，首先尝试从缓存中加载，然后再次尝试尝试从singletonFactories中加载。因为在创建单例bean的时候会存在依赖注入的情况，而在创建依赖的时候为了避免循环依赖， Spring创建bean的原则是不等bean创建完成就会将创建bean的ObjectFactory提早曝光加入到缓存中，一旦下一个bean创建时需要依赖上个bean，则直接使用ObjectFactory。\n主要代码：\n/** Cache of singleton objects: bean name --\u0026gt; bean instance */\r// singletonObjects：完成初始化的单例对象的cache（一级缓存）\rprivate final Map\u0026lt;String, Object\u0026gt; singletonObjects = new ConcurrentHashMap\u0026lt;String, Object\u0026gt;(64);\r// 当前正在创建bean\r/** Names of beans that are currently in creation */\rprivate final Set\u0026lt;String\u0026gt; singletonsCurrentlyInCreation =\rCollections.newSetFromMap(new ConcurrentHashMap\u0026lt;String, Boolean\u0026gt;(16));\r// 完成实例化但是尚未初始化的，提前暴光的单例对象的Cache （二级缓存）\r/** Cache of early singleton objects: bean name --\u0026gt; bean instance */\rprivate final Map\u0026lt;String, Object\u0026gt; earlySingletonObjects = new HashMap\u0026lt;String, Object\u0026gt;(16);\r/** Cache of singleton factories: bean name --\u0026gt; ObjectFactory */\r// 进入实例化阶段的单例对象工厂的cache （三级缓存）\rprivate final Map\u0026lt;String, ObjectFactory\u0026lt;?\u0026gt;\u0026gt; singletonFactories = new HashMap\u0026lt;String, ObjectFactory\u0026lt;?\u0026gt;\u0026gt;(16);\rprotected Object getSingleton(String beanName, boolean allowEarlyReference) {\r// 从一级缓存中查找\rObject singletonObject = this.singletonObjects.get(beanName);\rif (singletonObject == null \u0026amp;\u0026amp; isSingletonCurrentlyInCreation(beanName)) {\rsynchronized (this.singletonObjects) {\r// 从二级缓存中查找\rsingletonObject = this.earlySingletonObjects.get(beanName);\rif (singletonObject == null \u0026amp;\u0026amp; allowEarlyReference) {\r// 从三级缓存中查找\rObjectFactory\u0026lt;?\u0026gt; singletonFactory = this.singletonFactories.get(beanName);\rif (singletonFactory != null) {\rsingletonObject = singletonFactory.getObject();\r// 放入二级缓存\rthis.earlySingletonObjects.put(beanName, singletonObject);\r// 从三级缓存移除\rthis.singletonFactories.remove(beanName);\r}\r}\r}\r}\rreturn (singletonObject != NULL_OBJECT ? singletonObject : null);\r}\r 这段代码解决了著名的循环依赖问题\n循环依赖：其实就是循环引用，也就是两个或者两个以上的bean互相持有对方，最终形成闭环。比如A依赖于B，B依赖于C，C又依赖于A。\n首先以自己写代码为例，出现循环引用的情况：\npackage com.zt.javastudy.spring;\r/**\r* @author zhengtao\r* @description 测试循环依赖\r* @date 2021/4/9\r*/\rpublic class TestXunHuan{\rpublic static void main(String[] args) {\rSystem.out.println(new StudentC());\r}\r}\r/**\r* StudentC与StudentD存在循环引用\r*/\rclass StudentC {\rpublic StudentC() {\rnew StudentD();\r}\r}\rclass StudentD {\rpublic StudentD() {\rnew StudentC();\r}\r}\r 结果栈溢出：\nException in thread \u0026quot;main\u0026quot; java.lang.StackOverflowError\r spring中循环依赖的三种情况：\n  构造器注入循环依赖   @Service\rpublic class StudentA {\rprivate StudentB b;\rpublic StudentB getB() {\rreturn b;\r}\rpublic void setB(StudentB b) {\rthis.b = b;\r}\r/**\r* 构造函数循环依赖\r* @param b\r*/\rpublic StudentA(StudentB b) {\rthis.b = b;\r}\r}\r@Service\rpublic class StudentB {\rprivate StudentA a;\rpublic StudentA getA() {\rreturn a;\r}\rpublic void setA(StudentA a) {\rthis.a = a;\r}\r/**\r* 构造函数循环依赖\r* @param a\r*/\rpublic StudentB(StudentA a) {\rthis.a = a;\r}\r}\r   field属性注入（setter方法注入）循环依赖 @Service\rpublic class StudentA {\r@Autowired\rprivate StudentB b;\rpublic StudentB getB() {\rreturn b;\r}\rpublic void setB(StudentB b) {\rthis.b = b;\r}\r}\r@Service\rpublic class StudentB {\r@Autowired\rprivate StudentA a;\rpublic StudentA getA() {\rreturn a;\r}\rpublic void setA(StudentA a) {\rthis.a = a;\r}\r}\r   prototype原型模式 field属性注入循环依赖 // 原型模式\r@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)\r@Service\rpublic class StudentA {\r@Autowired\rprivate StudentB b;\rpublic StudentB getB() {\rreturn b;\r}\rpublic void setB(StudentB b) {\rthis.b = b;\r}\r}\r// 原型模式\r@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)\r@Service\rpublic class StudentB {\r@Autowired\rprivate StudentA a;\rpublic StudentA getA() {\rreturn a;\r}\rpublic void setA(StudentA a) {\rthis.a = a;\r}\r}\r spring 中帮我们解决了第二种field属性注入（setter方法注入）循环依赖， 是使用了三级缓存的方式来解决的：\n 先从一级缓存singletonObjects中去获取。（如果获取到就直接return） 如果获取不到或者对象正在创建中（isSingletonCurrentlyInCreation()），那就再从二级缓存earlySingletonObjects中获取。（如果获取到就直接return） 如果还是获取不到，且允许singletonFactories（allowEarlyReference=true）通过getObject()获取。就从三级缓存singletonFactory.getObject()获取。（如果获取到了就从singletonFactories中移除，并且放进earlySingletonObjects。其实也就是从三级缓存移动（是剪切、不是复制哦~）**到了二级缓存）  加入singletonFactories三级缓存的前提是执行了构造器，所以构造器的循环依赖没法解决\n  这样的意义是什么呢？\n​\tA首先完成了初始化的第一步，并且将自己提前曝光到singletonFactories中也就是加入到三级缓存中，此时进行初始化的第二步，发现自己依赖对象B，此时就尝试去get(B)，发现B还没有被create，所以走create流程，B在初始化第一步的时候发现自己依赖了对象A，于是尝试get(A)，尝试一级缓存singletonObjects(肯定没有，因为A还没初始化完全)，尝试二级缓存earlySingletonObjects（也没有），尝试三级缓存singletonFactories，由于A通过ObjectFactory将自己提前曝光了，所以B能够通过ObjectFactory.getObject拿到A对象(虽然A还没有初始化完全，但是总比没有好呀)，B拿到A对象后顺利完成了初始化阶段1、2、3，完全初始化之后将自己放入到一级缓存singletonObjects中。此时返回A中，A此时能拿到B的对象顺利完成自己的初始化阶段2、3，最终A也完成了初始化，进去了一级缓存singletonObjects中，而且更加幸运的是，由于B拿到了A的对象引用而A现在已经完成了初始化，所以B现在拿到的A对象已经完成了初始化。\n从bean的实例中获取对象 ​\t调用该方法getObjectForBeanInstance()得到对象\n 对FactoryBean正确性的验证。 对非FactoryBean不做任何处理。 对bean进行转换。 将从Factory中解析bean的工作委托给getObjectFromFactoryBean。  获取单例 如果缓存中不存在已经加载的单例bean就需要从头开始bean的加载过程了，而Spring中使用getSingleton的重载方法实现bean的加载过程。\npublic Object getSingleton(String beanName, ObjectFactory\u0026lt;?\u0026gt; singletonFactory) {\rAssert.notNull(beanName, \u0026quot;Bean name must not be null\u0026quot;);\rsynchronized (this.singletonObjects) {\r// 一级缓存\rObject singletonObject = this.singletonObjects.get(beanName);\rif (singletonObject == null) {\r// 是否正在创建中\rif (this.singletonsCurrentlyInDestruction) {\rthrow new BeanCreationNotAllowedException(beanName,\r\u0026quot;Singleton bean creation not allowed while singletons of this factory are in destruction \u0026quot; +\r\u0026quot;(Do not request a bean from a BeanFactory in a destroy method implementation!)\u0026quot;);\r}\rif (logger.isDebugEnabled()) {\rlogger.debug(\u0026quot;Creating shared instance of singleton bean '\u0026quot; + beanName + \u0026quot;'\u0026quot;);\r}\r// 记录加载状态\rbeforeSingletonCreation(beanName);\rboolean newSingleton = false;\rboolean recordSuppressedExceptions = (this.suppressedExceptions == null);\rif (recordSuppressedExceptions) {\rthis.suppressedExceptions = new LinkedHashSet\u0026lt;\u0026gt;();\r}\rtry {\r// 获得实例\rsingletonObject = singletonFactory.getObject();\rnewSingleton = true;\r}\rcatch (IllegalStateException ex) {\r// Has the singleton object implicitly appeared in the meantime -\u0026gt;\r// if yes, proceed with it since the exception indicates that state.\rsingletonObject = this.singletonObjects.get(beanName);\rif (singletonObject == null) {\rthrow ex;\r}\r}\rcatch (BeanCreationException ex) {\rif (recordSuppressedExceptions) {\rfor (Exception suppressedException : this.suppressedExceptions) {\rex.addRelatedCause(suppressedException);\r}\r}\rthrow ex;\r}\rfinally {\rif (recordSuppressedExceptions) {\rthis.suppressedExceptions = null;\r}\r// 清除加载状态\rafterSingletonCreation(beanName);\r}\rif (newSingleton) {\r// 加入缓存\raddSingleton(beanName, singletonObject);\r}\r}\rreturn singletonObject;\r}\r}\r// this.singletonsCurrentlyInCreation.add(beanName) 将该bean加入正在加载的bean set集合中\rprotected void beforeSingletonCreation(String beanName) {\rif (!this.inCreationCheckExclusions.contains(beanName) \u0026amp;\u0026amp; !this.singletonsCurrentlyInCreation.add(beanName)) {\rthrow new BeanCurrentlyInCreationException(beanName);\r}\r}\r// this.singletonsCurrentlyInCreation.remove(beanName) 将该bean从正在加载bean的set集合中删除\rprotected void afterSingletonCreation(String beanName) {\rif (!this.inCreationCheckExclusions.contains(beanName) \u0026amp;\u0026amp; !this.singletonsCurrentlyInCreation.remove(beanName)) {\rthrow new IllegalStateException(\u0026quot;Singleton '\u0026quot; + beanName + \u0026quot;' isn't currently in creation\u0026quot;);\r}\r}\r// 清除二、三级缓存加入一级缓存\rprotected void addSingleton(String beanName, Object singletonObject) {\rsynchronized (this.singletonObjects) {\r// 加入一级缓存\rthis.singletonObjects.put(beanName, singletonObject);\r// 从三级缓存移除\rthis.singletonFactories.remove(beanName);\r// 从二级缓存移除\rthis.earlySingletonObjects.remove(beanName);\r// 加入单例注册set\rthis.registeredSingletons.add(beanName);\r}\r}\r 准备创建bean protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args)\rthrows BeanCreationException {\rif (logger.isTraceEnabled()) {\rlogger.trace(\u0026quot;Creating instance of bean '\u0026quot; + beanName + \u0026quot;'\u0026quot;);\r}\rRootBeanDefinition mbdToUse = mbd;\r// Make sure bean class is actually resolved at this point, and\r// clone the bean definition in case of a dynamically resolved Class\r// which cannot be stored in the shared merged bean definition.\r// 解析class\rClass\u0026lt;?\u0026gt; resolvedClass = resolveBeanClass(mbd, beanName);\rif (resolvedClass != null \u0026amp;\u0026amp; !mbd.hasBeanClass() \u0026amp;\u0026amp; mbd.getBeanClassName() != null) {\rmbdToUse = new RootBeanDefinition(mbd);\rmbdToUse.setBeanClass(resolvedClass);\r}\r// Prepare method overrides.\rtry {\r// 验证和准备 覆盖的方法\rmbdToUse.prepareMethodOverrides();\r}\rcatch (BeanDefinitionValidationException ex) {\rthrow new BeanDefinitionStoreException(mbdToUse.getResourceDescription(),\rbeanName, \u0026quot;Validation of method overrides failed\u0026quot;, ex);\r}\rtry {\r// Give BeanPostProcessors a chance to return a proxy instead of the target bean instance.\r// 给BeanPostProcessors一个返回代理而不是目标bean实例的机会\rObject bean = resolveBeforeInstantiation(beanName, mbdToUse);\rif (bean != null) {\rreturn bean;\r}\r}\rcatch (Throwable ex) {\rthrow new BeanCreationException(mbdToUse.getResourceDescription(), beanName,\r\u0026quot;BeanPostProcessor before instantiation of bean failed\u0026quot;, ex);\r}\rtry {\r// 真正创建bean\rObject beanInstance = doCreateBean(beanName, mbdToUse, args);\rif (logger.isTraceEnabled()) {\rlogger.trace(\u0026quot;Finished creating instance of bean '\u0026quot; + beanName + \u0026quot;'\u0026quot;);\r}\rreturn beanInstance;\r}\rcatch (BeanCreationException | ImplicitlyAppearedSingletonException ex) {\r// A previously detected exception with proper bean creation context already,\r// or illegal singleton state to be communicated up to DefaultSingletonBeanRegistry.\rthrow ex;\r}\rcatch (Throwable ex) {\rthrow new BeanCreationException(\rmbdToUse.getResourceDescription(), beanName, \u0026quot;Unexpected exception during bean creation\u0026quot;, ex);\r}\r}\r 这段代码可以分为：\n resolveBeanClass，根据设置的class属性或者根据className来解析Class。 mbdToUse.prepareMethodOverrides()，对override属性进行标记及验证。 Object bean = resolveBeforeInstantiation(beanName, mbdToUse)，应用初始化前的后处理器，解析指定bean是否存在初始化前的短路操作。aop功能就是基于这里的 Object beanInstance = doCreateBean(beanName, mbdToUse, args)，真正核心，创建bean。  创建bean protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args)\rthrows BeanCreationException {\r// Instantiate the bean.\rBeanWrapper instanceWrapper = null;\rif (mbd.isSingleton()) {\rinstanceWrapper = this.factoryBeanInstanceCache.remove(beanName);\r}\rif (instanceWrapper == null) {\r// 实例化，调用构造方法实例化对象\rinstanceWrapper = createBeanInstance(beanName, mbd, args);\r}\rObject bean = instanceWrapper.getWrappedInstance();\rClass\u0026lt;?\u0026gt; beanType = instanceWrapper.getWrappedClass();\rif (beanType != NullBean.class) {\rmbd.resolvedTargetType = beanType;\r}\r// Allow post-processors to modify the merged bean definition.\rsynchronized (mbd.postProcessingLock) {\rif (!mbd.postProcessed) {\rtry {\rapplyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);\r}\rcatch (Throwable ex) {\rthrow new BeanCreationException(mbd.getResourceDescription(), beanName,\r\u0026quot;Post-processing of merged bean definition failed\u0026quot;, ex);\r}\rmbd.postProcessed = true;\r}\r}\r// Eagerly cache singletons to be able to resolve circular references\r// even when triggered by lifecycle interfaces like BeanFactoryAware.\rboolean earlySingletonExposure = (mbd.isSingleton() \u0026amp;\u0026amp; this.allowCircularReferences \u0026amp;\u0026amp;\risSingletonCurrentlyInCreation(beanName));\rif (earlySingletonExposure) {\rif (logger.isTraceEnabled()) {\rlogger.trace(\u0026quot;Eagerly caching bean '\u0026quot; + beanName +\r\u0026quot;' to allow for resolving potential circular references\u0026quot;);\r}\r// 添加三级缓存\raddSingletonFactory(beanName, () -\u0026gt; getEarlyBeanReference(beanName, mbd, bean));\r}\r// Initialize the bean instance.\rObject exposedObject = bean;\rtry {\r// 填充属性\rpopulateBean(beanName, mbd, instanceWrapper);\r// 调用init方法初始化bean\rexposedObject = initializeBean(beanName, exposedObject, mbd);\r}\rcatch (Throwable ex) {\rif (ex instanceof BeanCreationException \u0026amp;\u0026amp; beanName.equals(((BeanCreationException) ex).getBeanName())) {\rthrow (BeanCreationException) ex;\r}\relse {\rthrow new BeanCreationException(\rmbd.getResourceDescription(), beanName, \u0026quot;Initialization of bean failed\u0026quot;, ex);\r}\r}\r// 循环依赖检查\rif (earlySingletonExposure) {\rObject earlySingletonReference = getSingleton(beanName, false);\rif (earlySingletonReference != null) {\rif (exposedObject == bean) {\rexposedObject = earlySingletonReference;\r}\relse if (!this.allowRawInjectionDespiteWrapping \u0026amp;\u0026amp; hasDependentBean(beanName)) {\rString[] dependentBeans = getDependentBeans(beanName);\rSet\u0026lt;String\u0026gt; actualDependentBeans = new LinkedHashSet\u0026lt;\u0026gt;(dependentBeans.length);\rfor (String dependentBean : dependentBeans) {\rif (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) {\ractualDependentBeans.add(dependentBean);\r}\r}\rif (!actualDependentBeans.isEmpty()) {\rthrow new BeanCurrentlyInCreationException(beanName,\r\u0026quot;Bean with name '\u0026quot; + beanName + \u0026quot;' has been injected into other beans [\u0026quot; +\rStringUtils.collectionToCommaDelimitedString(actualDependentBeans) +\r\u0026quot;] in its raw version as part of a circular reference, but has eventually been \u0026quot; +\r\u0026quot;wrapped. This means that said other beans do not use the final version of the \u0026quot; +\r\u0026quot;bean. This is often the result of over-eager type matching - consider using \u0026quot; +\r\u0026quot;'getBeanNamesForType' with the 'allowEagerInit' flag turned off, for example.\u0026quot;);\r}\r}\r}\r}\r// Register bean as disposable.\rtry {\rregisterDisposableBeanIfNecessary(beanName, bean, mbd);\r}\rcatch (BeanDefinitionValidationException ex) {\rthrow new BeanCreationException(\rmbd.getResourceDescription(), beanName, \u0026quot;Invalid destruction signature\u0026quot;, ex);\r}\rreturn exposedObject;\r}\r 创建bean的实例:createBeanInstance() 该方法作用为实例化 bean\n 如果存在工厂方法则使用工厂方法进行初始化。 一个类有多个构造函数，每个构造函数都有不同的参数，所以需要根据参数锁定构造函数并进行初始化。 如果既不存在工厂方法也不存在带有参数的构造函数，则使用默认的构造函数进行bean的实例化。  解决循环依赖:addSingletonFactory() protected void addSingletonFactory(String beanName, ObjectFactory\u0026lt;?\u0026gt; singletonFactory) {\rAssert.notNull(singletonFactory, \u0026quot;Singleton factory must not be null\u0026quot;);\rsynchronized (this.singletonObjects) {\rif (!this.singletonObjects.containsKey(beanName)) {\r// 加入三级缓存\rthis.singletonFactories.put(beanName, singletonFactory);\r// 删除二级缓存\rthis.earlySingletonObjects.remove(beanName);\rthis.registeredSingletons.add(beanName);\r}\r}\r}\r 创建完bean的实例后，将该单例提早曝光， 将创建该单例的工厂加入三级缓存\n属性注入:populateBean() 主要功能就是属性填充\n主要流程为：\n  根据注入类型（byName/byType），提取依赖的bean，并统一存入PropertyValues中。\nprotected void autowireByName(\rString beanName, AbstractBeanDefinition mbd, BeanWrapper bw, MutablePropertyValues pvs) {\rString[] propertyNames = unsatisfiedNonSimpleProperties(mbd, bw);\rfor (String propertyName : propertyNames) {\rif (containsBean(propertyName)) {\r// 递归调用getBean()\rObject bean = getBean(propertyName);\rpvs.add(propertyName, bean);\rregisterDependentBean(propertyName, beanName);\rif (logger.isTraceEnabled()) {\rlogger.trace(\u0026quot;Added autowiring by name from bean name '\u0026quot; + beanName +\r\u0026quot;' via property '\u0026quot; + propertyName + \u0026quot;' to bean named '\u0026quot; + propertyName + \u0026quot;'\u0026quot;);\r}\r}\relse {\rif (logger.isTraceEnabled()) {\rlogger.trace(\u0026quot;Not autowiring property '\u0026quot; + propertyName + \u0026quot;' of bean '\u0026quot; + beanName +\r\u0026quot;' by name: no matching bean found\u0026quot;);\r}\r}\r}\r}\r 这里面主要流程是在传入的参数pvs中找出已经加载的bean，并递归实例化，进而加入到pvs中\n  将所有PropertyValues中的属性填充至BeanWrapper中\n现在已经完成了对所有注入属性的获取，但是获取的属性是以PropertyValues形式存在的，还并没有应用到已经实例化的bean中，这一工作是在applyPropertyValues中完成。\n  初始化bean:initializeBean() ​\tSpring中程序已经执行过bean的实例化，并且进行了属性的填充，而就在这时将会调用用户设定的初始化方法。\n循环依赖检查 如果存在循环依赖，所以此时候代理对象还在二级缓存里~~~（备注：本利讲解的是自己被循环依赖了的情况） so，此处getSingleton()，就会把里面的对象拿出来，我们知道此时候它已经是个Proxy代理对象~~~\r最后赋值给 exposedObject 然后return出去，进而最终被addSingleton()添加进一级缓存里面去 这样就保证了我们容器里**最终实际上是代理对象**，而非原始对象~~~~~\r 从spring的启动开始 ​\t前面看了那么多觉得这本书讲的很多东西都没啥用，这一章讲的就是项目用到的spring的启动方式。\npublic class AccpServiceBoostrap {\rprivate static final Logger logger = Logger.getLogger(AccpServiceBoostrap.class);\rpublic static void main(String[] args) {\rlogger.info(\u0026quot;starting accp service\u0026quot;);\r@SuppressWarnings({ \u0026quot;resource\u0026quot;, \u0026quot;unused\u0026quot; })\rApplicationContext applicationContext = new ClassPathXmlApplicationContext(\u0026quot;classpath*:applicationContext.xml\u0026quot;);\rlogger.info(\u0026quot;accp service start ok.\u0026quot;);\r}\r}\r ApplicationContext和BeanFacotry两者都是用于加载Bean的，但是相比之下，ApplicationContext提供了更多的扩展功能，简单一点说：ApplicationContext包含BeanFactory的所有功能。通常建议比BeanFactory优先，除非在一些限制的场合，比如字节长度对内存有很大的影响时\n接下来，就跟着这本书将这句代码读通吧，冲啊。\n/**\r* Create a new ClassPathXmlApplicationContext, loading the definitions\r* from the given XML file and automatically refreshing the context.\r* @param configLocation resource location\r* @throws BeansException if context creation failed\r*/\rpublic ClassPathXmlApplicationContext(String configLocation) throws BeansException {\rthis(new String[] {configLocation}, true, null);\r}\r 注释翻译：创建一个新的ClassPathXmlApplicationContext，从给定的XML文件中加载定义，并自动刷新上下文\npublic ClassPathXmlApplicationContext(\rString[] configLocations, boolean refresh, @Nullable ApplicationContext parent)\rthrows BeansException {\r// 执行构造函数\rsuper(parent);\r// 设置配置路径,解析给定的路径数组\rsetConfigLocations(configLocations);\rif (refresh) {\r// 核心方法\rrefresh();\r}\r}\r public void setConfigLocations(@Nullable String... locations) {\rif (locations != null) {\rAssert.noNullElements(locations, \u0026quot;Config locations must not be null\u0026quot;);\rthis.configLocations = new String[locations.length];\rfor (int i = 0; i \u0026lt; locations.length; i++) {\rthis.configLocations[i] = resolvePath(locations[i]).trim();\r}\r}\relse {\rthis.configLocations = null;\r}\r}\r 此函数主要用于解析给定的路径数组，当然，如果数组中包含特殊符号，如${var}占位符，那么在resolvePath中会搜寻匹配的系统变量并替换。\n比如我们项目中\nApplicationContext applicationContext = new ClassPathXmlApplicationContext(\u0026quot;classpath*:applicationContext.xml\u0026quot;);\r 这里面classpath*就是占位符的使用相当于，\nclasspath：只会到你的class路径中查找找文件。\nclasspath*：不仅包含class路径，还包括jar文件中（class路径）进行查找。\n主要讲一下核心方法 refresh()\npublic void refresh() throws BeansException, IllegalStateException {\rsynchronized (this.startupShutdownMonitor) {\rStartupStep contextRefresh = this.applicationStartup.start(\u0026quot;spring.context.refresh\u0026quot;);\r// Prepare this context for refreshing.\r// 准备环境\rprepareRefresh();\r// Tell the subclass to refresh the internal bean factory.\r// 初始化BeanFactory，并进行xml文件读取\rConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();\r// Prepare the bean factory for use in this context.\r// 对BeanFactory进行各种功能填充\rprepareBeanFactory(beanFactory);\rtry {\r// Allows post-processing of the bean factory in context subclasses.\rpostProcessBeanFactory(beanFactory);\rStartupStep beanPostProcess = this.applicationStartup.start(\u0026quot;spring.context.beans.post-process\u0026quot;);\r// Invoke factory processors registered as beans in the context.\rinvokeBeanFactoryPostProcessors(beanFactory);\r// Register bean processors that intercept bean creation.\rregisterBeanPostProcessors(beanFactory);\rbeanPostProcess.end();\r// Initialize message source for this context.\rinitMessageSource();\r// Initialize event multicaster for this context.\rinitApplicationEventMulticaster();\r// Initialize other special beans in specific context subclasses.\r// 留给子类来初始化其它的bean\ronRefresh();\r// Check for listener beans and register them.\rregisterListeners();\r// Instantiate all remaining (non-lazy-init) singletons.\r// 初始化剩下的单例bean(no-lazy)\rfinishBeanFactoryInitialization(beanFactory);\r// Last step: publish corresponding event.\r// 通知生命周期处理器刷新过程，启动bean的生命周期，同时发出事件通知监听者。\rfinishRefresh();\r}\rcatch (BeansException ex) {\rif (logger.isWarnEnabled()) {\rlogger.warn(\u0026quot;Exception encountered during context initialization - \u0026quot; +\r\u0026quot;cancelling refresh attempt: \u0026quot; + ex);\r}\r// Destroy already created singletons to avoid dangling resources.\rdestroyBeans();\r// Reset 'active' flag.\rcancelRefresh(ex);\r// Propagate exception to caller.\rthrow ex;\r}\rfinally {\r// Reset common introspection caches in Spring's core, since we\r// might not ever need metadata for singleton beans anymore...\rresetCommonCaches();\rcontextRefresh.end();\r}\r}\r}\r 环境准备 protected void prepareRefresh() {\r// Switch to active.\rthis.startupDate = System.currentTimeMillis();\rthis.closed.set(false);\rthis.active.set(true);\rif (logger.isDebugEnabled()) {\rif (logger.isTraceEnabled()) {\rlogger.trace(\u0026quot;Refreshing \u0026quot; + this);\r}\relse {\rlogger.debug(\u0026quot;Refreshing \u0026quot; + getDisplayName());\r}\r}\r// Initialize any placeholder property sources in the context environment.\rinitPropertySources();\r// Validate that all properties marked as required are resolvable:\r// see ConfigurablePropertyResolver#setRequiredProperties\rgetEnvironment().validateRequiredProperties();\r// Store pre-refresh ApplicationListeners...\rif (this.earlyApplicationListeners == null) {\rthis.earlyApplicationListeners = new LinkedHashSet\u0026lt;\u0026gt;(this.applicationListeners);\r}\relse {\r// Reset local application listeners to pre-refresh state.\rthis.applicationListeners.clear();\rthis.applicationListeners.addAll(this.earlyApplicationListeners);\r}\r// Allow for the collection of early ApplicationEvents,\r// to be published once the multicaster is available...\rthis.earlyApplicationEvents = new LinkedHashSet\u0026lt;\u0026gt;();\r}\r 这个函数其实没什么逻辑，主要可以用来继承完成一些操作\n initPropertySources正符合Spring的开放式结构设计，给用户最大扩展Spring的能力。用户可以根据自身的需要重写initPropertySources方法，并在方法中进行个性化的属性处理及设置。 validateRequiredProperties则是对属性进行验证  一般在对一些配置文件进行检查时可以使用到。\n加载BeanFactory protected ConfigurableListableBeanFactory obtainFreshBeanFactory() {\r//核心逻辑\rrefreshBeanFactory();\rreturn getBeanFactory();\r}\rprotected final void refreshBeanFactory() throws BeansException {\rif (hasBeanFactory()) {\rdestroyBeans();\rcloseBeanFactory();\r}\rtry {\rDefaultListableBeanFactory beanFactory = createBeanFactory();\rbeanFactory.setSerializationId(getId());\r// 设置一些值\rcustomizeBeanFactory(beanFactory);\r// 加载BeanDefinition\rloadBeanDefinitions(beanFactory);\rthis.beanFactory = beanFactory;\r}\rcatch (IOException ex) {\rthrow new ApplicationContextException(\u0026quot;I/O error parsing bean definition source for \u0026quot; + getDisplayName(), ex);\r}\r}\r 这段代码的逻辑就是设置一些值，比如是否允许循环依赖等，然后加载BeanDefinition，其实就是进行bean的解析和注册，也就是最开始看的那些东西具体流程参考目录 解析及注册BeanDefinitions功能扩展 进入函数prepareBeanFactory前，Spring已经完成了对配置的解析，而ApplicationContext在功能上的扩展也由此展开。这里没太看懂啊，\n 增加对SPEL语言的支持。 增加对属性编辑器的支持。 增加对一些内置类，比如EnvironmentAware、MessageSourceAware的信息注入。 设置了依赖功能可忽略的接口。 注册一些固定依赖的属性。 增加AspectJ的支持（会在第7章中进行详细的讲解）。 将相关环境变量及属性注册以单例模式注册。  BeanFactory的后处理 主要是处理配置，Spring IoC容器允许BeanFactoryPostProcessor在容器实际实例化任何其他的bean之前读取配置元数据，并有可能修改它。当Spring加载任何实现了这个接口的bean的配置时，都会在bean工厂载入所有bean的配置之后执行postProcessBeanFactory方法。在PropertyResourceConfigurer类中实现了postProcessBeanFactory方法，在方法中先后调用了mergeProperties、convertProperties、processProperties这3个方法，分别得到配置，将得到的配置转换为合适的类型，最后将配置内容告知BeanFactory。正是通过实现BeanFactoryPostProcessor接口，BeanFactory会在实例化任何bean之前获得配置信息，从而能够正确解析bean描述文件中的变量引用。\n初始化非延迟加载单例 完成BeanFactory的初始化工作，其中包括ConversionService的设置、配置冻结以及非延迟加载的bean的初始化工作。\nprotected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) {\r// Initialize conversion service for this context.\rif (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) \u0026amp;\u0026amp;\rbeanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) {\rbeanFactory.setConversionService(\rbeanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class));\r}\r// Register a default embedded value resolver if no bean post-processor\r// (such as a PropertyPlaceholderConfigurer bean) registered any before:\r// at this point, primarily for resolution in annotation attribute values.\rif (!beanFactory.hasEmbeddedValueResolver()) {\rbeanFactory.addEmbeddedValueResolver(strVal -\u0026gt; getEnvironment().resolvePlaceholders(strVal));\r}\r// Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early.\rString[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false);\rfor (String weaverAwareName : weaverAwareNames) {\rgetBean(weaverAwareName);\r}\r// Stop using the temporary ClassLoader for type matching.\rbeanFactory.setTempClassLoader(null);\r// Allow for caching all bean definition metadata, not expecting further changes.\r// 冻结所有的bean定义，说明注册的bean定义将不被修改或进行任何进一步的处理。\rbeanFactory.freezeConfiguration();\r// Instantiate all remaining (non-lazy-init) singletons.\r// 初始化剩下的单例bean(no - lazy)\rbeanFactory.preInstantiateSingletons();\r}\r 重点就是 preInstantiateSingletons() 这个方法，ApplicationContext实现的默认行为就是在启动时将所有单例bean提前进行实例化。提前实例化意味着作为初始化过程的一部分，ApplicationContext实例会创建并配置所有的单例bean。\npublic void preInstantiateSingletons() throws BeansException {\rif (logger.isTraceEnabled()) {\rlogger.trace(\u0026quot;Pre-instantiating singletons in \u0026quot; + this);\r}\r// Iterate over a copy to allow for init methods which in turn register new bean definitions.\r// While this may not be part of the regular factory bootstrap, it does otherwise work fine.\rList\u0026lt;String\u0026gt; beanNames = new ArrayList\u0026lt;\u0026gt;(this.beanDefinitionNames);\r// Trigger initialization of all non-lazy singleton beans...\rfor (String beanName : beanNames) {\rRootBeanDefinition bd = getMergedLocalBeanDefinition(beanName);\rif (!bd.isAbstract() \u0026amp;\u0026amp; bd.isSingleton() \u0026amp;\u0026amp; !bd.isLazyInit()) {\rif (isFactoryBean(beanName)) {\rObject bean = getBean(FACTORY_BEAN_PREFIX + beanName);\rif (bean instanceof FactoryBean) {\rFactoryBean\u0026lt;?\u0026gt; factory = (FactoryBean\u0026lt;?\u0026gt;) bean;\rboolean isEagerInit;\rif (System.getSecurityManager() != null \u0026amp;\u0026amp; factory instanceof SmartFactoryBean) {\risEagerInit = AccessController.doPrivileged(\r(PrivilegedAction\u0026lt;Boolean\u0026gt;) ((SmartFactoryBean\u0026lt;?\u0026gt;) factory)::isEagerInit,\rgetAccessControlContext());\r}\relse {\risEagerInit = (factory instanceof SmartFactoryBean \u0026amp;\u0026amp;\r((SmartFactoryBean\u0026lt;?\u0026gt;) factory).isEagerInit());\r}\rif (isEagerInit) {\rgetBean(beanName);\r}\r}\r}\relse {\rgetBean(beanName);\r}\r}\r}\r// Trigger post-initialization callback for all applicable beans...\rfor (String beanName : beanNames) {\rObject singletonInstance = getSingleton(beanName);\rif (singletonInstance instanceof SmartInitializingSingleton) {\rStartupStep smartInitialize = this.getApplicationStartup().start(\u0026quot;spring.beans.smart-initialize\u0026quot;)\r.tag(\u0026quot;beanName\u0026quot;, beanName);\rSmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance;\rif (System.getSecurityManager() != null) {\rAccessController.doPrivileged((PrivilegedAction\u0026lt;Object\u0026gt;) () -\u0026gt; {\rsmartSingleton.afterSingletonsInstantiated();\rreturn null;\r}, getAccessControlContext());\r}\relse {\rsmartSingleton.afterSingletonsInstantiated();\r}\rsmartInitialize.end();\r}\r}\r}\r 这个方法核心就是getBean，其实又回到了bean 的加载finishRefresh ​\t在Spring中还提供了Lifecycle接口，Lifecycle中包含start/stop方法，实现此接口后Spring会保证在启动的时候调用其start方法开始生命周期，并在Spring关闭的时候调用stop方法来结束生命周期，通常用来配置后台程序，在启动后一直运行（如对MQ进行轮询等）。而finishRefresh正是保证了这一功能的实现\nprotected void finishRefresh() {\r// Clear context-level resource caches (such as ASM metadata from scanning).\rclearResourceCaches();\r// Initialize lifecycle processor for this context.\rinitLifecycleProcessor();\r// Propagate refresh to lifecycle processor first.\rgetLifecycleProcessor().onRefresh();\r// Publish the final event.\rpublishEvent(new ContextRefreshedEvent(this));\r// Participate in LiveBeansView MBean, if active.\rif (!IN_NATIVE_IMAGE) {\rLiveBeansView.registerApplicationContext(this);\r}\r}\r   当ApplicationContext启动或停止时，它会通过LifecycleProcessor来与所有声明的bean的周期做状态更新，而在LifecycleProcessor的使用前首先需要初始化,initLifecycleProcessor() 这个函数就是来初始化LifecycleProcessor这个bean的。\n  **onRefresh()**启动所有实现了Lifecycle接口的bean。\npublic void onRefresh() {\rstartBeans(true);\rthis.running = true;\r}\r// 这个函数的写法就很有意思\rprivate void startBeans(boolean autoStartupOnly) {\r// 获得bean\rMap\u0026lt;String, Lifecycle\u0026gt; lifecycleBeans = getLifecycleBeans();\rMap\u0026lt;Integer, LifecycleGroup\u0026gt; phases = new TreeMap\u0026lt;\u0026gt;();\rlifecycleBeans.forEach((beanName, bean) -\u0026gt; {\rif (!autoStartupOnly || (bean instanceof SmartLifecycle \u0026amp;\u0026amp; ((SmartLifecycle) bean).isAutoStartup())) {\rint phase = getPhase(bean);\rphases.computeIfAbsent(\rphase,\rp -\u0026gt; new LifecycleGroup(phase, this.timeoutPerShutdownPhase, lifecycleBeans, autoStartupOnly)\r).add(beanName, bean);\r}\r});\r// 启动bean\rif (!phases.isEmpty()) {\rphases.values().forEach(LifecycleGroup::start);\r}\r}\r   当完成ApplicationContext初始化的时候，要通过Spring中的事件发布机制来发出Context RefreshedEvent事件，以保证对应的监听器可以做进一步的逻辑处理， publishEvent 这个函数就是用来发布事件的。\n  bean的生命周期，课外知识 bean的生命周期主要是这些，实例化 -\u0026gt; 属性赋值 -\u0026gt; 初始化 -\u0026gt; 销毁， 网上那张比较流行的图其实是对这些步骤的扩展\n这几个过程分别对应的方法为：\n createBeanInstance() -\u0026gt; 实例化 populateBean() -\u0026gt; 属性赋值 initializeBean() -\u0026gt; 初始化  主要扩展点为\n将这几个扩展点分开来说就是网上这张图\nspring 管理bean 主要是注册 bean 和 装配bean\n读到这里其实就已经把spring的启动全部读完了，按照自己的理解其实就是可以分为几步：\n 注册bean，即将bean从配置文件中读取出来，注册到list中 提前实例化非延迟加载的单例 bean ，这就是把bean赋值了 启动bean的生命周期  整个流程中发现并没有对注解注入的bean进行注册也就是说目前spring中是不可能有@Service这些注解注解的bean的，那么为什么能启动呢？\n​\t\u0026lt; context:component-scan\u0026gt;隐式地启用了\u0026lt; context:annotation-config\u0026gt;的功能。\u0026lt; context:annotation-config\u0026gt;的作用是让Spring具备解析@Component等注解的功能，通过这个配置使得使用也可以得到注解注释的bean。\n\u0026lt;context:annotation-config /\u0026gt;\r ​\t同样 \u0026lt; aop:aspectj-autoproxy/\u0026gt; 开启支持 aop\nAOP 感觉这本书的aop讲的并不是很好，以后有机会可以再找书看看。\n首先一个使用aop的小栗子\n@Component\rpublic class AopStudy {\rpublic void test(){\rSystem.out.println(\u0026quot;真正的方法执行啦\u0026quot;);\r}\r}\r@Component\r@Aspect\rpublic class AopRun {\r// 定义切面\r@Pointcut(\u0026quot;execution(* com.zt.javastudy.grammar.*.test(..))\u0026quot;)\rpublic void test(){\r}\r@Before(\u0026quot;test()\u0026quot;)\rpublic void beforeTest(){\rSystem.out.println(\u0026quot;beforeTest\u0026quot;);\r}\r@After(\u0026quot;test()\u0026quot;)\rpublic void afterTest(){\rSystem.out.println(\u0026quot;afterTest\u0026quot;);\r}\r@Around(\u0026quot;test()\u0026quot;)\rpublic void arountTest(ProceedingJoinPoint point){\rSystem.out.println(\u0026quot;around1\u0026quot;);\rtry {\rpoint.proceed();\r} catch (Throwable throwable) {\rthrowable.printStackTrace();\r}\rSystem.out.println(\u0026quot;around2\u0026quot;);\r}\r}\r 测试\n@Slf4j\r@RunWith(SpringRunner.class)\r@SpringBootTest()\rpublic class AopStudyTest {\r@Autowired\rprivate AopStudy aopStudy;\r@Test\rpublic void test(){\raopStudy.test();\r}\r}\r/**\raround1\rbeforeTest\r真正的方法执行啦\rafterTest\raround2\r*/\r aop使用起来确实是方便，只需要在代理bean上加上@Aspect 注解，然后在类中定义切面，再使用相对应的注解，就可以在方法执行的不同时刻拓展不同的功能。但是有句话叫做简曰但不简单，aop的源码确实比较复杂，没怎么看明白。\n在xml中\u0026lt; aop:aspectj-autoproxy/\u0026gt; 通过这个注解开启对aop的支持，之前讲过Spring中的自定义注解，如果声明了自定义的注解，那么就一定会在程序中的某个地方注册了对应的解析器。\naop部分的解析器由AopNamespaceHandler注册，其init方法\npublic void init() {\r// In 2.0 XSD as well as in 2.5+ XSDs\rregisterBeanDefinitionParser(\u0026quot;config\u0026quot;, new ConfigBeanDefinitionParser());\rregisterBeanDefinitionParser(\u0026quot;aspectj-autoproxy\u0026quot;, new AspectJAutoProxyBeanDefinitionParser());\rregisterBeanDefinitionDecorator(\u0026quot;scoped-proxy\u0026quot;, new ScopedProxyBeanDefinitionDecorator());\r// Only in 2.0 XSD: moved to context namespace in 2.5+\rregisterBeanDefinitionParser(\u0026quot;spring-configured\u0026quot;, new SpringConfiguredBeanDefinitionParser());\r}\r 在解析配置文件的时候，一旦遇到aspectj-autoproxy注解时就会使用解析器AspectJAutoProxyBeanDefinitionParser进行解析,所有解析器，因为是对BeanDefinitionParser接口的统一实现，入口都是从parse函数开始的，AspectJAutoProxyBeanDefinitionParser的parse函数如下\npublic BeanDefinition parse(Element element, ParserContext parserContext) {\r// 注册 核心代码\rAopNamespaceUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(parserContext, element);\r// 对于注解中子类的处理\rextendBeanDefinition(element, parserContext);\rreturn null;\r}\rpublic static void registerAspectJAnnotationAutoProxyCreatorIfNecessary(\rParserContext parserContext, Element sourceElement) {\r// 注册或者升级AnnotationAwareAspectJAutoProxyCreator\rBeanDefinition beanDefinition = AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(\rparserContext.getRegistry(), parserContext.extractSource(sourceElement));\r// 处理proxy-target-class以及expose-proxy属性\ruseClassProxyingIfNecessary(parserContext.getRegistry(), sourceElement);\r// 注册组件并通知，便于监听器做进一步处理\rregisterComponentIfNecessary(beanDefinition, parserContext);\r}\r 注册或者升级AnnotationAwareAspectJAutoProxyCreator ​\t这里的东西感觉书上讲的不是很清楚，简单来说就是实现了自动注册AnnotationAwareAspectJAutoProxyCreator类的功能。\n处理proxy-target-class以及expose-proxy属性   proxy-target-class\n这个属性的配置其实就是说采用哪种代理的方式，默认为false，Spring AOP部分使用JDK动态代理或者CGLIB来为目标对象创建代理，当这个属性为true时就会使用cglib来创建代理对象，\n  expose-proxy\n代表是否将代理bean暴露给用户，如果暴露，可以通过Spring AopContext类获得，默认不暴露，典型的可以用来事务@Transactional失效的问题详情见：\nhttps://www.cnblogs.com/2YSP/p/11748389.html\n  经过这个代码的处理，完成了对AnnotationAwareAspectJAutoProxyCreator类型的自动注册。\nAnnotationAwareAspectJAutoProxyCreator这个类就为我们进行aop的逻辑处理，但是到这里为止其实只是证明了spring现在有处理aop的能力了，也知道了spring有处理的能力是因为AnnotationAwareAspectJAutoProxyCreator这个类，但是怎么处理的？何时调用这个类的方法进行对象功能的增加并返回代理对象的？下面将进行这些的解释。\n​\t让我们把思绪拉到spring bean的注册在bean的注册中有这么一段代码\ntry {\r// Give BeanPostProcessors a chance to return a proxy instead of the target bean instance.\rObject bean = resolveBeforeInstantiation(beanName, mbdToUse);\rif (bean != null) {\rreturn bean;\r}\rprotected Object resolveBeforeInstantiation(String beanName, RootBeanDefinition mbd) {\rObject bean = null;\rif (!Boolean.FALSE.equals(mbd.beforeInstantiationResolved)) {\r// Make sure bean class is actually resolved at this point.\rif (!mbd.isSynthetic() \u0026amp;\u0026amp; hasInstantiationAwareBeanPostProcessors()) {\rClass\u0026lt;?\u0026gt; targetType = determineTargetType(beanName, mbd);\rif (targetType != null) {\rbean = applyBeanPostProcessorsBeforeInstantiation(targetType, beanName);\rif (bean != null) {\rbean = applyBeanPostProcessorsAfterInitialization(bean, beanName);\r}\r}\r}\rmbd.beforeInstantiationResolved = (bean != null);\r}\rreturn bean;\r}\r 其中有两个方法，applyBeanPostProcessorsBeforeInstantiation、applyBeanPostProcessorsAfterInitialization这两个方法里面去调用了BeanPostProcessor中的postProcessBeforeInitialization和postProcessAfterInitialization这两个方法，而AnnotationAwareAspectJAutoProxyCreator实现了BeanPostProcessor接口**，所以当Spring加载这个Bean时会在实例化前调用它的postProcessBeforeInitialization和postProcessAfterInitialization方法**\n这两个方法也就是做了一件事情创建AOP代理\n创建AOP代理 这两个方法基本逻辑 一样，这里分析postProcessAfterInitialization这个方法\n/**\r* Create a proxy with the configured interceptors if the bean is\r* identified as one to proxy by the subclass.\r* @see #getAdvicesAndAdvisorsForBean\r*/\r// 注释就告诉我们这是创建aop代理的地方\r@Override\rpublic Object postProcessAfterInitialization(@Nullable Object bean, String beanName) {\rif (bean != null) {\rObject cacheKey = getCacheKey(bean.getClass(), beanName);\rif (this.earlyProxyReferences.remove(cacheKey) != bean) {\r// 关键方法 如果需要被代理那么就封装指定的bean\rreturn wrapIfNecessary(bean, beanName, cacheKey);\r}\r}\rreturn bean;\r}\rprotected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) {\rif (StringUtils.hasLength(beanName) \u0026amp;\u0026amp; this.targetSourcedBeans.contains(beanName)) {\rreturn bean;\r}\rif (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) {\rreturn bean;\r}\r// 给定的bean是否一个基础设施类如果是就不需要增强\rif (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) {\rthis.advisedBeans.put(cacheKey, Boolean.FALSE);\rreturn bean;\r}\r// Create proxy if we have advice.\r// 获取增加方法或增强器\rObject[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);\rif (specificInterceptors != DO_NOT_PROXY) {\rthis.advisedBeans.put(cacheKey, Boolean.TRUE);\r// 创建代理\rObject proxy = createProxy(\rbean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));\rthis.proxyTypes.put(cacheKey, proxy.getClass());\rreturn proxy;\r}\rthis.advisedBeans.put(cacheKey, Boolean.FALSE);\rreturn bean;\r}\r 基础设施类包括：Spring跳过的是适用于当前bean的Advisor的Advice/Aspect对象，说人话就是我们定义的切面注解@AspectJ\n获取增强方法或者增强器 protected Object[] getAdvicesAndAdvisorsForBean(\rClass\u0026lt;?\u0026gt; beanClass, String beanName, @Nullable TargetSource targetSource) {\rList\u0026lt;Advisor\u0026gt; advisors = findEligibleAdvisors(beanClass, beanName);\rif (advisors.isEmpty()) {\rreturn DO_NOT_PROXY;\r}\rreturn advisors.toArray();\r}\rprotected List\u0026lt;Advisor\u0026gt; findEligibleAdvisors(Class\u0026lt;?\u0026gt; beanClass, String beanName) {\r// 获取所有的增强\rList\u0026lt;Advisor\u0026gt; candidateAdvisors = findCandidateAdvisors();\r// 寻找所有增强中适用于bean的增强并应用\rList\u0026lt;Advisor\u0026gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName);\rextendAdvisors(eligibleAdvisors);\rif (!eligibleAdvisors.isEmpty()) {\religibleAdvisors = sortAdvisors(eligibleAdvisors);\r}\rreturn eligibleAdvisors;\r}\r 获取增强器 protected List\u0026lt;Advisor\u0026gt; findCandidateAdvisors() {\r// Add all the Spring advisors found according to superclass rules.\rList\u0026lt;Advisor\u0026gt; advisors = super.findCandidateAdvisors();\r// Build Advisors for all AspectJ aspects in the bean factory.\rif (this.aspectJAdvisorsBuilder != null) {\radvisors.addAll(this.aspectJAdvisorsBuilder.buildAspectJAdvisors());\r}\rreturn advisors;\r}\r 这里的代码过于复杂，主要思路就是\n 获取所有beanName，这一步骤中所有在beanFacotry中注册的Bean都会被提取出来。 遍历所有beanName，并找出声明AspectJ注解的类，进行进一步的处理。 对标记为AspectJ注解的类进行增强器的提取。 将提取结果加入缓存  代码首先完成了对增强器的获取，包括获取注解以及根据注解生成增强的步骤，然后考虑到在配置中可能会将增强配置成延迟初始化，那么需要在首位加入同步实例化增强器以保证增强使用之前的实例化，最后是对DeclareParents注解的获取。\n寻找匹配的增强器 protected List\u0026lt;Advisor\u0026gt; findAdvisorsThatCanApply(\rList\u0026lt;Advisor\u0026gt; candidateAdvisors, Class\u0026lt;?\u0026gt; beanClass, String beanName) {\rProxyCreationContext.setCurrentProxiedBeanName(beanName);\rtry {\rreturn AopUtils.findAdvisorsThatCanApply(candidateAdvisors, beanClass);\r}\rfinally {\rProxyCreationContext.setCurrentProxiedBeanName(null);\r}\r}\r 上个函数中已经完成了所有增强器的解析，但是对于所有增强器来讲，并不一定都适用于当前的Bean，还要挑取出适合的增强器，也就是满足我们配置的通配符的增强器，这个函数就完成了这一工作。\n创建代理 ​\t就是真正创建代理的地方\nprotected Object createProxy(Class\u0026lt;?\u0026gt; beanClass, @Nullable String beanName,\r@Nullable Object[] specificInterceptors, TargetSource targetSource) {\rif (this.beanFactory instanceof ConfigurableListableBeanFactory) {\rAutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass);\r}\rProxyFactory proxyFactory = new ProxyFactory();\rproxyFactory.copyFrom(this);\rif (!proxyFactory.isProxyTargetClass()) {\rif (shouldProxyTargetClass(beanClass, beanName)) {\rproxyFactory.setProxyTargetClass(true);\r}\relse {\revaluateProxyInterfaces(beanClass, proxyFactory);\r}\r}\rAdvisor[] advisors = buildAdvisors(beanName, specificInterceptors);\rproxyFactory.addAdvisors(advisors);\rproxyFactory.setTargetSource(targetSource);\rcustomizeProxyFactory(proxyFactory);\rproxyFactory.setFrozen(this.freezeProxy);\rif (advisorsPreFiltered()) {\rproxyFactory.setPreFiltered(true);\r}\rreturn proxyFactory.getProxy(getProxyClassLoader());\r}\r public Object getProxy(@Nullable ClassLoader classLoader) {\rreturn createAopProxy().getProxy(classLoader);\r}\rprotected final synchronized AopProxy createAopProxy() {\rif (!this.active) {\ractivate();\r}\rreturn getAopProxyFactory().createAopProxy(this);\r}\r// 真正的代码\rpublic AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException {\rif (!IN_NATIVE_IMAGE \u0026amp;\u0026amp;\r(config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config))) {\rClass\u0026lt;?\u0026gt; targetClass = config.getTargetClass();\rif (targetClass == null) {\rthrow new AopConfigException(\u0026quot;TargetSource cannot determine target class: \u0026quot; +\r\u0026quot;Either an interface or a target is required for proxy creation.\u0026quot;);\r}\rif (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) {\rreturn new JdkDynamicAopProxy(config);\r}\rreturn new ObjenesisCglibAopProxy(config);\r}\relse {\rreturn new JdkDynamicAopProxy(config);\r}\r}\r 上面的代码主要是确定使用哪种代理方式进行代理，总的来说就是：\n 如果指定了(proxy-target-classs设为true)使用Cglib，那么就会使用Cglib的方式 如果没有指定(或为false)，那么先会检测被代理类是否实现了自己的接口，如果实现了，那么就采用JDK动态代理的方式，如果没有实现那么就走Cglib。  先简单学习 一下两种代理的使用方式\njdk动态代理：\n/**\r* @author zhengtao\r* @description jdk 动态代理学习\r* @date 2021/4/29\r*/\rpublic interface IJdkProxyStudy {\r/**\r* 目标方法\r*/\rvoid add();\r}\rpublic class JdkProxyStudyImpl implements IJdkProxyStudy {\r@Override\rpublic void add() {\rSystem.out.println(\u0026quot;add\u0026quot;);\r}\r}\rpublic class MyInvocationHandler implements InvocationHandler {\r// 目标对象\rprivate Object target;\rpublic MyInvocationHandler(Object target) {\rsuper();\rthis.target = target;\r}\r/**\r* 执行目标对象的方法\r* @param proxy\r* @param method\r* @param args\r* @return\r* @throws Throwable\r*/\r@Override\rpublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\rSystem.out.println(\u0026quot;before\u0026quot;);\r// 执行目标对象的方法\rObject result = method.invoke(target, args);\rSystem.out.println(\u0026quot;after\u0026quot;);\rreturn result;\r}\r/**\r* 获得目标对象的代理对象\r* @return 代理对象\r*/\rpublic Object getProxy(){\rreturn Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), target.getClass().getInterfaces(), this);\r}\r}\r 测试jdk动态代理：\n@Test\rpublic void testJdkProxy(){\r// 接口\rIJdkProxyStudy jdkProxyStudy = new JdkProxyStudyImpl();\rMyInvocationHandler invocationHandler = new MyInvocationHandler(jdkProxyStudy);\rIJdkProxyStudy proxy = (IJdkProxyStudy) invocationHandler.getProxy();\rproxy.add();\r// 没有实现接口的类，使用jdk代理报错\rCglibTest cglibTest = new CglibTest();\rMyInvocationHandler invocationHandler1 = new MyInvocationHandler(cglibTest);\rCglibTest proxy1 = (CglibTest) invocationHandler1.getProxy();\rproxy1.test();\r}\r/** 结果\rbefore\radd\rafter\r*/\r 我们再次来回顾一下使用JDK代理的方式，在整个创建过程中，对于InvocationHandler的创建是最为核心的，在自定义的InvocationHandler中需要重写3个函数。\n 构造函数，将代理的对象传入。 invoke方法，此方法中实现了AOP增强的所有逻辑。 getProxy方法，此方法千篇一律，但是必不可少。  Spring中JDK代理实现：\n invoke方法:  /**\r* Implementation of {@code InvocationHandler.invoke}.\r* \u0026lt;p\u0026gt;Callers will see exactly the exception thrown by the target,\r* unless a hook method throws an exception.\r*/\r@Override\r@Nullable\rpublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\rObject oldProxy = null;\rboolean setProxyContext = false;\rTargetSource targetSource = this.advised.targetSource;\rObject target = null;\rtry {\rif (!this.equalsDefined \u0026amp;\u0026amp; AopUtils.isEqualsMethod(method)) {\r// The target does not implement the equals(Object) method itself.\rreturn equals(args[0]);\r}\relse if (!this.hashCodeDefined \u0026amp;\u0026amp; AopUtils.isHashCodeMethod(method)) {\r// The target does not implement the hashCode() method itself.\rreturn hashCode();\r}\relse if (method.getDeclaringClass() == DecoratingProxy.class) {\r// There is only getDecoratedClass() declared -\u0026gt; dispatch to proxy config.\rreturn AopProxyUtils.ultimateTargetClass(this.advised);\r}\relse if (!this.advised.opaque \u0026amp;\u0026amp; method.getDeclaringClass().isInterface() \u0026amp;\u0026amp;\rmethod.getDeclaringClass().isAssignableFrom(Advised.class)) {\r// Service invocations on ProxyConfig with the proxy config...\rreturn AopUtils.invokeJoinpointUsingReflection(this.advised, method, args);\r}\rObject retVal;\rif (this.advised.exposeProxy) {\r// Make invocation available if necessary.\roldProxy = AopContext.setCurrentProxy(proxy);\rsetProxyContext = true;\r}\r// Get as late as possible to minimize the time we \u0026quot;own\u0026quot; the target,\r// in case it comes from a pool.\rtarget = targetSource.getTarget();\rClass\u0026lt;?\u0026gt; targetClass = (target != null ? target.getClass() : null);\r// Get the interception chain for this method.\rList\u0026lt;Object\u0026gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);\r// Check whether we have any advice. If we don't, we can fallback on direct\r// reflective invocation of the target, and avoid creating a MethodInvocation.\rif (chain.isEmpty()) {\r// We can skip creating a MethodInvocation: just invoke the target directly\r// Note that the final invoker must be an InvokerInterceptor so we know it does\r// nothing but a reflective operation on the target, and no hot swapping or fancy proxying.\rObject[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);\rretVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse);\r}\relse {\r// We need to create a method invocation...\rMethodInvocation invocation =\rnew ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain);\r// Proceed to the joinpoint through the interceptor chain.\rretVal = invocation.proceed();\r}\r// Massage return value if necessary.\rClass\u0026lt;?\u0026gt; returnType = method.getReturnType();\rif (retVal != null \u0026amp;\u0026amp; retVal == target \u0026amp;\u0026amp;\rreturnType != Object.class \u0026amp;\u0026amp; returnType.isInstance(proxy) \u0026amp;\u0026amp;\r!RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) {\r// Special case: it returned \u0026quot;this\u0026quot; and the return type of the method\r// is type-compatible. Note that we can't help if the target sets\r// a reference to itself in another returned object.\rretVal = proxy;\r}\relse if (retVal == null \u0026amp;\u0026amp; returnType != Void.TYPE \u0026amp;\u0026amp; returnType.isPrimitive()) {\rthrow new AopInvocationException(\r\u0026quot;Null return value from advice does not match primitive return type for: \u0026quot; + method);\r}\rreturn retVal;\r}\rfinally {\rif (target != null \u0026amp;\u0026amp; !targetSource.isStatic()) {\r// Must have come from TargetSource.\rtargetSource.releaseTarget(target);\r}\rif (setProxyContext) {\r// Restore old proxy.\rAopContext.setCurrentProxy(oldProxy);\r}\r}\r}\r 上面的函数中最主要的工作就是创建了一个拦截器链，并使用ReflectiveMethodInvocation类进行了链的封装，而在ReflectiveMethodInvocation类的proceed方法中实现了拦截器的逐一调用\ngetProxy方法  public Object getProxy(@Nullable ClassLoader classLoader) {\rif (logger.isTraceEnabled()) {\rlogger.trace(\u0026quot;Creating JDK dynamic proxy: \u0026quot; + this.advised.getTargetSource());\r}\rreturn Proxy.newProxyInstance(classLoader, this.proxiedInterfaces, this);\r}\r Cglib代理学习：\npublic class CglibTest {\rpublic void test(){\rSystem.out.println(\u0026quot;test\u0026quot;);\r}\r}\rpublic class CgLibProxy implements MethodInterceptor {\r// 目标对象\rprivate Object target;\rpublic CgLibProxy(Object target) {\rsuper();\rthis.target = target;\r}\r@Override\rpublic Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {\rSystem.out.println(\u0026quot;before test\u0026quot;);\rObject result = methodProxy.invokeSuper(o, objects);\rSystem.out.println(\u0026quot;after test\u0026quot;);\rreturn result;\r}\rpublic Object getProxy(){\rEnhancer enhancer = new Enhancer();\renhancer.setSuperclass(this.target.getClass());\renhancer.setCallback(this);\rObject proxy = enhancer.create();\rreturn proxy;\r}\r}\r 测试：\n@Test\rpublic void testCglibProxy(){\rCglibTest cglibTest = new CglibTest();\rCgLibProxy cgLibProxy = new CgLibProxy(cglibTest);\rCglibTest proxy = (CglibTest) cgLibProxy.getProxy();\rproxy.test();\r}\r结果\rbefore test\rtest\rafter test\r spring中怎么实现的就不多讲了。\n静态代理  public interface StaticProxy {\rvoid test();\r}\rpublic class StaticProxyImpl implements StaticProxy {\r@Override\rpublic void test() {\rSystem.out.println(\u0026quot;test\u0026quot;);\r}\r}\rpublic class StaticProxyTest implements StaticProxy {\rprivate StaticProxy staticProxy;\rpublic StaticProxyTest(StaticProxy staticProxy) {\rthis.staticProxy = staticProxy;\r}\r@Override\rpublic void test() {\rSystem.out.println(\u0026quot;before test\u0026quot;);\rthis.staticProxy.test();\rSystem.out.println(\u0026quot;after test\u0026quot;);\r}\r}\r 测试\n@Test\rpublic void testStaticProxy(){\rStaticProxy staticProxy = new StaticProxyTest(new StaticProxyImpl());\rstaticProxy.test();\r}\r结果\rbefore test\rtest\rafter test\r 静态代理感觉起来就是每个类都必须有一个代理类来具体实现，所以就效率不高。\n","id":7,"section":"posts","summary":"spring源码学习 ​ 对于学习spring源码肯定最重要的学习spring的一些理念，比如控制翻转ioc，依赖注入di，面向切面编程aop等","tags":["spring"],"title":"spring源码学习","uri":"https://wzgl998877.github.io/2022/01/spring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/","year":"2022"},{"content":"thrift+zk RPC调用框架 zk 在这个框架中zk其实只是作为了注册中心来使用 (客户端只需要在zk上获得地址，服务端只需要将自己注册在zk上)，所以先了解一下zk的节点的划分。\nZooKeeper 节点是有生命周期的，这取决于节点的类型。在 ZooKeeper 中，节点类型可以分为持久节点（PERSISTENT ）、临时节点（EPHEMERAL），以及时序节点（SEQUENTIAL ），具体在节点创建过程中，一般是组合使用，可以生成以下 4 种节点类型。\n持久节点（PERSISTENT） 所谓持久节点，是指在节点创建后，就一直存在，直到有删除操作来主动清除这个节点——不会因为创建该节点的客户端会话失效而消失。 持久顺序节点（PERSISTENT_SEQUENTIAL） 这类节点的基本特性和上面的节点类型是一致的。额外的特性是，在ZK中，每个父节点会为他的第一级子节点维护一份时序，会记录每个子节点创建的先后顺序。基于这个特性，在创建子节点的时候，可以设置这个属性，那么在创建节点过程中，ZK会自动为给定节点名加上一个数字后缀，作为新的节点名。这个数字后缀的范围是整型的最大值。 临时节点（EPHEMERAL） 和持久节点不同的是，临时节点的生命周期和客户端会话绑定。也就是说，如果客户端会话失效，那么这个节点就会自动被清除掉。注意，这里提到的是会话失效，而非连接断开。另外，在临时节点下面不能创建子节点。\n临时顺序节点（EPHEMERAL_SEQUENTIAL）\n可以用来实现分布式锁\n客户端有关zk的操作：\n","id":8,"section":"posts","summary":"thrift+zk RPC调用框架 zk 在这个框架中zk其实只是作为了注册中心来使用 (客户端只需要在zk上获得地址，服务端只需要将自己注册在zk上)，所以先了解一","tags":["RPC"],"title":"thrift+zk RPC调用框架","uri":"https://wzgl998877.github.io/2022/01/thrift-zk-rpc%E8%B0%83%E7%94%A8%E6%A1%86%E6%9E%B6/","year":"2022"},{"content":"Websocket学习 WebSocket是一种网络传输协议，可在单个TCP连接上进行全双工通信，位于应用层。\n 全双工：  单工（simplex ） : 只能有一个方向的通信而没有反方向的交互。 半双工（half duplex ） ：通信的双方都可以发送信息，但不能双方同时发送(当然也就不能同时接收)。 全双工（full duplex） : 通信的双方可以同时发送和接收信息。    建立websocket连接的步骤：\n 使用http进行握手，告知服务器通信协议变为websocket  GET /chat HTTP/1.1\rHost: server.example.com\rUpgrade: websocket\rConnection: Upgrade\rSec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==\rOrigin: http://example.com\rSec-WebSocket-Protocol: chat, superchat\rSec-WebSocket-Version: 13\r# 服务器响应\rHTTP/1.1 101 Switching Protocols\rUpgrade: websocket\rConnection: Upgrade\rSec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo=\rSec-WebSocket-Protocol: chat\r# ng配置\rlocation / {\rproxy_pass http://127.0.0.1:8110; proxy_set_header Host $http_host; proxy_http_version 1.1; proxy_set_header Upgrade \u0026quot;websocket\u0026quot;;\rproxy_set_header Connection \u0026quot;Upgrade\u0026quot;; }  进行websocket通信  ","id":9,"section":"posts","summary":"Websocket学习 WebSocket是一种网络传输协议，可在单个TCP连接上进行全双工通信，位于应用层。 全双工： 单工（simplex ） :","tags":["Websocket"],"title":"Websocket学习","uri":"https://wzgl998877.github.io/2022/01/websocket%E5%AD%A6%E4%B9%A0/","year":"2022"},{"content":"图解http 网络模型   OSI 模型(具体每层的定义还需要看书确定这个只是网上看的，可以回去看计网)\n  应用层（application）：最接近终端用户的OSI层，这就意味着OSI应用层与用户之间是通过应用软件直接相互作用的。网络进程访问应用层；提供接口服务。\n  表示层（presention）：数据表现形式；特定功能的实现-比如加密模式确保原始设备上加密的数据可以在目标设备上正确地解密。\n  会话层（session）：主机间通信；对应用会话管理，同步。\n  传输层（transport）:实现端到端传输；分可靠与不可靠传输；在传输前实现错误检测与流量控制，定义端口号（标记相应的服务）。\n  网络层（network）（单位类型：报文）：数据传输；提供逻辑地址，选择路由数据包，负责在源和终点之间建立连接。\n  数据链路层（date link）（单位类型：帧）：访问介质；数据在该层封装成帧；用MAC地址作为访问媒介；具有错误检测与修正功能。MAC描述在共享介质环境中如何进行站的调度、发生和接收数据。MAC确保信息跨链路的可靠传输，对数据传输进行同步，识别错误和控制数据的流向。一般地讲，MAC只在共享介质环境中才是重要的，只有在共享介质环境中多个节点才能连接到同一传输介质上。\n  物理层（physical）（单位类型：比特）：实现比特流的透明传输，物理接口，具有电气特性。\n    TCP/IP 四层模型\n 应用层：应用层决定了向用户提供应用服务时通信的活动。TCP/IP协议族内预存了各类通用的应用服务。比如，FTP（File Transfer Protocol，文件传输协议）和DNS（Domain Name System，域名系统）服务就是其中两类。HTTP协议也处于该层。 传输层：传输层对上层应用层，提供处于网络连接中的两台计算机之间的数据传输。在传输层有两个性质不同的协议：TCP（Transmission Control Protocol，传输控制协议）和UDP（User Data Protocol，用户数据报协议）。 网络层：（又名网络互连层）网络层用来处理在网络上流动的数据包。数据包是网络传输的最小数据单位。该层规定了通过怎样的路径（所谓的传输路线）到达对方计算机，并把数据包传送给对方。与对方计算机之间通过多台计算机或网络设备进行传输时，网络层所起的作用就是在众多的选项内选择一条传输路线。 链路层：（又名数据链路层，网络接口层）用来处理连接网络的硬件部分。包括控制操作系统、硬件的设备驱动、NIC（Network InterfaceCard，网络适配器，即网卡），及光纤等物理可见部分（还包括连接器等一切传输媒介）。硬件上的范畴均在链路层的作用范围之内。    五层模型\nOSI是一个完整的、完善的宏观理论模型;而TCP/IP(参考)模型，更加侧重的是互联网通信核心(也是就是围绕TCP/IP协议展开的一系列通信协议)的分层，因此它不包括物理层，以及其他一些不想干的协议; 而五层模型就是将物理层加进来了而已。\n     OSI TCP/IP 五层模型     应用层 应用层 应用层   表示层 应用层 应用层   会话层 应用层 应用层   传输层 传输层 传输层   网络层 网络层 网络层   数据链路层 数据链路层 数据链路层   物理层 数据链路层 并没有给出具体的物理层的实现 物理层    IP协议 ​\t是TCP/IP协议栈中最核心的协议之一，通过IP地址，保证了联网设备的唯一性，实现了网络通信的面向无连接和不可靠的传输功能。\nARP 地址解析协议 ​\t网络层使用的是IP地址，但在实际网络的链路上传送数据帧时，最终还是必须使用该网络的硬件地址，ARP协议就 实现了从 IP 地址到 MAC 地址的映射，即询问目标 IP 对应的 MAC 地址\nTCP/UDP 协议 ​\tTCP协议全称是传输控制协议是一种面向连接的、可靠的、基于字节流的传输层通信协议。\n​\tUDP协议全称是用户数据报协议是面向无连接、不可靠的、基于报文的的传输层通信协议。\n​\t经典知识点：三次握手，四次挥手\n B的TCP服务器进程先创建传输控制块 TCB，准备接受客户进程的连接请求。然后服务器进程就处于LISTEN（收听）状态，等待客户的连接请求。如有，即作出响应。A的TCP客户进程也是首先创建传输控制模块TCB，然后向B发出连接请求报文段，这时首部中的同步位SYN = 1，同时选择一个初始序号seq = x。TCP规定，SYN报文段（即SYN = 1的报文段）不能携带数据，但要消耗掉一个序号。这时，TCP客户进程进入SYN-SENT（同步已发送）状态。 B收到连接请求报文段后，如同意建立连接，则向A发送确认。在确认报文段中应把SYN位和ACK位都置1，确认号是ack = x + 1，同时也为自己选择一个初始序号seq = y。请注意，这个报文段也不能携带数据，但同样要消耗掉一个序号。这时TCP服务器进程进入SYN-RCVD（同步收到）状态。 TCP客户进程收到B的确认后，还要向B给出确认。确认报文段的ACK置1，确认号ack = y + 1，而自己的序号seq = x + 1。TCP的标准规定，ACK报文段可以携带数据。但如果不携带数据则不消耗序号，在这种情况下，下一个数据报文段的序号仍是seq = x + 1。这时，TCP连接已经建立，A进入ESTABLISHED（已建立连接）状态。当B收到A的确认后，也进入ESTABLISHED状态。  为什么要三次握手？\n​\t这主要是为了防止已失效的连接请求报文段突然又传送到了B，因而产生错误。\n所谓“已失效的连接请求报文段”是这样产生的。考虑一种正常情况。A发出连接请求，但因连接请求报文丢失而未收到确认。于是A再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接。A共发送了两个连接请求报文段，其中第一个丢失，第二个到达了B。没有“已失效的连接请求报文段”。现假定出现一种异常情况，即A发出的第一个连接请求报文段并没有丢失，而是在某些网络结点长时间滞留了，以致延误到连接释放以后的某个时间才到达B。本来这是一个早已失效的报文段。但B收到此失效的连接请求报文段后，就误认为是A又发出一次新的连接请求。于是就向A发出确认报文段，同意建立连接。假定不采用三次握手，那么只要B发出确认，新的连接就建立了。由于现在A并没有发出建立连接的请求，因此不会理睬B的确认，也不会向B发送数据。但B却以为新的运输连接已经建立了，并一直等待A发来数据。B的许多资源就这样白白浪费了。\n 数据传输结束后，通信的双方都可释放连接。现在A和B都处于ESTABLISHED状态（图5-32）。A的应用进程先向其TCP发出连接释放报文段，并停止再发送数据，主动关闭TCP连接。A把连接释放报文段首部的终止控制位FIN置1，其序号seq = u，它等于前面已传送过的数据的最后一个字节的序号加1。这时A进入FIN-WAIT-1（终止等待1）状态，等待B的确认。请注意，TCP规定，FIN报文段即使不携带数据，它也消耗掉一个序号。 B收到连接释放报文段后即发出确认，确认号是ack = u + 1，而这个报文段自己的序号是v，等于B前面已传送过的数据的最后一个字节的序号加1。然后B就进入CLOSE-WAIT（关闭等待）状态。TCP服务器进程这时应通知高层应用进程，因而从A到B这个方向的连接就释放了，这时的TCP连接处于半关闭(half-close)状态，即A已经没有数据要发送了，但B若发送数据，A仍要接收。也就是说，从B到A这个方向的连接并未关闭，这个状态可能会持续一些时间。 A收到来自B的确认后，就进入FIN-WAIT-2（终止等待2）状态，等待B发出的连接释放报文段。若B已经没有要向A发送的数据，其应用进程就通知TCP释放连接。这时B发出的连接释放报文段必须使FIN = 1。现假定B的序号为w（在半关闭状态B可能又发送了一些数据）。B还必须重复上次已发送过的确认号ack = u + 1。这时B就进入LAST-ACK（最后确认）状态，等待A的确认。 A在收到B的连接释放报文段后，必须对此发出确认。在确认报文段中把ACK置1，确认号ack = w + 1，而自己的序号是seq = u + 1（根据TCP标准，前面发送过的FIN报文段要消耗一个序号）。然后进入到TIME-WAIT（时间等待）状态。请注意，现在TCP连接还没有释放掉。必须经过时间等待计时器(TIME-WAIT timer)设置的时间2MSL后，A才进入到CLOSED状态。  为什么A在TIME-WAIT状态必须等待2MSL的时间呢？这有两个理由。\n第一，为了保证A发送的最后一个ACK报文段能够到达B。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的B收不到对已发送的FIN + ACK报文段的确认。B会超时重传这个FIN + ACK报文段，而A就能在2MSL时间内收到这个重传的FIN + ACK报文段。接着A重传一次确认，重新启动2MSL计时器。最后，A和B都正常进入到CLOSED状态。如果A在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后立即释放连接，那么就无法收到B重传的FIN + ACK报文段，因而也不会再发送一次确认报文段。这样，B就无法按照正常步骤进入CLOSED状态。第二，防止上一节提到的“已失效的连接请求报文段”出现在本连接中。A在发送完最后一个ACK报文段后，再经过时间2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。B只要收到了A发出的确认，就进入CLOSED状态。同样，B在撤销相应的传输控制块TCB后，就结束了这次的TCP连接。我们注意到，B结束TCP连接的时间要比A早一些。\n除时间等待计时器外，TCP还设有一个保活计时器(keepalive timer)。设想有这样的情况：客户已主动与服务器建立了TCP连接。但后来客户端的主机突然出故障。显然，服务器以后就不能再收到客户发来的数据。因此，应当有措施使服务器不要再白白等待下去。这就是使用保活计时器。服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两小时。若两小时没有收到客户的数据，服务器就发送一个探测报文段，以后则每隔75分钟发送一次。若一连发送10个探测报文段后仍无客户的响应，服务器就认为客户端出了故障，接着就关闭这个连接。\nTCP 重传、滑动窗口、流量控制、拥塞控制 TCP 实现可靠传输的方式之一，是通过序列号与确认应答。\n在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。当上一个数据包收到了应答了， 再发送下一个。\n这个模式就有点像我和你面对面聊天，你一句我一句。但这种方式的缺点是效率比较低的。\n如果你说完一句话，我在处理其他事情，没有及时回复你，那你不是要干等着我做完其他事情后，我回复你，你才能说下一句话，很显然这不现实。\n所以，这样的传输方式有一个缺点：数据包的往返时间越长，通信的效率就越低。\n为了解决这个问题，tcp使用了窗口的概念。\n滑动窗口 有了窗口，就可以指定窗口大小，窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。\n发送窗口表示：在没有收到B的确认的情况下，A可以连续把窗口内的数据都发送出去。凡是已经发送过的数据，在未收到确认之前都必须暂时保留（p1~p2），以便在超时重传时使用。\n接收窗口大小是20。在接收窗口外面，到30号为止的数据是已经发送过确认，并且已经交付主机了。因此在B可以不再保留这些数据。接收窗口内的序号（31～50）是允许接收的。B收到了序号为32和33的数据。这些数据没有按序到达，因为序号为31的数据没有收到（也许丢失了，也许滞留在网络中的某处）。请注意，B只能对按序收到的数据中的最高序号给出确认，因此B发送的确认报文段中的确认号仍然是31（即期望收到的序号），而不能是32或33。\n现在假定B收到了序号为31的数据，并把序号为31～33的数据交付主机，然后B删除这些数据。接着把接收窗口向前移动3个序号，同时给A发送确认，其中窗口值仍为20，但确认号是34。这表明B已经收到了到序号33为止的数据。我们注意到，B还收到了序号为37, 38和40的数据，但这些都没有按序到达，只能先暂存在接收窗口中。A收到B的确认后，就可以把发送窗口向前滑动3个序号，但指针P2不动。可以看出，现在A的可用窗口增大了，可发送的序号范围是42～53。\n这就是所谓的滑动窗口。\n重传方式 TCP 针对数据包丢失的情况，会用重传机制解决，重传方式有：\n 超时重传：就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据。 快速重传：是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。 SACK 方法：这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。 Duplicate SACK： 又称 D-SACK，其主要使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。  具体文章参考博文：https://www.cnblogs.com/xiaolincoding/p/12732052.html\n流量控制 一般说来，我们总是希望数据传输得更快一些。但如果发送方把数据发送得过快，接收方就可能来不及接收，这就会造成数据的丢失。所谓流量控制(flow control)就是让发送方的发送速率不要太快，要让接收方来得及接收。\n利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制。\n设A向B发送数据。在连接建立时，B告诉了A：“我的接收窗口rwnd = 400”（这里rwnd表示receiver window）。因此，发送方的发送窗口不能超过接收方给出的接收窗口的数值。请注意，TCP的窗口单位是字节，不是报文段。TCP连接建立时的窗口协商过程在图中没有显示出来。再设每一个报文段为100字节长，而数据报文段序号的初始值设为1（见图中第一个箭头上面的序号seq =1。图中右边的注释可帮助理解整个的过程）。请注意，图中箭头上面大写ACK表示首部中的确认位ACK，小写ack表示确认字段的值。\n我们应注意，接收方的主机B进行了三次流量控制。第一次把窗口减小到rwnd = 300，第二次又减到rwnd = 100，最后减到rwnd = 0，即不允许发送方再发送数据了。这种使发送方暂停发送的状态将持续到主机B重新发出一个新的窗口值为止。我们还应注意到，B向A发送的三个报文段都设置了ACK= 1，只有在ACK = 1时确认号字段才有意义。现在我们考虑一种情况。在图5-22中，B向A发送了零窗口的报文段后不久，B的接收缓存又有了一些存储空间。于是B向A发送了rwnd = 400的报文段。然而这个报文段在传送过程中丢失了。A一直等待收到B发送的非零窗口的通知，而B也一直等待A发送的数据。如果没有其他措施，这种互相等待的死锁局面将一直延续下去。为了解决这个问题，TCP为每一个连接设有一个持续计时器(persistence timer)。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口探测报文段（仅携带1字节的数据），而对方就在确认这个探测报文段时给出了现在的窗口值[插图]。如果窗口仍然是零，那么收到这个报文段的一方就重新设置持续计时器。如果窗口仍然是零，那么收到这个报文段的一方就重新设置持续计时器。如果窗口不是零，那么死锁的僵局就可以打破了。\n拥塞控制 在计算机网络中的链路容量（即带宽）、交换结点中的缓存和处理机等，都是网络的资源。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫做拥塞(congestion)。\n拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞窗口 cwnd是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的。\n发送窗口 swnd 和接收窗口 rwnd 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。\n拥塞控制的具体方法有：\n  慢开始(slow-start)：由小到大逐渐增大拥塞窗口数值，通常在刚刚开始发送报文段时，先把拥塞窗口cwnd设置为一个最大报文段MSS的数值[插图]。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。\n  拥塞避免(congestion avoidance)：是让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1\n  快重传(fast retransmit)：首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等待自己发送数据时才进行捎带确认，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，由于发送方能尽早重传未被确认的报文段，因此采用快重传后可以使整个网络的吞吐量提高约20%。\n  快恢复(fast recovery)：(1) 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把慢开始门限ssthresh减半。这是为了预防网络发生拥塞。请注意，接下去不执行慢开始算法。(2) 由于发送方现在认为网络很可能没有发生拥塞（如果网络发生了严重的拥塞，就不会一连有好几个报文段连续到达接收方，也就不会导致接收方连续发送重复确认），因此与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。不懂\n  DNS 域名解析服务 输入网址需要经过哪些协议 ​\t从输入URL到页面加载发生了什么？\n  DNS解析 ，将域名解析为ip地址\n  TCP连接，与服务器建立tcp连接，将http报文分割成报文段，并把每个报文段可靠地传给服务器\n  发送HTTP请求\n  服务器处理请求并返回HTTP报文\n  浏览器解析渲染页面\n  连接结束\n具体可以参考 https://segmentfault.com/a/1190000006879700\n  ​\t​\t表格版\n​\t上图有一个错误，请注意，是OSPF不是OPSF。 OSPF（Open Shortest Path First，ospf）开放最短路径优先协议,是由Internet工程任务组开发的路由选择协议\nhttps http的缺点：\n 通信使用明文（不加密），内容可能会被窃听 不验证通信方的身份，因此有可能遭遇伪装 无法证明报文的完整性，所以有可能已遭篡改  为了统一解决上述这些问题，我们把添加了加密及认证机制的HTTP称为HTTPS（HTTP Secure）。\nHTTPS并非是应用层的一种新协议。只是HTTP通信接口部分用SSL（SecureSocket Layer）和TLS（Transport Layer Security）协议代替而已。通常，HTTP直接和TCP通信。当使用SSL时，则演变成先和SSL通信，再由SSL和TCP通信了。简言之，所谓HTTPS，其实就是身披SSL协议这层外壳的HTTP。\nSSL是独立于HTTP的协议，所以不光是HTTP协议，其他运行在应用层的SMTP和Telnet等协议均可配合SSL协议使用。可以说SSL是当今世界上应用最为广泛的网络安全技术。\n加密方式   对称加密：加密和解密同用一个密钥的方式称为共享密钥加密（Common key cryptosystem），也被叫做对称密钥加密。优点：速度快 缺点：不安全\n  非对称加密：公开密钥加密使用一对非对称的密钥。一把叫做私有密钥（private key），另一把叫做公开密钥（public key）。优点：安全 缺点：速度慢。\n  HTTPS采用共享密钥加密和公开密钥加密两者并用的混合加密机制，在交换密钥环节使用公开密钥加密方式，之后的建立通信交换报文阶段则使用共享密钥加密方式。\n  遗憾的是，公开密钥加密方式还是存在一些问题的。那就是无法证明公开密钥本身就是货真价实的公开密钥。\n比如，正准备和某台服务器建立公开密钥加密方式下的通信时，如何证明收到的公开密钥就是原本预想的那台服务器发行的公开密钥。或许在公开密钥传输途中，真正的公开密钥已经被攻击者替换掉了。\n为了解决上述问题，可以使用由数字证书认证机构（CA,CertificateAuthority）和其相关机关颁发的公开密钥证书。数字证书认证机构的业务流程：\n  首先，服务器的运营人员向数字证书认证机构提出公开密钥的申请。数字证书认证机构在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公钥证书后绑定在一起。\n  服务器会将这份由数字证书认证机构颁发的公钥证书发送给客户端，以进行公开密钥加密方式通信。公钥证书也可叫做数字证书或直接称为证书。\n  接到证书的客户端可使用数字证书认证机构的公开密钥，对那张证书上的数字签名进行验证，一旦验证通过，客户端便可明确两件事：一，认证服务器的公开密钥的是真实有效的数字证书认证机构。二，服务器的公开密钥是值得信赖的。\n  此处认证机关的公开密钥必须安全地转交给客户端。使用通信方式时，如何安全转交是一件很困难的事，因此，多数浏览器开发商发布版本时，会事先在内部植入常用认证机关的公开密钥。\nHTTPS的安全通信机制 步骤1： 客户端通过发送Client Hello报文开始SSL通信。报文中包含客户端支持的SSL的指定版本、加密组件（Cipher Suite）列表（所使用的加密算法及密钥长度等）。\n步骤2： 服务器可进行SSL通信时，会以Server Hello报文作为应答。和客户端一样，在报文中包含SSL版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的。\n步骤3： 之后服务器发送Certificate报文。报文中包含公开密钥证书。\n步骤4： 最后服务器发送Server Hello Done报文通知客户端，最初阶段的SSL握手协商部分结束。\n步骤5: SSL第一次握手结束之后，客户端以Client Key Exchange报文作为回应。报文中包含通信加密中使用的一种被称为Pre-master secret的随机密码串。该报文已用步骤3中的公开密钥进行加密。\n步骤6： 接着客户端继续发送Change Cipher Spec报文。该报文会提示服务器，在此报文之后的通信会采用Pre-master secret密钥加密。\n步骤7： 客户端发送Finished报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准。\n步骤8： 服务器同样发送Change Cipher Spec报文。\n步骤9： 服务器同样发送Finished报文。\n步骤10： 服务器和客户端的Finished报文交换完毕之后，SSL连接就算建立完成。当然，通信会受到SSL的保护。从此处开始进行应用层协议的通信，即发送HTTP请求。\n步骤11： 应用层协议通信，即发送HTTP响应。\n步骤12： 最后由客户端断开连接。断开连接时，发送close_notify报文。上图做了一些省略，这步之后再发送TCP FIN报文来关闭与TCP的通信。在以上流程中，应用层发送数据。\nmaster key 就是https通信中使用的共享密钥\nhttps的问题  一种是指通信慢。和使用HTTP相比，网络负载可能会变慢2到100倍。除去和TCP连接、发送HTTP请求·响应以外，还必须进行SSL通信，因此整体上处理通信量不可避免会增加。 另一种是指由于大量消耗CPU及内存等资源，导致处理速度变慢。SSL必须进行加密处理。在服务器和客户端都需要进行加密和解密的运算处理。因此从结果上讲，比起HTTP会更多地消耗服务器和客户端的硬件资源，导致负载增强。  ","id":10,"section":"posts","summary":"图解http 网络模型 OSI 模型(具体每层的定义还需要看书确定这个只是网上看的，可以回去看计网) 应用层（application）：最接近终端用户的","tags":["http"],"title":"图解http","uri":"https://wzgl998877.github.io/2022/01/%E5%9B%BE%E8%A7%A3http/","year":"2022"},{"content":"数据库知识 一些函数 orcale中的decode() 函数 ​\tdecode(条件,值1，返回值1，值2，返回值2,\u0026hellip;.值n，返回值n，缺省值)；\n​\tdecode(字段或字段的运算，值1，值2，值3）\nselect decode(COUPON_AMOUNT,'40.00','1','2'),COUPON_AMOUNT from T_CHN_WECHAT_LIST;--如果是40.00那么就是1否则就是2\r ​\t用来代替case when then else end\nselect decode(name,'a',id,0) id_1,\rdecode(name,'b',id,0) id_2,\rdecode(name,'c',id,0) id_3 from t_decode;\r-- 相等于：case when then else end\rselect case name when 'a' then id else 0 end as id_1,\rcase name when 'b' then id else 0 end as id_2,\rcase name when 'c' then id else 0 end as id_3 from t_decode;\r 与order by连用\n order by 1,代表按第一个栏位排序，order by 加数字代表按第几个栏位排序。 order by 中认为null是最大值，所以如果是ASC升序则排在最后，DESC降序则排在最前。 order by 与 decode连用可以达到自定义排序的效果。  SELECT t.rowid rd, row_number() over (PARTITION BY t.chn_check_id ORDER BY decode(t.status, '2', '5', t.status), t.trans_time DESC) rn FROM settle_user.t_check_trans_tmp_list t\rWHERE t.chn_check_id IS NOT NULL -- 先根据chn_check_id 分区，然后根据状态和时间排序，其中如果status是2则按照5来排序，其他status就按照本来的值来排序，这里status的取值为0,1,2,3,4；所以5排在最后，所以当status为2时排在最后\r 参考博客：https://blog.csdn.net/qichangjian/article/details/88975499\nhttps://blog.csdn.net/qq_35029061/article/details/82795804?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control\u0026amp;dist_request_id=1328696.1178.16166729427143225\u0026amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control\ncase when CASE WHEN用于SQL语句中的条件判断，Case具有两种格式，简单Case函数和Case搜索函数\n--简单Case函数\rCASE sex WHEN '1' THEN '男'\rWHEN '2' THEN '女'\rELSE '其他' END\r--Case搜索函数\rCASE WHEN sex = '1' THEN '男'\rWHEN sex = '2' THEN '女'\rELSE '其他' END\r 几个注意的点\n 在case when中若不加else，那么不满足条件就为null。 执行到end，如果end后还有语句会继续执行。  CASE WHEN sex = '1' THEN '男'\rWHEN sex = '2' THEN '女'\rELSE '其他' END '太监'\r-- 那么无论是什么都会变为太监 哈哈\r orcale 中的序列 sequence是序列号生成器，可以为表中的行自动生成序列号，产生一组等间隔的数值(类型为数字)。其主要的用途是生成表的主键值，可以在插入语句中引用，在插入之前，获取序列号nextval值，然后进行插入。也可以通过查询检查当前值，或使序列增至下一个值。\n创建序列 create sequence t_mng_user_user_id\rincrement by 1 -- 每次加几个\rstart with 1 -- 从几开始计数\rnomaxvalue -- 不设置最大值\rnocycle -- 一直累加，不循环\rcache 10;\r 这里创建了一个序列，序列名称叫做t_mng_user_user_id 从1开始每次加一\n使用序列 select t_mng_user_user_id.nextval from DUAL; -- 获得增加后的值\rselect t_mng_user_user_id.currval from DUAL; -- 获得当前值\r 使用场景   不包含子查询、snapshot、VIEW的 SELECT 语句\n  INSERT语句的子查询中\n  INSERT语句的VALUES中\n  UPDATE 的 SET中\n例如：\n  update T_MNG_USER set USER_ID = t_mng_user_user_id.nextval where USER_ID = '2021030510101722';\r 集合函数  union 并集运算  select USER_ID from T_MNG_USER union select USER_ID from T_MNG_USER_ROLE ;\r 注意：如果union前面是n列，那么后面也必须是n列，即union前后列数必须相同。而且查询结果的列名是按照union前面n列的名称命名\nINTERSECT 交集运算  select USER_ID from T_MNG_USER intersect select USER_ID from T_MNG_USER_ROLE where USER_ID = '2017112710000009';\r 注意：intersect前面列名和后面列名要相同\nMINUS 差集  select USER_ID from T_MNG_USER where USER_ID in ('2017112710000009','2013061210007957') minus select USER_ID from T_MNG_USER_ROLE where USER_ID = '2017112710000009';\r ","id":11,"section":"posts","summary":"数据库知识 一些函数 orcale中的decode() 函数 ​ decode(条件,值1，返回值1，值2，返回值2,\u0026hellip;.值n，返回值n","tags":null,"title":"数据库知识","uri":"https://wzgl998877.github.io/2022/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9F%A5%E8%AF%86/","year":"2022"},{"content":"日常问题总结 工作中总是会遇到各种各样的问题，只有总结下来才是一笔财富。\nfastjson的一些技巧 在工作中总是遇到给前端的字段需要是下划线的，这时候可以通过全局配置来实现。\n添加这个配置bean后，所有的http请求都会进行转换，即会将返回参数改为下划线\n@Bean\rpublic HttpMessageConverters fastJsonHttpMessageConverters(){\rFastJsonHttpMessageConverter converter = new FastJsonHttpMessageConverter();\rFastJsonConfig fastJsonConfig = new FastJsonConfig();\r// 格式化输出，也就是换行等处理\rfastJsonConfig.setSerializerFeatures(SerializerFeature.PrettyFormat);\rSerializeConfig config = new SerializeConfig();\r// 转为下划线\rconfig.propertyNamingStrategy = PropertyNamingStrategy.SnakeCase;\rfastJsonConfig.setSerializeConfig(config);\rconverter.setFastJsonConfig(fastJsonConfig);\rreturn new HttpMessageConverters(converter);\r}\rCamelCase策略，Java对象属性：personId，序列化后属性：persionId\rPascalCase策略，Java对象属性：personId，序列化后属性：PersonId\rSnakeCase策略，Java对象属性：personId，序列化后属性：person_id\rKebabCase策略，Java对象属性：personId，序列化后属性：person-id\r 例子：\n@Data\rpublic class TestResponse {\rprivate String userName;\rprivate String teacherName;\r}\r @RequestMapping(\u0026quot;/group/test\u0026quot;)\rpublic Object test(HttpServletRequest request, HttpServletResponse response) {\rTestResponse response1 = new TestResponse();\rresponse1.setUserName(\u0026quot;zt\u0026quot;);\rresponse1.setTeacherName(\u0026quot;zt\u0026quot;);\rreturn response1;\r}\r// 返回结果就自动转为了下划线了\r{\r\u0026quot;teacher_name\u0026quot;: \u0026quot;zt\u0026quot;,\r\u0026quot;user_name\u0026quot;: \u0026quot;zt\u0026quot;\r}\r 除了这种全局配置的方式，也可以进行代码层面的配置\n转为string\n@RequestMapping(\u0026quot;/test\u0026quot;)\rpublic String test(HttpServletRequest request, HttpServletResponse response) {\rTestResponse response1 = new TestResponse();\rresponse1.setUserName(\u0026quot;zt\u0026quot;);\rresponse1.setTeacherName(\u0026quot;zt\u0026quot;);\rSerializeConfig config = new SerializeConfig();\rconfig.propertyNamingStrategy = PropertyNamingStrategy.SnakeCase;\r// 返回的json就是下划线的\rreturn JSON.toJSONString(response1, config);\r}\r{\u0026quot;teacher_name\u0026quot;:\u0026quot;zt\u0026quot;,\u0026quot;user_name\u0026quot;:\u0026quot;zt\u0026quot;}\r string转为对象\n@RequestMapping(\u0026quot;/test2\u0026quot;)\rpublic Object test2(HttpServletRequest request, HttpServletResponse response) {\rString response1 = \u0026quot;{\\\u0026quot;teacherName\\\u0026quot;:\\\u0026quot;zt\\\u0026quot;,\\\u0026quot;userName\\\u0026quot;:\\\u0026quot;zt\\\u0026quot;}\u0026quot;;\r// 转为下划线\rParserConfig parserConfig = new ParserConfig();\rparserConfig.propertyNamingStrategy = PropertyNamingStrategy.SnakeCase;\rreturn JSON.parseObject(response1, TestResponse.class, parserConfig);\r}\r// 很奇怪应该不是这样的\r{\r\u0026quot;userName\u0026quot;: \u0026quot;zt\u0026quot;,\r\u0026quot;teacherName\u0026quot;: \u0026quot;zt\u0026quot;\r}\r 这个本来应该也是的，但是现在有点尴尬，不得行\nJava 中是“值传递” java中方法参数传递方式是按值传递,只不过值不同。\r如果参数是基本类型，传递的是基本类型的字面量值的拷贝。\r如果参数是引用类型，传递的是该参量所引用的对象在堆中地址值的拷贝。\r 举例：\npackage com.zt.javastudy.grammar;\r/**\r* @author zhengtao\r* @description java中方法参数传递方式是按值传递。\r* 如果参数是基本类型，传递的是基本类型的字面量值的拷贝。\r* 如果参数是引用类型，传递的是该参量所引用的对象在堆中地址值的拷贝。\r* @date 2021/4/25\r*/\rpublic class QuoteStudy {\rpublic static void main(String[] args) {\rint a = 0;\radd(a);\rSystem.out.println(a);\rString b = \u0026quot;hello\u0026quot;;\radd(b);\rSystem.out.println(b);\rStringBuilder c = new StringBuilder(\u0026quot;hello\u0026quot;);\radd(c);\rSystem.out.println(c);\rStringBuilder d = new StringBuilder(\u0026quot;hello\u0026quot;);\rmove(d);\rSystem.out.println(d);\r}\r/**\r* 基本类型传递的值的拷贝，所以不影响原值\r* @param a\r*/\rprivate static void add(int a){\ra = 1;\r}\r/**\r* 对象传递的是对象的引用的拷贝，所以如果改变对象的属性是可以改变，如果将引用赋值给另一个对象，则不会改变原对象的引用\r* @param b\r*/\rprivate static void add(String b){\r// 在字符中 = ，就相当于重新new对象，因为string类型是不可变的，等价于b = new String(\u0026quot;helloWorld\u0026quot;)\rb = \u0026quot;helloWorld\u0026quot;;\r}\r/**\r* 对象传递的是对象的引用的拷贝,改变对象属性可以成功\r* @param c\r*/\rprivate static void add(StringBuilder c){\rc = c.append(\u0026quot;world!\u0026quot;);\r}\r/**\r* 改变引用的指向，不成功\r* @param c\r*/\rprivate static void move(StringBuilder c){\rc = new StringBuilder(\u0026quot;helloworld!\u0026quot;);\r}\r}\r// 结果\r0\rhello\rhelloworld!\rhello\r @Autowired 的一点发现 在日常写代码中基本上都是，写一个service，写一个impl，然后将@Service注解加在impl类上，在代码中直接使用@Autowired 自动注入。\n@autowired注释可以对类成员变量、方法、构造函数进行标注，完成自动装配功能。@autowired查找bean首先是先通过byType查，如果发现找到有很多bean，则按照byName方式对比获取，若有名称一样的则可以加上@Qualifier(\u0026ldquo;XXX\u0026rdquo;)配置使用。\n所以说当一个service只有一个一个impl实现时，自动注入根据byType发现只有一个实现，所以就能正确进行装配，但是如果有多个实现则会报错。\npublic interface TestService {\rvoid test();\r}\r@Service\rpublic class TestServiceImpl implements TestService {\r@Override\rpublic void test() {\rSystem.out.println(\u0026quot;实现1\u0026quot;);\r}\r}\r@Service\rpublic class TestServiceI2mpl implements TestService {\r@Override\rpublic void test() {\rSystem.out.println(\u0026quot;实现2\u0026quot;);\r}\r}\r 这时可以使用@Qualifier注解来完成正确的装配\n@Slf4j\r@RunWith(SpringRunner.class)\r@SpringBootTest()\rpublic class AopStudyTest {\r// 多个实现类，使用@Qudalifier使用byName注入\r@Qualifier(\u0026quot;testServiceImpl\u0026quot;)\r@Autowired\rprivate TestService testService;\r@Qualifier(\u0026quot;testServiceI2mpl\u0026quot;)\r@Autowired\rprivate TestService testService2;\r@Test\rpublic void testService(){\rtestService.test();\rtestService2.test();\r}\r}\r 公司的一套框架 web容器同步请求 Web容器（比如tomcat）默认情况下会为每个请求分配一个请求处理线程（在tomcat7/8中，能够同时处理到达的请求的线程数量默认为200），默认情况下，在响应完成前，该线程资源都不会被释放。如图所示：\n处理HTTP请求和执行具体业务代码的线程是同一个线程！\n如果业务代码处理时间比较长，那么请求处理线程将一直被占用，直到任务结束，这种情况下，随着并发请求数量的增加，将可能导致处理请求线程全部被占用，此时tomcat会将后来的请求堆积到内部阻塞队列容器中，如果存放请求的阻塞队列也满了，那么后续的进来请求将会遭遇拒绝服务，直到有线程资源可以处理请求为止。\n实践是检验真理的唯一标准 将工作线程设为1，方便测试\nserver:\rport: 19003\rtomcat:\ruri-encoding: UTF-8\rmax-threads: 1 #最大工作线程数量\rmin-spare-threads: 1 #最小工作线程数量\r#max-connections: 10000 #一瞬间最大支持的并发的连接数\raccept-count: 1 #等待队列长度\r @RequestMapping(\u0026quot;/testCommon\u0026quot;)\rpublic String testCommon() throws InterruptedException {\rlog.info(\u0026quot;请求开始！\u0026quot;);\rstart = System.currentTimeMillis();\rThread.sleep(5000);\rlog.info(\u0026quot;请求处理时间:{}ms\u0026quot;, (System.currentTimeMillis() - start));\rreturn \u0026quot;hello world!\u0026quot;;\r}\r 返回结果为：\n很明显的看到当有两个请求过来时，第二个会阻塞，直到第一个请求完成后才会开始处理，而且执行请求的线程和处理业务的线程是同一个线程。\nweb容器异步请求 有同步请求当然就有异步请求，Servlet 3.0开始支持异步处理请求。在接收到请求之后，Servlet线程可以将耗时的操作委派给另一个线程来完成，自己在不生成响应的情况下返回至容器，以便能处理另一个请求。此时当前请求的响应将被延后，在异步处理完成后时再对客户端进行响应（异步线程拥有 ServletRequest 和 ServletResponse 对象的引用）。开启异步请求处理之后，Servlet 线程不再是一直处于阻塞状态以等待业务逻辑的处理，而是启动异步线程之后可以立即返回。异步处理的特性可以帮助应用节省容器中的线程。如图所示：\n 我们还能发现，实际上这里的异步请求处理对于客户端浏览器来说仍然是同步输出，它并没有提升响应速度，用户是没有感知的，但是异步请求处理解放了服务器端的请求处理线程的使用，处理请求线程并没有卡在业务代码那里等待，当前的业务逻辑被转移给其他线程去处理了，能够让tomcat同时接受更多的请求，从而提升了并发处理请求的能力！\n代码说话\npackage com.zt.javastudy.async;\rimport brave.Tracing;\rimport lombok.extern.slf4j.Slf4j;\rimport org.springframework.beans.factory.annotation.Autowired;\rimport org.springframework.beans.factory.annotation.Qualifier;\rimport org.springframework.beans.factory.config.ConfigurableBeanFactory;\rimport org.springframework.cloud.sleuth.SpanNamer;\rimport org.springframework.cloud.sleuth.instrument.async.TraceRunnable;\rimport org.springframework.context.annotation.Scope;\rimport org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;\rimport org.springframework.util.ObjectUtils;\rimport org.springframework.web.bind.annotation.RequestMapping;\rimport org.springframework.web.bind.annotation.RestController;\rimport javax.servlet.AsyncContext;\rimport javax.servlet.ServletOutputStream;\rimport javax.servlet.http.HttpServletRequest;\rimport javax.servlet.http.HttpServletResponse;\rimport java.io.IOException;\r/**\r* 测试异步http请求\r*\r* @author zhengtao on 2021/9/23\r*/\r@RestController\r@Slf4j\r@Scope(value = ConfigurableBeanFactory.SCOPE_PROTOTYPE)\rpublic class AsyncController {\r@Autowired\r@Qualifier(\u0026quot;httpWorkThreadPool\u0026quot;)\rprivate ThreadPoolTaskExecutor executor;\r@Autowired\rprivate Tracing tracing;\r@Autowired\rprivate SpanNamer defaultSpanNamer;\r// private static LongAdder start = new LongAdder();\rprivate volatile long start;\r@RequestMapping(\u0026quot;/testAsync\u0026quot;)\rpublic void test(HttpServletRequest request, HttpServletResponse response) {\rlog.info(\u0026quot;请求开始！\u0026quot;);\rstart = System.currentTimeMillis();\rAsyncContext asyncContext = request.startAsync(request, response);\r// 设置监听\rasyncContext.addListener(new HttpAsyncListener());\rexecutor.execute(new TraceRunnable(tracing, defaultSpanNamer, () -\u0026gt; {\rtry {\rdoInvoke(asyncContext);\r} catch (InterruptedException e) {\re.printStackTrace();\r}\r}));\r}\r/**\r* 处理业务\r*\r* @param asyncContext\r*/\rprivate void doInvoke(AsyncContext asyncContext) throws InterruptedException {\rThread.sleep(5000);\rcompleteResponse(\u0026quot;这是一个异步的http请求\u0026quot;, 200, asyncContext);\r}\r/**\r* 将\r* @param context\r* @param status\r* @param asyncContext\r*/\rprivate void completeResponse(String context, int status, AsyncContext asyncContext) {\rHttpServletResponse servletResponse = (HttpServletResponse) asyncContext.getResponse();\rif (!ObjectUtils.isEmpty(context)) {\rservletResponse.setContentType(asyncContext.getRequest().getContentType());\rservletResponse.setStatus(status);\rcompleteResponse(servletResponse, context);\r}\r// 调用了complete方法后才算请求完成\rasyncContext.complete();\rlog.info(\u0026quot;请求处理时间:{}ms\u0026quot;, (System.currentTimeMillis() - start));\r}\rprivate void completeResponse(HttpServletResponse servletResponse, String context) {\rServletOutputStream out = null;\rtry {\rbyte[] buff = context.getBytes();\rservletResponse.setContentLength(buff.length);\rout = servletResponse.getOutputStream();\rout.write(buff);\rout.flush();\r} catch (IOException e) {\rlog.error(\u0026quot;complete http reqeust error\u0026quot;, e);\r} finally {\rif (out != null) {\rtry {\rout.close();\r} catch (Exception e) {\rlog.error(e.getMessage(), e);\r}\r}\r}\r}\r}\r package com.zt.javastudy.async;\rimport lombok.extern.slf4j.Slf4j;\rimport javax.servlet.AsyncEvent;\rimport javax.servlet.AsyncListener;\rimport java.io.IOException;\r/**\r* 异步监听器\r*\r* @author zhengtao on 2021/9/23\r*/\r@Slf4j\rpublic class HttpAsyncListener implements AsyncListener {\r@Override\rpublic void onComplete(AsyncEvent event) throws IOException {\rlog.info(\u0026quot;http异步请求完成\u0026quot;);\r}\r@Override\rpublic void onTimeout(AsyncEvent event) throws IOException {\rlog.info(\u0026quot;http请求超时\u0026quot;);\r}\r@Override\rpublic void onError(AsyncEvent event) throws IOException {\rlog.info(\u0026quot;http请求失败\u0026quot;);\r}\r@Override\rpublic void onStartAsync(AsyncEvent event) throws IOException {\rlog.info(\u0026quot;http异步请求开始\u0026quot;);\r}\r}\r 测试，同样是发两个请求：\n可以很明显的看到，请求线程是同一个，但是第一个请求还没结束第二个请求就已经开始处理了。业务代码则是自定义的线程池处理的。\n搞懂这个之后看公司的代码就很简单了\n静态方法中使用bean 写一些工具类时，可能会用到其他的bean。第一眼是这样写的\n@Component\rpublic class MerchUtils {\r@Autowired\rprivate static IAgentService iAgentService;\rprivate static ConcurrentHashMap\u0026lt;String, Agent\u0026gt; agentMap = new ConcurrentHashMap\u0026lt;\u0026gt;();\rpublic static String getAgentName(String agentId) {\rAgent agent = agentMap.get(agentId);\rif (agent == null \u0026amp;\u0026amp; !agentMap.containsKey(agentId)) {\ragent = iAgentService.get(agentId);\rif (agent != null \u0026amp;\u0026amp; StringUtils.isNotEmpty(agentId)) {\ragentMap.put(agentId, agent);\r}\r}\rif (agent == null) {\rreturn agentId;\r}\rreturn agent.getAgentNameCn();\r}\r}\r 这样会报null，因为静态方法优先于bean的注入。\n正确写法为：\npublic class MerchUtils {\rprivate static IAgentService iAgentService;\r@Autowired\rpublic MerchUtils(IAgentService iAgentService) {\rMerchUtils.iAgentService = iAgentService;\r}\rprivate static ConcurrentHashMap\u0026lt;String, Agent\u0026gt; agentMap = new ConcurrentHashMap\u0026lt;\u0026gt;();\rpublic static String getAgentName(String agentId) {\rAgent agent = agentMap.get(agentId);\rif (agent == null \u0026amp;\u0026amp; !agentMap.containsKey(agentId)) {\ragent = iAgentService.get(agentId);\rif (agent != null \u0026amp;\u0026amp; StringUtils.isNotEmpty(agentId)) {\ragentMap.put(agentId, agent);\r}\r}\rif (agent == null) {\rreturn agentId;\r}\rreturn agent.getAgentNameCn();\r}\r}\r @ConditionalOnProperty 有时需要根据配置文件来决定是否创建 bean\npackage com.zt.javastudy.grammar;\rimport lombok.extern.slf4j.Slf4j;\rimport org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;\rimport org.springframework.context.annotation.Bean;\rimport org.springframework.context.annotation.Configuration;\r/**\r* 注解学习\r*\r* @author zhengtao on 2021/10/27\r*/\r@Configuration\r@ConditionalOnProperty(\rprefix = \u0026quot;test\u0026quot;,\rname = {\u0026quot;enable\u0026quot;},\rhavingValue = \u0026quot;true\u0026quot;,\rmatchIfMissing = false\r)\r@Slf4j\rpublic class ConditionalTest {\r@Bean(initMethod = \u0026quot;start\u0026quot;, destroyMethod = \u0026quot;shutdown\u0026quot;)\rpublic ConditionalTest buildProducer() {\rlog.info(\u0026quot;创建bean了\u0026quot;);\rConditionalTest conditionalTest = new ConditionalTest();\rreturn conditionalTest;\r}\rprivate void start() {\r}\rprivate void shutdown() {\r}\r}\r 其中 name 就是配置项的名称，havingValue 就是匹配的值，在这个代码中只有test.enable=true,才会创建bean。\n分布式id解决方案 uuid ​\tUUID(Universally Unique Identifier)的标准型式包含32个16进制数字，以连字号分为五段，形式为8-4-4-4-12的36个字符，示例：550e8400-e29b-41d4-a716-446655440000\n优点：\n 性能非常高：本地生成，没有网络消耗。  缺点：\n  不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。\n  信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。\n  ID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用：\n① MySQL官方有明确的建议主键要尽量越短越好，36个字符长度的UUID不符合要求。\n② 对MySQL索引不利：如果作为数据库主键，在InnoDB引擎下，UUID的无序性可能会引起数据位置频繁变动，严重影响性能。\n  snowflake(雪花算法) ​\t雪花算法（Snowflake）是twitter公司内部分布式项目采用的ID生成算法，具体规则如下：\n 1位，不用。二进制中最高位为1的都是负数，但是我们生成的id一般都使用整数，所以这个最高位固定是0 41位，用来记录时间戳（毫秒）。 - 41位可以表示 2^{41}-1 个数字，  如果只用来表示正整数（计算机中正数包含0），可以表示的数值范围是：0 至 2^{41}-1，减1是因为可表示的数值范围是从0开始算的，而不是1。 - 也就是说41位可以表示 2^{41}-1 个毫秒的值，转化成单位年则是 (2^{41}-1) / (1000 60 60 24 365) = 69 年   10位，用来记录工作机器id。 - 可以部署在 2^{10} = 1024 个节点，包括 5位 datacenterId 和 5位 workerId - 5位（bit）可以表示的最大正整数是 2^{5}-1 = 31 ，即可以用 0、1、2、3、\u0026hellip;.31 这 32 个数字，来表示不同的 datecenterId 或 workerId 12位，序列号，用来记录同毫秒内产生的不同id。 - 12位（bit）可以表示的最大正整数是 2^{12}-1 = 4095 ，即可以用 0、1、2、3、\u0026hellip;.4094 这 4095 个数字，来表示同一机器同一时间截（毫秒)内产生的 4095 个 ID 序号。  由于在 Java 中 64bit 的整数是 long 类型，所以在 Java 中 SnowFlake 算法生成的 id 就是 long 来存储的。\n优点：\n 毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。 可以根据自身业务特性分配bit位，非常灵活。  缺点：\n 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。  基于Redis模式 Redis也同样可以实现，原理就是利用redis的 incr命令实现ID的原子性自增。\n127.0.0.1:6379\u0026gt; set seq_id 1 // 初始化自增ID为1\rOK\r127.0.0.1:6379\u0026gt; incr seq_id // 增加1，并返回递增后的数值\r(integer) 2\r 用redis实现需要注意一点，要考虑到redis持久化的问题。redis有两种持久化方式RDB和AOF\n RDB会定时打一个快照进行持久化，假如连续自增但redis没及时持久化，而这会Redis挂掉了，重启Redis后会出现ID重复的情况。 AOF会对每条写命令进行持久化，即使Redis挂掉了也不会出现ID重复的情况，但由于incr命令的特殊性，会导致Redis重启恢复的数据时间过长。  简单代码演示：\nLong serialNo = RedisTemplateUtil.incrBy(REDIS_KEY_PREFIX + seq.getSequenceName(), seq.getStep());\rpublic static Long incrBy(String key, long delta){\rreturn getRedisTemplate().opsForValue().increment(key, delta);\r}\r mybatis - 动态数据源 动态数据源，主要是为了解决读写分离的场景。\n那么创建一个数据源主要有哪几步呢？\n 配置 dao，model(bean)，xml mapper文件的扫描路径 注入数据源配置属性，创建数据源。 将数据源设置到SQL会话工厂和事务管理器。  这样当进行数据库操作时，就会通过我们创建的动态数据源去获取要操作的数据源了。一步一步操作完成功能\n创建多个数据源 package com.jlpay.saas.common.db.datasource;\rimport com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceBuilder;\rimport lombok.extern.slf4j.Slf4j;\rimport org.springframework.beans.factory.annotation.Qualifier;\rimport org.springframework.boot.context.properties.ConfigurationProperties;\rimport org.springframework.context.annotation.Bean;\rimport org.springframework.context.annotation.Configuration;\rimport org.springframework.context.annotation.Primary;\rimport javax.sql.DataSource;\rimport java.util.HashMap;\rimport java.util.Map;\r/**\r* @Description: 配置多数据源\r* @Author shuqingzhou\r* @Date 2021/11/15 9:09\r* @Version 1.0\r*/\r@Configuration\r@Slf4j\rpublic class DynamicDataSourceConfig {\r/**\r* 创建 DataSource Bean\r*/\r@Primary\r@Bean(\u0026quot;masterDataSource\u0026quot;)\r@ConfigurationProperties(prefix = \u0026quot;spring.datasource.druid.master\u0026quot;)\rpublic DataSource masterDataSource(){\rDataSource dataSource = DruidDataSourceBuilder.create().build();\rreturn dataSource;\r}\r/**\r* 创建 DataSource Bean\r*/\r@Bean(\u0026quot;slaveDataSource\u0026quot;)\r@ConfigurationProperties(prefix = \u0026quot;spring.datasource.druid.salve\u0026quot;)\rpublic DataSource slaveDataSource(){\rDataSource dataSource = DruidDataSourceBuilder.create().build();\rreturn dataSource;\r}\r/**\r* 如果还有数据源,在这继续添加 DataSource Bean\r*/\r@Bean(\u0026quot;dynamicDataSource\u0026quot;)\r@Primary\rpublic DynamicDataSource dynamicDataSource(@Qualifier(\u0026quot;masterDataSource\u0026quot;) DataSource masterDataSource, @Qualifier(\u0026quot;slaveDataSource\u0026quot;)DataSource slaveDataSource) {\rMap\u0026lt;Object, Object\u0026gt; targetDataSources = new HashMap\u0026lt;\u0026gt;(2);\rtargetDataSources.put(DataSourceNames.MASTER, masterDataSource);\rtargetDataSources.put(DataSourceNames.SLAVE, slaveDataSource);\r// 还有数据源,在targetDataSources中继续添加\rlog.info(\u0026quot;DataSources:{}\u0026quot;, targetDataSources);\rreturn new DynamicDataSource(masterDataSource, targetDataSources);\r}\r}\r 将数据源设置到SQL会话工厂和事务管理器 package com.jlpay.saas.common.db.datasource;\rimport org.apache.ibatis.session.SqlSessionFactory;\rimport org.mybatis.spring.SqlSessionFactoryBean;\rimport org.mybatis.spring.SqlSessionTemplate;\rimport org.mybatis.spring.boot.autoconfigure.MybatisProperties;\rimport org.springframework.beans.factory.annotation.Autowired;\rimport org.springframework.beans.factory.annotation.Qualifier;\rimport org.springframework.boot.context.properties.EnableConfigurationProperties;\rimport org.springframework.context.annotation.Bean;\rimport org.springframework.context.annotation.Configuration;\rimport org.springframework.core.io.*;\rimport org.springframework.jdbc.datasource.DataSourceTransactionManager;\rimport org.springframework.transaction.PlatformTransactionManager;\rimport java.io.File;\rimport java.io.FileInputStream;\rimport java.io.InputStream;\r/**\r* @Description: Mybatis数据源配置\r* @Author shuqingzhou\r* @Date 2021/11/15 9:09\r* @Version 1.0\r*/\r@Configuration\r@EnableConfigurationProperties(MybatisProperties.class)\rpublic class MybatisConfig {\rprivate MybatisProperties mybatisProperties;\rpublic MybatisConfig(MybatisProperties properties) {\rthis.mybatisProperties = properties;\r}\r@Autowired\r@Qualifier(value = \u0026quot;dynamicDataSource\u0026quot;)\rprivate DynamicDataSource dynamicDataSource;\r/**\r* 配置mybatis的sqlSession连接动态数据源\r* @throws Exception\r*/\r@Bean\rpublic SqlSessionFactory sqlSessionFactory() throws Exception {\rSqlSessionFactoryBean bean = new SqlSessionFactoryBean();\rbean.setDataSource(dynamicDataSource);\rbean.setMapperLocations(mybatisProperties.resolveMapperLocations());\rbean.setTypeAliasesPackage(mybatisProperties.getTypeAliasesPackage());\rResource resource = new DefaultResourceLoader().getResource(mybatisProperties.getConfigLocation());\rbean.setConfigLocation(resource);\rbean.setConfiguration(mybatisProperties.getConfiguration());\rreturn bean.getObject();\r}\r@Bean\rpublic SqlSessionTemplate sqlSessionTemplate() throws Exception {\rreturn new SqlSessionTemplate(sqlSessionFactory());\r}\r/**\r* 将动态数据源添加到事务管理器中，并生成新的bean\r* @return the platform transaction manager\r*/\r@Bean\rpublic PlatformTransactionManager transactionManager() {\rreturn new DataSourceTransactionManager(dynamicDataSource);\r}\r}\r tips：在访问数据库时会调用 determineCurrentLookupKey() 方法获取数据库实例的 key\nprotected DataSource determineTargetDataSource() {\rAssert.notNull(this.resolvedDataSources, \u0026quot;DataSource router not initialized\u0026quot;);\rObject lookupKey = determineCurrentLookupKey();\rDataSource dataSource = this.resolvedDataSources.get(lookupKey);\rif (dataSource == null \u0026amp;\u0026amp; (this.lenientFallback || lookupKey == null)) {\rdataSource = this.resolvedDefaultDataSource;\r}\rif (dataSource == null) {\rthrow new IllegalStateException(\u0026quot;Cannot determine target DataSource for lookup key [\u0026quot; + lookupKey + \u0026quot;]\u0026quot;);\r}\rreturn dataSource;\r}\r@Nullable\rprotected abstract Object determineCurrentLookupKey();\r 所以我们可以通过重写 determineCurrentLookupKey 方法来实现更改数据源\npackage com.jlpay.saas.common.db.datasource;\rimport org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;\rimport javax.sql.DataSource;\rimport java.util.Map;\r/**\r* @Description: 动态多数据源\r* @Author shuqingzhou\r* @Date 2021/11/15 9:09\r* @Version 1.0\r*/\rpublic class DynamicDataSource extends AbstractRoutingDataSource {\rprivate static final ThreadLocal\u0026lt;String\u0026gt; CONTEXT_HOLDER = new ThreadLocal\u0026lt;\u0026gt;();\r/**\r* 配置DataSource, defaultTargetDataSource为主数据库\r*/\rpublic DynamicDataSource(DataSource defaultTargetDataSource, Map\u0026lt;Object, Object\u0026gt; targetDataSources) {\rsuper.setDefaultTargetDataSource(defaultTargetDataSource);\rsuper.setTargetDataSources(targetDataSources);\rsuper.afterPropertiesSet();\r}\r@Override\rprotected Object determineCurrentLookupKey() {\rreturn getDataSource();\r}\rpublic static void setDataSource(String dataSource) {\rCONTEXT_HOLDER.set(dataSource);\r}\rpublic static String getDataSource() {\rreturn CONTEXT_HOLDER.get();\r}\rpublic static void remove() {\rCONTEXT_HOLDER.remove();\r}\r}\r 这里使用一个ThreadLocal的变量达到每个线程都有自己的数据源的效果。我们只需要在要需要切换数据源时\nDynamicDataSource.setDataSource(),即可动态的更改数据源。\n但是这样做未免太low了，所以运用切面来升级一波！！！\n 定义注解  package com.jlpay.saas.common.db.datasource;\rimport java.lang.annotation.*;\r/**\r* @Description: 数据源注解\r* @Author shuqingzhou\r* @Date 2021/11/15 9:09\r* @Version 1.0\r*/\r@Target({ElementType.METHOD})\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\rpublic @interface DataSource {\rString value() default DataSourceNames.MASTER;\r}\rpackage com.jlpay.saas.common.db.datasource;\r/**\r* @Description: 主备库名\r* @Author shuqingzhou\r* @Date 2021/11/15 9:09\r* @Version 1.0\r*/\rpublic interface DataSourceNames {\rString MASTER = \u0026quot;master\u0026quot;;\rString SLAVE = \u0026quot;slave\u0026quot;;\r}\r 创建一个AOP切面，拦截带 @DataSource 注解的方法，在方法执行前切换至目标数据源，执行完成后恢复到默认数据源。  package com.jlpay.saas.common.db.datasource;\rimport lombok.extern.slf4j.Slf4j;\rimport org.aspectj.lang.JoinPoint;\rimport org.aspectj.lang.annotation.After;\rimport org.aspectj.lang.annotation.AfterThrowing;\rimport org.aspectj.lang.annotation.Aspect;\rimport org.aspectj.lang.annotation.Before;\rimport org.aspectj.lang.reflect.MethodSignature;\rimport org.springframework.stereotype.Component;\rimport java.lang.reflect.Method;\r/**\r* @Description: 数据源切面处理\r* @Author shuqingzhou\r* @Date 2021/11/15 9:09\r* @Version 1.0\r*/\r@Aspect\r@Component\r@Slf4j\rpublic class DataSourceAspect {\r@Before(\u0026quot;execution(* com.jlpay.saas.*.db.service..*(..))\u0026quot;)\rpublic void before(JoinPoint point) throws Throwable {\rMethodSignature signature = (MethodSignature) point.getSignature();\rMethod method = signature.getMethod();\rDataSource dataSource = method.getAnnotation(DataSource.class);\rif (dataSource == null) {\rlog.debug(\u0026quot;【默认数据源】，切入点：{}\u0026quot;, signature.toShortString());\rDynamicDataSource.setDataSource(DataSourceNames.MASTER);\r} else {\rlog.debug(\u0026quot;【切换数据源】：{}，切入点：{}\u0026quot;, dataSource.value(), signature.toShortString());\rDynamicDataSource.setDataSource(dataSource.value());\r}\r}\r@After(\u0026quot;execution(* com.jlpay.saas.*.db.service..*(..))\u0026quot;)\rpublic void after() throws Throwable{\rDynamicDataSource.remove();\r}\r@AfterThrowing(\u0026quot;execution(* com.jlpay.saas.*.db.service..*(..))\u0026quot;)\rpublic void afterThrowing() {\rlog.info(\u0026quot;数据源异常，切换主库数据源\u0026quot;);\rDynamicDataSource.remove();\rDynamicDataSource.setDataSource(DataSourceNames.MASTER);\r}\r}\r 到现在如何实现动态数据源已经很透彻了。主要流程有：\n 创建数据源 将数据源设置到SQL会话工厂和事务管理器 重写 determineCurrentLookupKey 方法来更改数据源（到此，其实已经完成了动态数据源的功能，调用set方法即可动态的更改数据源） 自定义注解，并创建一个切面来调用set方法动态的更改数据源  ","id":12,"section":"posts","summary":"日常问题总结 工作中总是会遇到各种各样的问题，只有总结下来才是一笔财富。 fastjson的一些技巧 在工作中总是遇到给前端的字段需要是下划线的，","tags":null,"title":"日常问题总结","uri":"https://wzgl998877.github.io/2022/01/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/","year":"2022"},{"content":"消息队列介绍 消息队列主要应用场景为异步、削峰、解耦。\n异步解耦 场景一：用户注册，注册时需要发送短信及邮件，并且需要写库\n 串行模式。流程如下：   ​ 缺点：流程不断加长，影响用户体验。\n  显然就会想到使用异步解决，发邮件的同时可以发短信，流程如下：\n缺点：流程越多，在注册时需要调很多其他接口，代码耦合严重，出现问题不好排查\n  使用消息队列，流程如下：\n  注册接口只需要写库，并且推送到消息队列，至于其他业务订阅消息队列即可，达到了异步并且解耦\n削峰 场景二：秒杀活动，一般由于瞬时访问量过大，服务器接收过大，会导致流量暴增，相关系统无法处理请求甚至崩溃。而加入消息队列后，系统作为消费者，根据自身应用的能力进行消息的消费，不受大流量的影响。流程如下：\n常见消息队列 RocketMQ 架构 RocketMQ架构上主要分为四部分，如上图所示:\n  Producer：生产者，支持分布式集群方式部署。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。RocketMQ 提供了三种方式发送消息：同步、异步和单向\n  同步发送：同步发送指消息发送方发出数据后会在收到接收方发回响应之后才发下一个数据包。一般用于重要通知消息，例如重要通知邮件、营销短信。\n  异步发送：异步发送指发送方发出数据后，不等接收方发回响应，接着发送下个数据包，一般用于可能链路耗时较长而对响应时间敏感的业务场景，例如用户视频上传后通知启动转码服务。\n  单向发送：单向发送是指只负责发送消息而不等待服务器回应且没有回调函数触发，适用于某些耗时非常短但对可靠性要求并不高的场景，例如日志收集。\n     Consumer：消费者，支持分布式集群方式部署。支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制，可以满足大多数用户的需求。\n  Pull：拉取型消费者（Pull Consumer）主动从消息服务器拉取信息，只要批量拉取到消息，用户应用就会启动消费过程，所以 Pull 称为主动消费型。\n  Push：推送型消费者（Push Consumer）封装了消息的拉取、消费进度和其他的内部维护工作，将消息到达时执行的回调接口留给用户应用程序来实现。所以 Push 称为被动消费类型，但从实现上看还是从消息服务器中拉取消息，不同于 Pull 的是 Push 首先要注册消费监听器，当监听器处触发后才开始消费消息。\n  集群消费: 默认就为该模式，相同Consumer Group的每个Consumer实例平均分摊消息。如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。\n  广播消费：消息会发给消费者组中的每一个消费者进行消费。\n    NameServer：NameServer是一个非常简单的Topic路由注册中心，其角色类似Dubbo中的zookeeper，支持Broker的动态注册与发现。主要包括两个功能：Broker管理，NameServer接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查Broker是否还存活；路由信息管理，每个NameServer将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。然后Producer和Conumser通过NameServer就可以知道整个Broker集群的路由信息，从而进行消息的投递和消费。NameServer通常也是集群的方式部署，各实例间相互不进行信息通讯。Broker是向每一台NameServer注册自己的路由信息，所以每一个NameServer实例上面都保存一份完整的路由信息。当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer,Consumer仍然可以动态感知Broker的路由的信息。\n  BrokerServer：Broker主要负责消息的存储、投递和查询以及服务高可用保证，为了实现这些功能，Broker包含了以下几个重要子模块。\n Remoting Module：整个Broker的实体，负责处理来自clients端的请求。 Client Manager：负责管理客户端(Producer/Consumer)和维护Consumer的Topic订阅信息 Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能。 HA Service：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能。 Index Service：根据特定的Message key对投递到Broker的消息进行索引服务，以提供消息的快速查询。    \n名词解释 Message Message（消息）就是要传输的信息。\n一条消息必须有一个主题（Topic），主题可以看做是你的信件要邮寄的地址。\n一条消息也可以拥有一个可选的标签（Tag）和额处的键值对，它们可以用于设置一个业务 Key(messageId) 并在 Broker 上查找此消息以便在开发期间查找问题。\nTopic Topic（主题）可以看做消息的规类，它是消息的第一级类型。比如一个电商系统可以分为：交易消息、物流消息等，一条消息必须有一个 Topic 。\nTopic 与生产者和消费者的关系非常松散，一个 Topic 可以有0个、1个、多个生产者向其发送消息，一个生产者也可以同时向不同的 Topic 发送消息。\n一个 Topic 也可以被 0个、1个、多个消费者订阅。\nTag Tag（标签）可以看作子主题，它是消息的第二级类型，用于为用户提供额外的灵活性。使用标签，同一业务模块不同目的的消息就可以用相同 Topic 而不同的 Tag 来标识。比如交易消息又可以分为：交易创建消息、交易完成消息等，一条消息可以没有 Tag 。\nGroup 分组，一个组可以订阅多个Topic。\n分为ProducerGroup，ConsumerGroup，代表某一类的生产者和消费者，一般来说同一个服务可以作为Group，同一个Group一般来说发送和消费的消息都是一样的\nQueue 在Kafka中叫Partition，每个Queue内部是有序的，在RocketMQ中分为读和写两种队列，一般来说读写队列数量一致，如果不一致就会出现很多问题。\nMessage Queue Message Queue（消息队列），主题被划分为一个或多个子主题，即消息队列。\n一个 Topic 下可以设置多个消息队列，发送消息时执行该消息的 Topic ，RocketMQ 会轮询该 Topic 下的所有队列将消息发出去。\n消息的物理管理单位。一个Topic下可以有多个Queue，Queue的引入使得消息的存储可以分布式集群化，具有了水平扩展能力。\nOffset 在RocketMQ 中，所有消息队列都是持久化，长度无限的数据结构，所谓长度无限是指队列中的每个存储单元都是定长，访问其中的存储单元使用Offset 来访问，Offset 为 java long 类型，64 位，理论上在 100年内不会溢出，所以认为是长度无限。\n也可以认为 Message Queue 是一个长度无限的数组，Offset 就是下标。\nMessage Order Message Order（消息顺序）有两种：Orderly（顺序消费）和Concurrently（并行消费）。\n  消息有序指的是可以按照消息的发送顺序来消费(FIFO)。RocketMQ可以严格的保证消息有序，可以分为分区有序或者全局有序。\n顺序消费的原理解析，在默认的情况下消息发送会采取Round Robin轮询方式把消息发送到不同的queue(分区队列)；而消费消息的时候从多个queue上拉取消息，这种情况发送和消费是不能保证顺序。但是如果控制发送的顺序消息只依次发送到同一个queue中，消费的时候只从这个queue上依次拉取，则就保证了顺序。当发送和消费参与的queue只有一个，则是全局有序；如果多个queue参与，则为分区有序，即相对每个queue，消息都是有序的。\npublic static void main(String[] args) throws Exception {\rDefaultMQProducer producer = new DefaultMQProducer(\u0026quot;order_queue\u0026quot;);\rproducer.setNamesrvAddr(\u0026quot;127.0.0.1:9876\u0026quot;);\rproducer.start();\rString[] tags = new String[]{\u0026quot;TagA\u0026quot;, \u0026quot;TagC\u0026quot;, \u0026quot;TagD\u0026quot;};\r// 订单列表\rList\u0026lt;OrderStep\u0026gt; orderList = new Producer().buildOrders();\rDate date = new Date();\rSimpleDateFormat sdf = new SimpleDateFormat(\u0026quot;yyyy-MM-dd HH:mm:ss\u0026quot;);\rString dateStr = sdf.format(date);\rfor (int i = 0; i \u0026lt; 10; i++) {\r// 加个时间前缀\rString body = dateStr + \u0026quot; Hello RocketMQ \u0026quot; + orderList.get(i);\rMessage msg = new Message(\u0026quot;TopicTest\u0026quot;, tags[i % tags.length], \u0026quot;KEY\u0026quot; + i, body.getBytes());\rSendResult sendResult = producer.send(msg, new MessageQueueSelector() {\r@Override\rpublic MessageQueue select(List\u0026lt;MessageQueue\u0026gt; mqs, Message msg, Object arg) {\rLong id = (Long) arg; //根据订单id选择发送queue\r// 通过取余保证相同id的订单进入同一个队列，消费时会顺序消费，从而保证了订单的创建过程（创建，完成，付款）\rlong index = id % mqs.size(); return mqs.get((int) index);\r}\r}, orderList.get(i).getOrderId());//订单id\rSystem.out.println(String.format(\u0026quot;SendResult status:%s, queueId:%d, body:%s\u0026quot;,\rsendResult.getSendStatus(),\rsendResult.getMessageQueue().getQueueId(),\rbody));\r}\rproducer.shutdown();\r}\r   并行消费不再保证消息顺序，消费的最大并行数量受每个消费者客户端指定的线程池限制。\n  更多名词解释参考官网：https://github.com/apache/rocketmq/blob/master/docs/cn/concept.md\n通信机制 RocketMQ消息队列集群主要包括NameServer、Broker(Master/Slave)、Producer、Consumer4个角色，基本通讯流程如下：\n(1) Broker启动后需要完成一次将自己注册至NameServer的操作；随后每隔30s时间定时向NameServer上报Topic路由信息。\n(2) 消息生产者Producer作为客户端发送消息时候，需要根据消息的Topic从本地缓存的TopicPublishInfoTable获取路由信息。如果没有则更新路由信息会从NameServer上重新拉取，同时Producer会默认每隔30s向NameServer拉取一次路由信息。\n(3) 消息生产者Producer根据2）中获取的路由信息选择一个队列（MessageQueue）进行消息发送；Broker作为消息的接收者接收消息并落盘存储。\n(4) 消息消费者Consumer根据2）中获取的路由信息，并在完成客户端的负载均衡后，选择其中的某一个或者某几个消息队列来拉取消息并进行消费。\nRocketMQ中的负载均衡 RocketMQ中的负载均衡都在Client端完成，具体来说的话，主要可以分为Producer端发送消息时候的负载均衡和Consumer端订阅消息的负载均衡。\n  producer端\nProducer端在发送消息的时候，会先根据Topic找到指定的TopicPublishInfo，在获取了TopicPublishInfo路由信息后，RocketMQ的客户端在默认方式下selectOneMessageQueue()方法会从TopicPublishInfo中的messageQueueList中选择一个队列（MessageQueue）进行发送消息。具体的容错策略均在MQFaultStrategy这个类中定义。这里有一个sendLatencyFaultEnable开关变量，如果开启，在随机递增取模的基础上，再过滤掉not available的Broker代理。所谓的\u0026quot;latencyFaultTolerance\u0026quot;，是指对之前失败的，按一定的时间做退避。例如，如果上次请求的latency超过550Lms，就退避3000Lms；超过1000L，就退避60000L；如果关闭，采用随机递增取模的方式选择一个队列（MessageQueue）来发送消息，latencyFaultTolerance机制是实现消息发送高可用的核心关键所在。\n    Consumer的负载均衡 在RocketMQ中，Consumer端的两种消费模式（Push/Pull）都是基于拉模式来获取消息的，而在Push模式只是对pull模式的一种封装，其本质实现为消息拉取线程在从服务器拉取到一批消息后，然后提交到消息消费线程池后，又“马不停蹄”的继续向服务器再次尝试拉取消息。如果未拉取到消息，则延迟一下又继续拉取。在两种基于拉模式的消费方式（Push/Pull）中，均需要Consumer端在知道从Broker端的哪一个消息队列—队列中去获取消息。因此，有必要在Consumer端来做负载均衡，即Broker端中多个MessageQueue分配给同一个ConsumerGroup中的哪些Consumer消费。\n1、Consumer端的心跳包发送\n在Consumer启动后，它就会通过定时任务不断地向RocketMQ集群中的所有Broker实例发送心跳包（其中包含了，消息消费分组名称、订阅关系集合、消息通信模式和客户端id的值等信息）。Broker端在收到Consumer的心跳消息后，会将它维护在ConsumerManager的本地缓存变量—consumerTable，同时并将封装后的客户端网络通道信息保存在本地缓存变量—channelInfoTable中，为之后做Consumer端的负载均衡提供可以依据的元数据信息。\n2、Consumer端实现负载均衡的核心类—RebalanceImpl\n在Consumer实例的启动流程中的启动MQClientInstance实例部分，会完成负载均衡服务线程—RebalanceService的启动（每隔20s执行一次）。通过查看源码可以发现，RebalanceService线程的run()方法最终调用的是RebalanceImpl类的rebalanceByTopic()方法，该方法是实现Consumer端负载均衡的核心。这里，rebalanceByTopic()方法会根据消费者通信类型为“广播模式”还是“集群模式”做不同的逻辑处理。这里主要来看下集群模式下的主要处理流程：\n(1) 从rebalanceImpl实例的本地缓存变量—topicSubscribeInfoTable中，获取该Topic主题下的消息消费队列集合（mqSet）；\n(2) 根据topic和consumerGroup为参数调用mQClientFactory.findConsumerIdList()方法向Broker端发送获取该消费组下消费者Id列表的RPC通信请求（Broker端基于前面Consumer端上报的心跳包数据而构建的consumerTable做出响应返回，业务请求码：GET_CONSUMER_LIST_BY_GROUP）；\n(3) 先对Topic下的消息消费队列、消费者Id排序，然后用消息队列分配策略算法（默认为：消息队列的平均分配算法），计算出待拉取的消息队列。这里的平均分配算法，类似于分页的算法，将所有MessageQueue排好序类似于记录，将所有消费端Consumer排好序类似页数，并求出每一页需要包含的平均size和每个页面记录的范围range，最后遍历整个range而计算出当前Consumer端应该分配到的记录（这里即为：MessageQueue）。\n\n(4) 然后，调用updateProcessQueueTableInRebalance()方法，具体的做法是，先将分配到的消息队列集合（mqSet）与processQueueTable做一个过滤比对。\n\n 上图中processQueueTable标注的红色部分，表示与分配到的消息队列集合mqSet互不包含。将这些队列设置Dropped属性为true，然后查看这些队列是否可以移除出processQueueTable缓存变量，这里具体执行removeUnnecessaryMessageQueue()方法，即每隔1s 查看是否可以获取当前消费处理队列的锁，拿到的话返回true。如果等待1s后，仍然拿不到当前消费处理队列的锁则返回false。如果返回true，则从processQueueTable缓存变量中移除对应的Entry； 上图中processQueueTable的绿色部分，表示与分配到的消息队列集合mqSet的交集。判断该ProcessQueue是否已经过期了，在Pull模式的不用管，如果是Push模式的，设置Dropped属性为true，并且调用removeUnnecessaryMessageQueue()方法，像上面一样尝试移除Entry；  最后，为过滤后的消息队列集合（mqSet）中的每个MessageQueue创建一个ProcessQueue对象并存入RebalanceImpl的processQueueTable队列中（其中调用RebalanceImpl实例的computePullFromWhere(MessageQueue mq)方法获取该MessageQueue对象的下一个进度消费值offset，随后填充至接下来要创建的pullRequest对象属性中），并创建拉取请求对象—pullRequest添加到拉取列表—pullRequestList中，最后执行dispatchPullRequest()方法，将Pull消息的请求对象PullRequest依次放入PullMessageService服务线程的阻塞队列pullRequestQueue中，待该服务线程取出后向Broker端发起Pull消息的请求。其中，可以重点对比下，RebalancePushImpl和RebalancePullImpl两个实现类的dispatchPullRequest()方法不同，RebalancePullImpl类里面的该方法为空，这样子也就回答了上一篇中最后的那道思考题了。\n消息消费队列在同一消费组不同消费者之间的负载均衡，其核心设计理念是在一个消息消费队列在同一时间只允许被同一消费组内的一个消费者消费，一个消息消费者能同时消费多个消息队列。\n  ","id":13,"section":"posts","summary":"消息队列介绍 消息队列主要应用场景为异步、削峰、解耦。 异步解耦 场景一：用户注册，注册时需要发送短信及邮件，并且需要写库 串行模式。流程如下： ​ 缺","tags":["消息队列"],"title":"消息队列介绍","uri":"https://wzgl998877.github.io/2022/01/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","year":"2022"},{"content":"深入理解Java虚拟机 第2章 Java内存区域与内存溢出异常 程序计数器 ​\t程序计数器（Program Counter Register）是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。\n​\t由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）都只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。\n​\t此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。\nJava虚拟机栈 ​\t与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame)用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。\n​\t局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。\n​\t局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。\n本地方法栈 ​\t本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。\nJava堆 ​\tJava堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。\n方法区 ​\t它用于存储已被虚拟机加载的类信息(又叫对象类型数据，类的全路径名、类的直接超类的全限定名、类(接口)的类型、类的直接接口全限定名的有序列表)、常量、静态变量、即时编译器编译后的代码等数据。\n运行时常量池 ​\t运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。\n​\t运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量一定只有编译期才能产生，也就是并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。\n​\t在JDK 1.6中，intern()方法会把首次遇到的字符串实例复制到永久代中，返回的也是永久代中这个字符串实例的引用，而由StringBuilder创建的字符串实例在Java堆上，所以必然不是同一个引用，将返回false。而JDK 1.7（以及部分其他虚拟机，例如JRockit）的intern()实现不会再复制实例，只是在运行时常量池中记录首次出现的实例引用，因此intern()返回的引用和由StringBuilder创建的那个字符串实例是同一个。\n几个概念：\n 常量池：位于Class文件中，用于存放编译期生成的各种字面量(文本字符串 、八种基本类型的值 、被声明为final的常量等)和符号引用(类和方法的全限定名 、字段的名称和描述符 、方法的名称和描述符)，这部分内容将在类加载后进入方法区的运行时常量池中存放。 运行时常量池：位于方法区中，用于存放各种字面量和符号引用。 字符串常量池：从jdk1.7开始，将属于方法区（永久代）中的字符串常量池放入了堆中。  public static void main(String[] args) {\r// s位于常量池在class文件中，在类加载后就到了运行时常量池，jdk1.6后就属于了字符串常量池，所以是在堆中的\rString s =\u0026quot;1234\u0026quot;;\r// 在jvm中第一次出现，于是s.intern会返回一个指向字符串常量池的引用指向s\rSystem.out.println(s.intern()==s);\r// 字符串常量池已经有了,不会新建对象，直接返回引用\rString s1 = \u0026quot;1234\u0026quot;;\r// s1不是首次出现的，所以s1返回的就是指向堆里字符串常量池的引用也就是第一次出现的s\rSystem.out.println(s1.intern()==s1);\r// 因为在jvm运行时，java这个字符串就已经在字符串常量池了\rString s2 = new StringBuilder(\u0026quot;ja\u0026quot;).append(\u0026quot;va\u0026quot;).toString();\rSystem.out.println(s2.intern()==s2);\r// 在jvm中第一次出现，于是s3.intern只会在运行时常量池里保存第一个的引用指向s3\rString s3 = new StringBuilder(\u0026quot;123456\u0026quot;).append(\u0026quot;789\u0026quot;).toString();\r// 这已经不是第一次出现了，不会保存这个引用，而是继续指向s3\rString s4 = new StringBuilder(\u0026quot;123456\u0026quot;).append(\u0026quot;789\u0026quot;).toString();\rSystem.out.println(s3.intern()==s3);\rSystem.out.println(s4.intern()==s4);\rSystem.out.println(s4.intern()==s3);\r// 创建了两个对象，在直接new指令前先去字符串常量池去检查是否有这个对象如果没有那么先在字符串常量池创建这个对象然后再去堆上创建对象\rString s5 = new String(\u0026quot;hello\u0026quot;);\r// Byte,Short,Integer,Long,Character这5种整型的包装类也实现了常量池技术，很显然在堆上，默认-128 ~ 127 缓存\rInteger a = 127;\rInteger b = 127;\rSystem.out.println(a==b);\rInteger c = new Integer(127);\rSystem.out.println(c==a);\r// 超出了包装类的缓存区，所以在常量池里没有\rInteger d = 128;\rInteger e = 128;\rSystem.out.println(d==e);\r}\r/**\r结果\rture\rtrue\rfasle\rtrue\rfasle\rtrue\rtrue\rfalse\rfalse\r**/\r 直接内存 ​\t直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。\n​\t在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。\n对象的创建 Java是一门面向对象的编程语言，在Java程序运行过程中无时无刻都有对象被创建出来。在语言层面上，创建对象（例如克隆、反序列化）通常仅仅是一个new关键字而已，而在虚拟机中，对象（文中讨论的对象限于普通Java对象，不包括数组和Class对象等）的创建又是怎样一个过程呢？\n  虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。\n  在类加载检查通过后，接下来虚拟机将为新生对象分配内存。\n为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。假设Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”（Bump the Pointer）。如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”（Free List）。\n  内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值。这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。（零值就是默认值比如int为0）。\n  虚拟机要对对象进行必要的设置。例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对象头（Object Header）之中。\n  在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从Java程序的视角来看，对象创建才刚刚开始——方法还没有执行，所有的字段都还为零。所以，一般来说（由字节码中是否跟随invokespecial指令所决定），执行new指令之后会接着执行方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。\n  对象的内存布局 ​\t在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。\n 对象头：第一部分用于存储对象自身的运行时数据。对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，查找对象的元数据信息并不一定要经过对象本身，这点将在2.3.3节讨论。另外，如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中却无法确定数组的大小。 实例数据：是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。 对齐填充：并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说，就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（1倍或者2倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。  对象的访问定位 ​\t建立对象是为了使用对象，我们的Java程序需要通过栈上的reference数据来操作堆上的具体对象。\n第3章 垃圾收集器与内存分配策略 ​\t程序计数器、虚拟机栈、本地方法栈3个区域随线程而生，随线程而灭。因此这几个区域的内存分配和回收都具备确定性，在这几个区域内就不需要过多考虑回收的问题，因为方法结束或者线程结束时，内存自然就跟随着回收了。而Java堆和方法区则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间时才能知道会创建哪些对象，这部分内存的分配和回收都是动态的，垃圾收集器所关注的是这部分内存。\n对象已死吗 ​\t在堆里面存放着Java世界中几乎所有的对象实例，垃圾收集器在对堆进行回收前，第一件事情就是要确定这些对象之中哪些还“存活”着，哪些已经“死去”（即不可能再被任何途径使用的对象）。\n引用计数算法 ​\t很多教科书判断对象是否存活的算法是这样的：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。但是，至少主流的Java虚拟机里面没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间相互循环引用的问题。\n可达性分析算法 ​\t这个算法的基本思路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。在Java语言中，可作为GC Roots的对象包括下面几种：\n 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（即一般说的Native方法）引用的对象。  再谈引用 ​\t在JDK 1.2以前，Java中的引用的定义很传统：如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用。\n​\t在JDK 1.2之后，Java对引用的概念进行了扩充，将引用分为强引用（StrongReference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）4种，这4种引用强度依次逐渐减弱。\n 强引用就是指在程序代码之中普遍存在的，类似“Object obj = newObject()”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用是用来描述一些还有用但并非必需的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。在JDK 1.2之后，提供了SoftReference类来实现软引用。 弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK 1.2之后，提供了WeakReference类来实现弱引用。 虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。在JDK 1.2之后，提供了PhantomReference类来实现虚引用。  生存还是死亡 ​\t即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。\n​\t如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做的原因是，如果一个对象在finalize()方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能会导致F-Queue队列中其他对象永久处于等待，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移除出“即将回收”的集合。如果对象这时候还没有逃脱，那基本上它就真的被回收了。任何一个对象的finalize()方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize()方法不会被再次执行。\n判断对象是否已经死亡：\n 对象在进行可达性分析后发现没有与GC Roots相连接的引用链. 判断此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过都已经没必要执行，此时被回收。 如果被判定有必要执行finalize()方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可。若没有自救则被回收。  回收方法区 ​\t永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类。\n  回收废弃常量：其与回收Java堆中的对象非常类似，假如一个字符串“abc”已经进入了常量池中，但是当前系统没有任何一个String对象是叫做“abc”的，换句话说，就是没有任何String对象引用常量池中的“abc”常量，也没有其他地方引用了这个字面量，如果这时发生内存回收，而且必要的话，这个“abc”常量就会被系统清理出常量池。常量池中的其他类（接口）、方法、字段的符号引用也与此类似。\n  回收无用的类：类需要同时满足下面3个条件才能算是“无用的类”：\n 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。  虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样，不使用了就必然会回收。\n  垃圾收集算法 标记-清除算法 ​\t最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如同它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。\n​\t它的主要不足有两个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。\n复制算法 ​\t它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半，未免太高了一点。\n现在的商业虚拟机都采用这种收集算法来回收新生代\n新生代中的对象98%是“朝生夕死”的，所以并不需要按照1∶1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor[插图]。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8∶1，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的内存会被“浪费”。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。\n标记-整理算法 ​\t复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。\n分代收集算法 ​\t当前商业虚拟机的垃圾收集都采用“分代收集”（GenerationalCollection）算法，一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。\nHotSpot的算法实现 ​\t可达性分析对执行时间的敏感还体现在GC停顿上，因为这项分析工作必须在一个能确保一致性的快照中进行——这里“一致性”的意思是指在整个分析期间整个执行系统看起来就像被冻结在某个时间点上，不可以出现分析过程中对象引用关系还在不断变化的情况，该点不满足的话分析结果准确性就无法得到保证。这点是导致GC进行时必须停顿所有Java执行线程（Sun将这件事情称为“Stop The World”）的其中一个重要原因，即使是在号称（几乎）不会发生停顿的CMS收集器中，枚举根节点时也是必须要停顿的。\n​\t后面这本书中讲了几种虚拟机对这些算法的实现，看不进去。。\n内存分配与回收策略 ​\tJava技术体系中所提倡的自动内存管理最终可以归结为自动化地解决了两个问题：给对象分配内存以及回收分配给对象的内存。\n​\t对象的内存分配，往大方向讲，就是在堆上分配（但也可能经过JIT编译后被拆散为标量类型并间接地栈上分配），对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲，将按线程优先在TLAB上分配。\n大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。\n 新生代GC（Minor GC):指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。 老年代GC（Major GC / Full GC）：指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC。Major GC的速度一般会比Minor GC慢10倍以上。  大对象直接进入老年代，所谓的大对象是指，需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串以及数组\n长期存活的对象将进入老年代\n​\t既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这点，虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。对象在Survivor区中每“熬过”一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就将会被晋升到老年代中。\n​\t为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。\n空间分配担保 ​\t在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么Minor GC可以确保是安全的。如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次Minor GC，尽管这次Minor GC是有风险的；如果小于，或者HandlePromotionFailure设置不允许冒险，那这时也要改为进行一次Full GC。\n​\t新生代使用复制收集算法，但为了内存利用率，只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在Minor GC后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代。与生活中的贷款担保类似，老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，一共有多少对象会活下来在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进行Full GC来让老年代腾出更多空间。\n取平均值进行比较其实仍然是一种动态概率的手段，也就是说，如果某次Minor GC存活后的对象突增，远远高于平均值的话，依然会导致担保失败（Handle Promotion Failure）。如果出现了HandlePromotionFailure失败，那就只好在失败后重新发起一次Full GC。\n第6章 类文件结构 ​\t代码编译的结果从本地机器码转变为字节码，是存储格式发展的一小步，却是编程语言发展的一大步。\n​\t计算机只认识0和1，所以我们写的程序需要经编译器翻译成由0和1构成的二进制格式才能由计算机执行，将我们编写的程序编译成二进制本地机器码（Native Code）已不再是唯一的选择，越来越多的程序语言选择了与操作系统和机器指令集无关的、平台中立的格式作为程序编译后的存储格式。\n无关性的基石 ​\t如果计算机的CPU指令集只有x86一种，操作系统也只有Windows一种，那也许Java语言就不会出现。Java在刚刚诞生之时曾经提出过一个非常著名的宣传口号：“一次编写，到处运行（Write Once，Run Anywhere）”，Sun公司以及其他虚拟机提供商发布了许多可以运行在各种不同平台上的虚拟机，这些虚拟机都可以载入和执行同一种平台无关的字节码，从而实现了程序的“一次编写，到处运行”。\n​\t各种不同平台的虚拟机与所有平台都统一使用的程序存储格式——字节码（ByteCode）是构成平台无关性的基石但本节标题中刻意省略了“平台”二字，那是因为笔者注意到虚拟机的另外一种中立特性——语言无关性正越来越被开发者所重视。\n实现语言无关性的基础仍然是虚拟机和字节码存储格式。Java虚拟机不和包括Java在内的任何语言绑定，它只与“Class文件”这种特定的二进制文件格式所关联。\n后面详细讲了class文件的结构这个就不仔细写了。\n第7章 虚拟机类加载机制 ​\t虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。与那些在编译时需要进行连接工作的语言不同，在Java语言里面，类型的加载、连接和初始化过程都是在程序运行期间完成的。\n​\t类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）7个阶段。其中验证、准备、解析3个部分统称为连接（Linking）。\n对于初始化阶段，虚拟机规范则是严格规定了有且只有5种情况必须立即对类进行“初始化”\n 遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。当一个类在初始化时，要求其父类全部都已经初始化过了，但是一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口的时候（如引用接口中定义的常量）才会初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类 当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。  这5种场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方式都不会触发初始化，称为被动引用。\npackage com.zt.javastudy.grammar;\rimport javafx.scene.control.Pagination;\r/**\r* @author zhengtao\r* @description jvm中对类的加载过程的学习\r* @date 2021/3/18\r*/\rpublic class JVMStudyTwo {\rstatic {\rSystem.out.println(\u0026quot;JVM Study\u0026quot;);\r}\r// 用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类,所以只要运行这个main方法肯定最先初始化这个类\rpublic static void main(String[] args) {\r// 对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化\rSystem.out.println(SubClass.value);\r// 数组定义来引用类，不会触发此类的初始化\rSuperClass[] superClasses = new SuperClass[10];\r// 常量在编译阶段已经存储到了本类的常量池中去了，其实就相当于自身常量池的引用\rSystem.out.println(SubClass.HELLOWORLD);\rSystem.out.println(SuperClass.HELLOWORLD == SubClass.HELLOWORLD);\r}\r}\rclass SubClass extends SuperClass{\rstatic {\rSystem.out.println(\u0026quot;子类初始化\u0026quot;);\r}\rpublic static final String HELLOWORLD = \u0026quot;hello world！\u0026quot;;\r}\rclass SuperClass{\rstatic {\rSystem.out.println(\u0026quot;父类初始化\u0026quot;);\r}\rpublic static int value = 123;\rpublic static final String HELLOWORLD = \u0026quot;hello world\u0026quot;;\r}\r 加载 在加载阶段，虚拟机需要完成以下3件事情：\n 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。  相对于类加载过程的其他阶段，一个非数组类的加载阶段（准确地说，是加载阶段中获取类的二进制字节流的动作）是开发人员可控性最强的，因为加载阶段既可以使用系统提供的引导类加载器来完成，也可以由用户自定义的类加载器去完成，开发人员可以通过定义自己的类加载器去控制字节流的获取方式（即重写一个类加载器的loadClass()方法）。对于数组类而言，情况就有所不同，数组类本身不通过类加载器创建，它是由Java虚拟机直接创建的。\n​\t加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中,然后在内存中实例化一个java.lang.Class类的对象（并没有明确规定是在Java堆中，对于HotSpot虚拟机而言，Class对象比较特殊，它虽然是对象，但是存放在方法区里面），这个对象将作为程序访问方法区中的这些类型数据的外部接口。\n验证 ​\t验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。从执行性能的角度上讲，验证阶段的工作量在虚拟机的类加载子系统中又占了相当大的一部分。\n准备 ​\t准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。首先，这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。其次，这里所说的初始值“通常情况”下是数据类型的零值。\npublic static int value = 123;\r// 在准备阶段分配内存，并初始化为0\r 在“通常情况”下初始值是零值，那相对的会有一些“特殊情况”：如果类字段的字段属性表中存在ConstantValue属性，那在准备阶段变量value就会被初始化为ConstantValue属性所指定的值，也就是final修饰的常量。\npublic static int value = 123;\r// 由于是常量直接被初始化为123\r 解析 ​\t解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。\n 符号引用（Symbolic References）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。 直接引用（Direct References）：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。  初始化 ​\t在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则根据程序员通过程序制定的主观计划去初始化类变量和其他资源，或者可以从另外一个角度来表达：初始化阶段是执行类构造器()方法的过程。\n ()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但是不能访问。 ()方法与类的构造函数（或者说实例构造器()方法）不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的()方法执行之前，父类的()方法已经执行完毕。因此在虚拟机中第一个被执行的()方法的类肯定是java.lang.Object。 由于父类的()方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作 接口中不能使用静态语句块，但仍然有变量初始化的赋值操作，因此接口与类一样都会生成()方法。但接口与类不同的是，执行接口的()方法不需要先执行父接口的()方法。只有当父接口中定义的变量使用时，父接口才会初始化。另外，接口的实现类在初始化时也一样不会执行接口的()方法 虚拟机会保证一个类的()方法在多线程环境中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的()方法，其他线程都需要阻塞等待，直到活动线程执行()方法完毕。  类加载器 ​\t从Java虚拟机的角度来讲，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），这个类加载器使用C++语言实现，是虚拟机自身的一部分；另一种就是所有其他的类加载器，这些类加载器都由Java语言实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。\n  启动类加载器（Bootstrap ClassLoader）：前面已经介绍过，这个类将器负责将存放在\u0026lt;JAVA_HOME\u0026gt;\\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。\n  扩展类加载器（Extension ClassLoader）：这个加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载\u0026lt;JAVA_HOME\u0026gt;\\lib\\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。\n  应用程序类加载器（Application ClassLoader）：这个类加载器由sun.misc.Launcher$App-ClassLoader实现。由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，所以一般也称它为系统类加载器。\n三个加载器的层级为启动类加载器为高层，接下来为扩展类加载器然后应用类加载器，最后是用户自定义的加载器。\n  双亲委派模型 ​\t双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。这里类加载器之间的父子关系一般不会以继承（Inheritance）的关系来实现，而是都使用组合（Composition）关系来复用父加载器的代码。\n​\t双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。\n​\t使用双亲委派模型来组织类加载器之间的关系，有一个显而易见的好处就是Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类java.lang.Object，它存放在rt.jar之中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。双亲委派模型对于保证Java程序的稳定运作很重要。\n","id":14,"section":"posts","summary":"深入理解Java虚拟机 第2章 Java内存区域与内存溢出异常 程序计数器 ​ 程序计数器（Program Counter Register）是一块较小的内存空间，它","tags":["JVM"],"title":"深入理解Java虚拟机","uri":"https://wzgl998877.github.io/2022/01/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AD%A6%E4%B9%A0/","year":"2022"},{"content":"知识点！！！ 分布式session Nginx 正向代理 正向代理代理的对象是客户端，正向代理 是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。配置如下：\n1. server{\r# dns必须要\r2. resolver 8.8.8.8;\r3. resolver_timeout 30s;\r4. listen 82;\r5. location / {\r6. proxy_pass http://$http_host$request_uri;\r7. proxy_set_header Host $http_host;\r8. proxy_buffers 256 4k;\r9. proxy_max_temp_file_size 0;\r10. proxy_connect_timeout 30;\r11. proxy_cache_valid 200 302 10m;\r12. proxy_cache_valid 301 1h;\r13. proxy_cache_valid any 1m;\r14. }\r15. }\r 配置好后，重启nginx，以浏览器为例，要使用这个代理服务器，必须将浏览器代理设置为http://+服务器ip地址+:+82（82是刚刚设置的端口号）即可使用了，这样就相当于我们访问的是代理服务，代理服务器再去访问我们目标网站。\n反向代理 反向代理代理的对象是服务端。反向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。反向代理基本配置：\n1. http {\r2. # 省略了前面一般的配置，直接从负载均衡这里开始\r3. # 设置地址池，后端3台服务器，负载均衡这里是\r4. upstream http_server_pool {\r5. server 192.168.1.2:8080 weight=2 max_fails=2 fail_timeout=30s;\r6. server 192.168.1.3:8080 weight=3 max_fails=2 fail_timeout=30s;\r7. server 192.168.1.4:8080 weight=4 max_fails=2 fail_timeout=30s;\r8. }\r9. # 一个虚拟主机，用来反向代理http_server_pool这组服务器\r10. server {\r11. listen 80;\r12. # 外网访问的域名\r13. server_name www.test.com;\r14. location / {\r15. # 后端服务器返回500 503 404错误，自动请求转发到upstream池中另一台服务器\r16. proxy_next_upstream error timeout invalid_header http_500 http_503 http_404;\r17. proxy_pass http://http_server_pool;\r18. proxy_set_header Host www.test.com;\r19. proxy_set_header X-Real-IP $remote_addr;\r20. proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\r21. }\r22. access_log logs/www.test.com.access.log combined;\r23. }\r24. }\r 反向代理就是在请求时，请求这个服务器的请求转发到真正处理的服务器，其中可以加上一些负载均衡之类的，比如现在请求，http://www.test.com, 就会将这个请求重定向到http://http_server_pool ，然后这个是自己定义的，第4行代码，然后就根据权重轮询发送到对应的服务器。\n基本配置 博客 https://www.cnblogs.com/54chensongxia/p/12938929.html\n具体的location指令 博客 https://www.jianshu.com/p/b010c9302cd0\n生产遇到的问题，调支付宝下单接口总是返回\norg.apache.http.NoHttpResponseException: open-sea.alipay.com:8449 failed to respond\rat org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:143)\rat org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:57)\rat org.apache.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:261)\rat org.apache.http.impl.DefaultBHttpClientConnection.receiveResponseHeader(DefaultBHttpClientConnection.java:165)\rat org.apache.http.impl.conn.CPoolProxy.receiveResponseHeader(CPoolProxy.java:167)\rat org.apache.http.protocol.HttpRequestExecutor.doReceiveResponse(HttpRequestExecutor.java:272)\rat org.apache.http.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:124)\rat org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:271)\rat org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:184)\rat org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:88)\rat org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)\rat org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:184)\rat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:82)\rat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:107)\rat com.jlpay.commons.tools.http.HttpServiceImpl.execute(HttpServiceImpl.java:178)\rat com.taifung.qrcode.chn.alipay.service.trans.OfflinepayService.doOfflinepayCn(OfflinepayService.java:282)\rat com.taifung.qrcode.chn.alipay.service.trans.OfflinepayService.executeCommand(OfflinepayService.java:52)\rat com.taifung.qrcode.chn.alipay.service.trans.OfflinepayService.executeCommand(OfflinepayService.java:33)\rat com.taifung.qrcode.chn.alipay.service.trans.AlipayService.execute(AlipayService.java:28)\rat com.jlpay.commons.rpc.thrift.server.Dispatcher.invoke(Dispatcher.java:47)\rat com.jlpay.commons.rpc.thrift.server.RpcAdapterImpl.Invoke(RpcAdapterImpl.java:32)\rat com.jlpay.commons.rpc.thrift.server.RpcAdapter$Processor$Invoke.getResult(RpcAdapter.java:175)\rat com.jlpay.commons.rpc.thrift.server.RpcAdapter$Processor$Invoke.getResult(RpcAdapter.java:160)\rat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)\rat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\rat org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518)\rat org.apache.thrift.server.Invocation.run(Invocation.java:18)\rat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\rat java.util.concurrent.FutureTask.run(FutureTask.java:266)\rat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\rat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\rat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\rat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\rat java.lang.Thread.run(Thread.java:748)\r 观察日志，发现报这个错都是3秒后，报错，然后看ng配置\nserver {\rlisten 8449;\rproxy_connect_timeout 1s; // 默认值60s, nginx连接到后端服务器的连接超时时间\rproxy_timeout 3s; // 默认值为10分钟，nginx接收后端服务器的响应超时时间\rproxy_pass alipay;\r}\rupstream alipay {\rhash $remote_addr consistent;\rserver open.alipaymo.com:443 weight=5 max_fails=3 fail_timeout=30s; //max_fails默认值为1,fail_timeout默认值为10s,max_fails=0表示不做检查\r// max_fails和fail_timeout参数是配合使用的，按默认值，当某台upstream server挂了，表示在10s(fail_timeout)之内，有1(max_fails)个请求打到这台挂了的服务器，nginx就会把这台upstream server设为down机的状态，时长是10s，在这10s内如果又有请求进来，就不会被转到这台server上，过了10s重新认为这台server又恢复了配置的意义\r}\r 所以说，问题就是，调支付宝下单接口三秒后还没返回，所以ng就把连接断开了，解决办法将超时时间调成了5s，这个错误的次数也出现的少了。\nshell #!/bin/bash\r# 不可自行修改脚本，统一管理\r# 开启脚本调试\r#set -x\r#设置生效那个环境配置文件\r#---- start.sh stdout 为开启stdout.log\r# 目前有 dev kx.verify kx.prod 这几个环境，对应application-*.yml 的配置文件\r# 定义变量，\rPROFILES_ACTIVE=dev\r# 定义日志输出位置，如果没定义的话，在./logs目录 必须/结尾\rLOGPATH=./logs/\r#设置 Sentinel 控制台地址 -Dcsp.sentinel.dashboard.server=172.20.21.40:58080\r#SENTINEL_OPTS='-Dcsp.sentinel.dashboard.server=localhost:58080 -Dproject.name=openAccess -Dcsp.sentinel.log.use.pid=true'\rJAVA_OPTS=\u0026quot; -Djava.awt.headless=true -Djava.net.preferIPv4Stack=true \u0026quot;\r# echo 用于字符串的输出，-e开启转义\r# 函数定义方法，函数定义必须放在调用前 \\033[032;1m$@\\033[0m加颜色用的\rgreen_echo () { echo -e \u0026quot;\\033[032;1m$@\\033[0m\u0026quot;; }\r# 定位到运行脚本的相对位置\rcd `dirname $0`\rBIN_DIR=`pwd`\rcd ..\rDEPLOY_DIR=`pwd`\rCONF_DIR=$DEPLOY_DIR/config\rLOGS_FILE=$DEPLOY_DIR/logs\r# -z 检测字符串长度是否为0，为0返回 true。\r# -n 检测字符串长度是否不为 0，不为 0 返回 true。\r# $ 检测字符串是否为空，不为空返回 true。\rif [ -z \u0026quot;$SERVER_NAME\u0026quot; ]; then\r# 主机名\rSERVER_NAME=`hostname`\rfi\rPIDS=`ps -f | grep java | grep \u0026quot;.jar\u0026quot; | grep \u0026quot;$CONF_DIR\u0026quot; |awk '{print $2}'`\rif [ -n \u0026quot;$PIDS\u0026quot; ]; then\recho \u0026quot;ERROR: The $SERVER_NAME already started!\u0026quot;\recho \u0026quot;PID: $PIDS\u0026quot;\r# exit 退出命令，0为成功，其他为失败情况\rexit 1\rfi\rif [ -n \u0026quot;$SERVER_PORT\u0026quot; ]; then\rSERVER_PORT_COUNT=`netstat -tln | grep $SERVER_PORT | wc -l`\rif [ $SERVER_PORT_COUNT -gt 0 ]; then\recho \u0026quot;ERROR: The $SERVER_NAME port $SERVER_PORT already used!\u0026quot;\rexit 1\rfi\rfi\r#LOGS_DIR=\u0026quot;\u0026quot;\r#if [ -n \u0026quot;$LOGS_FILE\u0026quot; ]; then\r# LOGS_DIR=`dirname $LOGS_FILE`\r#else\r# LOGS_DIR=$DEPLOY_DIR/logs\r#fi\rLOGS_DIR=$DEPLOY_DIR/logs\r# -d 检测文件是否是目录，如果是,则返回true。\rif [ ! -d $LOGS_DIR ]; then\rmkdir $LOGS_DIR\rfi\rSTDOUT_FILE=$LOGS_DIR/stdout.log\rLIB_DIR=$DEPLOY_DIR\rMAIN_JAR=`ls $LIB_DIR|grep .jar |awk '{print \u0026quot;'$LIB_DIR'/\u0026quot;$0}' `\recho $MAIN_JAR\r#LIB_JARS=`ls $LIB_DIR|grep .jar|awk '{print \u0026quot;'$LIB_DIR'/\u0026quot;$0}'|tr \u0026quot;\\n\u0026quot; \u0026quot;:\u0026quot;`\rJAVA_DEBUG_OPTS=\u0026quot;\u0026quot;\rif [ \u0026quot;$1\u0026quot; = \u0026quot;debug\u0026quot; ]; then\rJAVA_DEBUG_OPTS=\u0026quot; -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n \u0026quot;\rfi\rJAVA_JMX_OPTS=\u0026quot;\u0026quot;\rif [ \u0026quot;$1\u0026quot; = \u0026quot;jmx\u0026quot; ]; then\rJAVA_JMX_OPTS=\u0026quot; -Dcom.sun.management.jmxremote.port=1099 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false \u0026quot;\rfi\rJAVA_MEM_OPTS=\u0026quot;\u0026quot;\rBITS=`java -version 2\u0026gt;\u0026amp;1 | grep -i 64-bit`\rif [ -n \u0026quot;$BITS\u0026quot; ]; then\rJAVA_MEM_OPTS=\u0026quot; -server -Xmx1g -Xms1g -Xmn256m -XX:PermSize=128m -Xss256k -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 \u0026quot;\relse\rJAVA_MEM_OPTS=\u0026quot; -server -Xms1g -Xmx1g -XX:PermSize=128m -XX:SurvivorRatio=2 -XX:+UseParallelGC \u0026quot;\rfi\recho -e \u0026quot;Starting the $SERVER_NAME ...\\c\u0026quot;\r# if语法，if condition1 then command1 else command(不能为空) fi\rif [ \u0026quot;$1\u0026quot; == \u0026quot;stdout\u0026quot; ]; then\r# 0 表示stdin标准输入；1 表示stdout标准输出；2 表示stderr标准错误。\r# nohup java .....(java 运行期间的配置) -jar $MAIN_JAR \u0026gt; $STDOUT_FILE 2\u0026gt;\u0026amp;1 \u0026amp; 意思就是运行jar文件，并把1标准输出，2 标准错误全部输出到$STDOUT_FILE中去 ，/dev/null这个就为空，代表不输出东西，$MAIN_JAR \u0026gt; $STDOUT_FILE \u0026gt; 表示清空然后重新输入，\u0026gt;\u0026gt;表示追加，所以重新运行，日志会被清空\rnohup java $JAVA_OPTS $JAVA_MEM_OPTS $JAVA_DEBUG_OPTS $JAVA_JMX_OPTS $SENTINEL_OPTS -Xbootclasspath/a:$CONF_DIR -DlogPath=$LOGPATH -Dspring.profiles.active=$PROFILES_ACTIVE -jar $MAIN_JAR \u0026gt; $STDOUT_FILE 2\u0026gt;\u0026amp;1 \u0026amp;\relse\rnohup java $JAVA_OPTS $JAVA_MEM_OPTS $JAVA_DEBUG_OPTS $JAVA_JMX_OPTS $SENTINEL_OPTS -Xbootclasspath/a:$CONF_DIR -DlogPath=$LOGPATH -Dspring.profiles.active=$PROFILES_ACTIVE -jar $MAIN_JAR \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\rfi\rCOUNT=0\r# -eq =，-ne !=,-gt \u0026gt;,-lt \u0026lt;,-ge \u0026gt;=,-le \u0026lt;=\rwhile [ $COUNT -lt 1 ]; do\recho -e \u0026quot;.\\c\u0026quot;\rsleep 1\rif [ -n \u0026quot;$SERVER_PORT\u0026quot; ]; then\rif [ \u0026quot;$SERVER_PROTOCOL\u0026quot; == \u0026quot;thrift\u0026quot; ]; then\r#COUNT=`echo status | nc -i 1 127.0.0.1 $SERVER_PORT | grep -c OK`\rCOUNT=`netstat -an | grep $SERVER_PORT | wc -l`\relse\rCOUNT=`netstat -an | grep $SERVER_PORT | wc -l`\rfi\relse\rCOUNT=`ps -f | grep java | grep \u0026quot;.jar\u0026quot; | grep \u0026quot;$DEPLOY_DIR\u0026quot; | awk '{print $2}' | wc -l`\rfi\rif [ $COUNT -gt 0 ]; then\rbreak\rfi\rdone\recho \u0026quot;OK!\u0026quot;\rPIDS=`ps -f | grep java | grep \u0026quot;.jar\u0026quot; | grep \u0026quot;$DEPLOY_DIR\u0026quot; | awk '{print $2}'`\rsleep 2\rgreen_echo \u0026quot;------ Prog info PLS check \u0026amp; dev(开发环境) kx.prod (科兴验证环境) kx.prod (科兴生产环境) ks.prod (金山生产环境) -----\u0026quot;\recho \u0026quot;PID: $PIDS\u0026quot;\recho \u0026quot;PROG_ENV: $PROFILES_ACTIVE\u0026quot;\recho \u0026quot;LOGS\u0026quot;: `ls -l /proc/$PIDS/fd | grep .log | awk '{print $NF}' | sort |uniq`\r 日志 目前java中日志框架主要有JDKLog、Log4J、LogBack、SLF4J 其中slf4j相当于是一个接口，log4j和logback相当于是具体实现。\n目前最流行slf4j+logback\n引入依赖，目前springboot默认就是这个组合的日志框架所以不需要额外引入依赖\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt;\r\u0026lt;project xmlns=\u0026quot;http://maven.apache.org/POM/4.0.0\u0026quot; xmlns:xsi=\u0026quot;http://www.w3.org/2001/XMLSchema-instance\u0026quot;\rxsi:schemaLocation=\u0026quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026quot;\u0026gt;\r\u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt;\r\u0026lt;parent\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.4.0\u0026lt;/version\u0026gt;\r\u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt;\r\u0026lt;/parent\u0026gt;\r\u0026lt;groupId\u0026gt;com.zt\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;java-study\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;name\u0026gt;java-study\u0026lt;/name\u0026gt;\r\u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt;\r\u0026lt;properties\u0026gt;\r\u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt;\r\u0026lt;/properties\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.2.71\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt;\r\u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;build\u0026gt;\r\u0026lt;plugins\u0026gt;\r\u0026lt;plugin\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt;\r\u0026lt;/plugin\u0026gt;\r\u0026lt;/plugins\u0026gt;\r\u0026lt;/build\u0026gt;\r\u0026lt;/project\u0026gt;\r 加入配置文件,配置文件详解见\nhttps://www.cnblogs.com/chanshuyi/p/something_about_java_log_framework.html\nhttps://cloud.tencent.com/developer/article/1698344\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt;\r\u0026lt;configuration scan=\u0026quot;true\u0026quot; scanPeriod=\u0026quot;10 seconds\u0026quot;\u0026gt;\r\u0026lt;!--springProperty和property都可以用来表示全局变量但springProperty代表去配置文件去读配置\t--\u0026gt;\r\u0026lt;springProperty scope=\u0026quot;context\u0026quot; name=\u0026quot;springAppName\u0026quot; source=\u0026quot;spring.application.name\u0026quot; defaultValue=\u0026quot;manage-tax\u0026quot;/\u0026gt;\r\u0026lt;!--那么问题来了，这个logPath配置文件里就没有是怎么读取的呢，没读到就默认是最高目录--\u0026gt;\r\u0026lt;springProperty scope=\u0026quot;context\u0026quot; name=\u0026quot;logPath\u0026quot; source=\u0026quot;logPath\u0026quot;/\u0026gt;\r\u0026lt;property name=\u0026quot;logPath\u0026quot; value=\u0026quot;../logs/\u0026quot;/\u0026gt;\r\u0026lt;property name=\u0026quot;CONSOLE_LOG_PATTERN\u0026quot; value=\u0026quot;[%date][%thread][manage-tax][%logger:%line][%M][%-5level][%X{logid}][%X{X-B3-TraceId:-}] =\u0026gt;%msg%n\u0026quot;/\u0026gt;\r\u0026lt;!--生产环境去掉控制台输出--\u0026gt;\r\u0026lt;appender name=\u0026quot;stdout\u0026quot; class=\u0026quot;ch.qos.logback.core.ConsoleAppender\u0026quot;\u0026gt;\r\u0026lt;withJansi\u0026gt;true\u0026lt;/withJansi\u0026gt;\r\u0026lt;encoder\u0026gt;\r\u0026lt;pattern\u0026gt;${CONSOLE_LOG_PATTERN}\u0026lt;/pattern\u0026gt;\r\u0026lt;charset\u0026gt;utf8\u0026lt;/charset\u0026gt;\r\u0026lt;/encoder\u0026gt;\r\u0026lt;/appender\u0026gt;\r\u0026lt;appender name=\u0026quot;dailyRollingFileAppender\u0026quot; class=\u0026quot;ch.qos.logback.core.rolling.RollingFileAppender\u0026quot;\u0026gt;\r\u0026lt;File\u0026gt;${logPath}${springAppName}.log\u0026lt;/File\u0026gt;\r\u0026lt;rollingPolicy class=\u0026quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026quot;\u0026gt;\r\u0026lt;FileNamePattern\u0026gt;${springAppName}.%d{yyyy-MM-dd}-%i.log\u0026lt;/FileNamePattern\u0026gt;\r\u0026lt;maxHistory\u0026gt;30\u0026lt;/maxHistory\u0026gt;\r\u0026lt;timeBasedFileNamingAndTriggeringPolicy class=\u0026quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\u0026quot;\u0026gt;\r\u0026lt;maxFileSize\u0026gt;100MB\u0026lt;/maxFileSize\u0026gt;\r\u0026lt;/timeBasedFileNamingAndTriggeringPolicy\u0026gt;\r\u0026lt;/rollingPolicy\u0026gt;\r\u0026lt;encoder\u0026gt;\r\u0026lt;Pattern\u0026gt;${CONSOLE_LOG_PATTERN}\u0026lt;/Pattern\u0026gt;\r\u0026lt;/encoder\u0026gt;\r\u0026lt;filter class=\u0026quot;ch.qos.logback.classic.filter.ThresholdFilter\u0026quot;\u0026gt;\r\u0026lt;level\u0026gt;DEBUG\u0026lt;/level\u0026gt;\r\u0026lt;/filter\u0026gt;\r\u0026lt;/appender\u0026gt;\r\u0026lt;!--\t异步打日志AsyncAppender --\u0026gt;\r\u0026lt;appender name =\u0026quot;ASYNC_FILE\u0026quot; class= \u0026quot;ch.qos.logback.classic.AsyncAppender\u0026quot;\u0026gt;\r\u0026lt;discardingThreshold\u0026gt;0\u0026lt;/discardingThreshold\u0026gt;\r\u0026lt;queueSize\u0026gt;1024\u0026lt;/queueSize\u0026gt;\r\u0026lt;includeCallerData\u0026gt;true\u0026lt;/includeCallerData\u0026gt;\r\u0026lt;appender-ref ref = \u0026quot;dailyRollingFileAppender\u0026quot;/\u0026gt;\r\u0026lt;/appender\u0026gt;\r\u0026lt;appender name =\u0026quot;ASYNC_STDOUT\u0026quot; class= \u0026quot;ch.qos.logback.classic.AsyncAppender\u0026quot;\u0026gt;\r\u0026lt;discardingThreshold\u0026gt;0\u0026lt;/discardingThreshold\u0026gt;\r\u0026lt;queueSize\u0026gt;1024\u0026lt;/queueSize\u0026gt;\r\u0026lt;includeCallerData\u0026gt;true\u0026lt;/includeCallerData\u0026gt;\r\u0026lt;appender-ref ref = \u0026quot;stdout\u0026quot;/\u0026gt;\r\u0026lt;/appender\u0026gt;\r\u0026lt;!-- 多环境日志配置\t--\u0026gt;\r\u0026lt;springProfile name=\u0026quot;dev\u0026quot;\u0026gt;\r\u0026lt;logger name=\u0026quot;com.jlpay\u0026quot; level=\u0026quot;DEBUG\u0026quot;/\u0026gt;\r\u0026lt;root level=\u0026quot;info\u0026quot;\u0026gt;\r\u0026lt;appender-ref ref=\u0026quot;ASYNC_FILE\u0026quot;/\u0026gt;\r\u0026lt;appender-ref ref=\u0026quot;ASYNC_STDOUT\u0026quot;/\u0026gt;\r\u0026lt;/root\u0026gt;\r\u0026lt;/springProfile\u0026gt;\r\u0026lt;root level=\u0026quot;info\u0026quot;\u0026gt;\r\u0026lt;appender-ref ref=\u0026quot;stdout\u0026quot;/\u0026gt;\r\u0026lt;appender-ref ref=\u0026quot;ASYNC_FILE\u0026quot;/\u0026gt;\r\u0026lt;/root\u0026gt;\r\u0026lt;/configuration\u0026gt;\r 使用\npackage com.zt.javastudy;\rimport lombok.extern.slf4j.Slf4j;\rimport org.slf4j.Logger;\rimport org.slf4j.LoggerFactory;\rimport org.springframework.boot.SpringApplication;\rimport org.springframework.boot.autoconfigure.SpringBootApplication;\rimport org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;\r/**\r* @author zhengtao\r*/\r@SpringBootApplication(exclude= {DataSourceAutoConfiguration.class})\r// 引入lombok注解，加上这个注释就可以使用log打印日志了\r@Slf4j\rpublic class JavaStudyApplication {\rpublic static final Logger logger = LoggerFactory.getLogger(JavaStudyApplication.class);\rpublic static void main(String[] args) {\rlogger.info(\u0026quot;java-study starting.....\u0026quot;);\rlog.error(\u0026quot;slf4j starting...\u0026quot;);\rSpringApplication.run(JavaStudyApplication.class, args);\rlogger.info(\u0026quot;java-study ok.....\u0026quot;);\rlog.error(\u0026quot;slf4j ok.........\u0026quot;);\r}\r}\r 如果是使用log4j只需要引入相应的配置，然后配置对应的配置文件，使用方法是一样的，例如\nlog4j.rootLogger=INFO,Console,CommonFile\rlog4j.appender.Console=org.apache.log4j.ConsoleAppender log4j.appender.Console.Target=System.out\rlog4j.appender.Console.Threshold=DEBUG\rlog4j.appender.Console.layout = org.apache.log4j.PatternLayout log4j.appender.Console.layout.ConversionPattern=[%d{yyyy-MM-dd HH\\:mm\\:ss SSSSSS}][%t][(QRCODE_MERCHANT_SERVER)(%C:%L)(%M)][%p][%X{logid}][%X{orderid}]%m%n\r#WARN INFO\rlog4j.appender.CommonFile=org.apache.log4j.RollingFileAppender\rlog4j.appender.CommonFile.MaxFileSize = 100MB\rlog4j.appender.CommonFile.File=../logs/qrcode_merchant.log\rlog4j.appender.CommonFile.MaxBackupIndex=100 log4j.appender.CommonFile.Threshold=INFO,ERROR,WARN\rlog4j.appender.CommonFile.layout=org.apache.log4j.PatternLayout log4j.appender.CommonFile.layout.ConversionPattern=[%d{yyyy-MM-dd HH\\:mm\\:ss SSSSSS}][%t][(QRCODE_MERCHANT_SERVER)(%C:%L)(%M)][%p][%X{logid}][%X{orderid}]%m%n\rlog4j.appender.CommonFile.Encoding=UTF-8\rlog4j.appender.CommonFile.BufferedIO=false\r 单元测试 一致性哈希 多线程和异步任务 @Transaction和@TransactionalEventListener file类 maven 公司项目配置文件读取过程\n 通过指定配置文件目录，来使得本地配置读取的为development  \u0026lt;resources\u0026gt;\r\u0026lt;resource\u0026gt;\r\u0026lt;directory\u0026gt;src/main/resources\u0026lt;/directory\u0026gt;\r\u0026lt;!-- 资源根目录排除各环境的配置，使用单独的资源目录来指定 --\u0026gt;\r\u0026lt;excludes\u0026gt;\r\u0026lt;exclude\u0026gt;test/*\u0026lt;/exclude\u0026gt;\r\u0026lt;exclude\u0026gt;mir/*\u0026lt;/exclude\u0026gt;\r\u0026lt;exclude\u0026gt;verify/*\u0026lt;/exclude\u0026gt;\r\u0026lt;exclude\u0026gt;production/*\u0026lt;/exclude\u0026gt;\r\u0026lt;exclude\u0026gt;development/*\u0026lt;/exclude\u0026gt;\r\u0026lt;/excludes\u0026gt;\r\u0026lt;/resource\u0026gt;\r\u0026lt;resource\u0026gt;\r\u0026lt;directory\u0026gt;src/main/resources/${profiles.active}\u0026lt;/directory\u0026gt;\r\u0026lt;/resource\u0026gt;\r\u0026lt;/resources\u0026gt;\r\u0026lt;profile\u0026gt;\r\u0026lt;!-- 本地开发环境 配置为真--\u0026gt;\r\u0026lt;id\u0026gt;development\u0026lt;/id\u0026gt;\r\u0026lt;properties\u0026gt;\r\u0026lt;profiles.active\u0026gt;development\u0026lt;/profiles.active\u0026gt;\r\u0026lt;/properties\u0026gt;\r\u0026lt;activation\u0026gt;\r\u0026lt;activeByDefault\u0026gt;true\u0026lt;/activeByDefault\u0026gt;\r\u0026lt;/activation\u0026gt;\r\u0026lt;/profile\u0026gt;\r  将配置文件达到jar中\n\u0026lt;outputDirectory\u0026gt;\rtarget/classes\r\u0026lt;/outputDirectory\u0026gt;\r   有了前面两步配合classpath* 就可以读到配置文件中的内容了，而我们线上之所以配置文件不是本地开发的配置文件是因为线上加了这个代码，\n  \u0026lt;resources\u0026gt;\r\u0026lt;resource\u0026gt;\r\u0026lt;directory\u0026gt;src/main/resources\u0026lt;/directory\u0026gt;\r\u0026lt;!-- resources下的所有文件都不打到jar中 --\u0026gt;\r\u0026lt;excludes\u0026gt;\r\u0026lt;exclude\u0026gt;**/*.*\u0026lt;/exclude\u0026gt;\r\u0026lt;/excludes\u0026gt;\r\u0026lt;/resource\u0026gt;\r\u0026lt;/resources\u0026gt;\r 从而线上的就会去寻找配置文件。\n把maven配置认真看下。\n幂等 分布式事务 ","id":15,"section":"posts","summary":"知识点！！！ 分布式session Nginx 正向代理 正向代理代理的对象是客户端，正向代理 是一个位于客户端和原始服务器(origin server)之间的","tags":null,"title":"知识点","uri":"https://wzgl998877.github.io/2022/01/%E7%9F%A5%E8%AF%86%E7%82%B9/","year":"2022"},{"content":"设计模式 七大软件设计原则 1 . 开闭原则 ​\t软件实体应当对扩展开放，对修改关闭。当应用的需求改变时，在不修改软件实体的源代码或者二进制代码的前提下，可以扩展模块的功能，使其满足新的需求，实现方法：可以通过“抽象约束、封装变化”来实现开闭原则，即通过接口或者抽象类为软件实体定义一个相对稳定的抽象层，而将相同的可变因素封装在相同的具体实现类中。\n2. 里氏替换原则 ​\t继承必须确保超类所拥有的性质在子类中仍然成立。里氏替换原则是实现开闭原则的重要方式之一，子类可以扩展父类的功能，但不能改变父类原有的功能。也就是说：子类继承父类时，除添加新的方法完成新增功能外，尽量不要重写父类的方法。\n 当子类的方法重载父类的方法时，方法的前置条件（即方法的输入参数）要比父类的方法更宽松 当子类的方法实现父类的方法时（重写/重载或实现抽象方法），方法的后置条件（即方法的的输出/返回值）要比父类的方法更严格或相等  3. 依赖倒置原则 ​\t高层模块不应该依赖低层模块，两者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象。其核心思想是：要面向接口编程，不要面向实现编程，依赖倒置原则是实现开闭原则的重要途径之一，它降低了客户与实现模块之间的耦合。\n4. 单一职责原则 ​\t一个类应该有且仅有一个引起它变化的原因，否则类应该被拆分。单一职责原则的核心就是控制类的粒度大小、将对象解耦、提高其内聚性。如果遵循单一职责原则将有以下优点。\n 降低类的复杂度。一个类只负责一项职责，其逻辑肯定要比负责多项职责简单得多。 提高类的可读性。复杂性降低，自然其可读性会提高。 提高系统的可维护性。可读性提高，那自然更容易维护了。 变更引起的风险降低。变更是必然的，如果单一职责原则遵守得好，当修改一个功能时，可以显著降低对其他功能的影响。  5. 接口隔离原则 ​\t客户端不应该被迫依赖于它不使用的方法，一个类对另一个类的依赖应该建立在最小的接口上。要为各个类建立它们需要的专用接口，而不要试图去建立一个很庞大的接口供所有依赖它的类去调用。\n​\t接口隔离原则和单一职责都是为了提高类的内聚性、降低它们之间的耦合性，体现了封装的思想，但两者是不同的：\n 单一职责原则注重的是职责，而接口隔离原则注重的是对接口依赖的隔离。 单一职责原则主要是约束类，它针对的是程序中的实现和细节；接口隔离原则主要约束接口，主要针对抽象和程序整体框架的构建。  在具体应用接口隔离原则时，应该根据以下几个规则来衡量。\n 接口尽量小，但是要有限度。一个接口只服务于一个子模块或业务逻辑。 为依赖接口的类定制服务。只提供调用者需要的方法，屏蔽不需要的方法。 了解环境，拒绝盲从。每个项目或产品都有选定的环境因素，环境不同，接口拆分的标准就不同深入了解业务逻辑。 提高内聚，减少对外交互。使接口用最少的方法去完成最多的事情。  6. 迪米特法则 ​\t迪米特法则（Law of Demeter，LoD）又叫作最少知识原则，迪米特法则的定义是：只与你的直接朋友交谈，不跟“陌生人”说话。其含义是：如果两个软件实体无须直接通信，那么就不应当发生直接的相互调用，可以通过第三方转发该调用。其目的是降低类之间的耦合度，提高模块的相对独立性。\n从迪米特法则的定义和特点可知，它强调以下两点：\n 从依赖者的角度来说，只依赖应该依赖的对象。 从被依赖者的角度说，只暴露应该暴露的方法。  7. 合成复用原则 ​\t合成复用原则又叫组合/聚合复用原则。它要求在软件复用时，要尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现。\n七大软件设计原则总结 ​\t这 7 种设计原则是软件设计模式必须尽量遵循的原则，各种原则要求的侧重点不同。其中，开闭原则是总纲，它告诉我们要对扩展开放，对修改关闭；里氏替换原则告诉我们不要破坏继承体系；依赖倒置原则告诉我们要面向接口编程；单一职责原则告诉我们实现类要职责单一；接口隔离原则告诉我们在设计接口的时候要精简单一；迪米特法则告诉我们要降低耦合度；合成复用原则告诉我们要优先使用组合或者聚合关系复用，少用继承关系复用。\n设计模式的分类和功能 1. 根据目的来分 根据模式是用来完成什么工作来划分，这种方式可分为创建型模式、结构型模式和行为型模式 3 种。\n 创建型模式：用于描述“怎样创建对象”，它的主要特点是“将对象的创建与使用分离”。GoF 中提供了单例、原型、工厂方法、抽象工厂、建造者等 5 种创建型模式。 结构型模式：用于描述如何将类或对象按某种布局组成更大的结构，GoF 中提供了代理、适配器、桥接、装饰、外观、享元、组合等 7 种结构型模式。 行为型模式：用于描述类或对象之间怎样相互协作共同完成单个对象都无法单独完成的任务，以及怎样分配职责。GoF 中提供了模板方法、策略、命令、职责链、状态、观察者、中介者、迭代器、访问者、备忘录、解释器等 11 种行为型模式。  2. 根据作用范围来分 根据模式是主要用于类上还是主要用于对象上来分，这种方式可分为类模式和对象模式两种。\n 类模式：用于处理类与子类之间的关系，这些关系通过继承来建立，是静态的，在编译时刻便确定下来了。GoF中的工厂方法、（类）适配器、模板方法、解释器属于该模式。 对象模式：用于处理对象之间的关系，这些关系可以通过组合或聚合来实现，在运行时刻是可以变化的，更具动态性。GoF 中除了以上 4 种，其他的都是对象模式。  表 1 介绍了这 23 种设计模式的分类。\n   范围\\目的 创建型模式 结构型模式 行为型模式     类模式 工厂方法 (类）适配器 模板方法、解释器   对象模式 单例 原型 抽象工厂 建造者 代理 (对象）适配器 桥接 装饰 外观 享元 组合 策略 命令 职责链 状态 观察者 中介者 迭代器 访问者 备忘录    3. GoF的23种设计模式的功能 前面说明了 GoF 的 23 种设计模式的分类，现在对各个模式的功能进行介绍。\n 单例（Singleton）模式：某个类只能生成一个实例，该类提供了一个全局访问点供外部获取该实例，其拓展是有限多例模式。 原型（Prototype）模式：将一个对象作为原型，通过对其进行复制而克隆出多个和原型类似的新实例。 工厂方法（Factory Method）模式：定义一个用于创建产品的接口，由子类决定生产什么产品。 抽象工厂（AbstractFactory）模式：提供一个创建产品族的接口，其每个子类可以生产一系列相关的产品。 建造者（Builder）模式：将一个复杂对象分解成多个相对简单的部分，然后根据不同需要分别创建它们，最后构建成该复杂对象。 代理（Proxy）模式：为某对象提供一种代理以控制对该对象的访问。即客户端通过代理间接地访问该对象，从而限制、增强或修改该对象的一些特性。 适配器（Adapter）模式：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。 桥接（Bridge）模式：将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度。 装饰（Decorator）模式：动态的给对象增加一些职责，即增加其额外的功能。 外观（Facade）模式：为多个复杂的子系统提供一个一致的接口，使这些子系统更加容易被访问。 享元（Flyweight）模式：运用共享技术来有效地支持大量细粒度对象的复用。 组合（Composite）模式：将对象组合成树状层次结构，使用户对单个对象和组合对象具有一致的访问性。 模板方法（TemplateMethod）模式：定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。 策略（Strategy）模式：定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的改变不会影响使用算法的客户。 命令（Command）模式：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。 职责链（Chain of Responsibility）模式：把请求从链中的一个对象传到下一个对象，直到请求被响应为止。通过这种方式去除对象之间的耦合。 状态（State）模式：允许一个对象在其内部状态发生改变时改变其行为能力。 观察者（Observer）模式：多个对象间存在一对多关系，当一个对象发生改变时，把这种改变通知给其他多个对象，从而影响其他对象的行为。 中介者（Mediator）模式：定义一个中介对象来简化原有对象之间的交互关系，降低系统中对象间的耦合度，使原有对象之间不必相互了解。 迭代器（Iterator）模式：提供一种方法来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。 访问者（Visitor）模式：在不改变集合元素的前提下，为一个集合中的每个元素提供多种访问方式，即每个元素有多个访问者对象访问。 备忘录（Memento）模式：在不破坏封装性的前提下，获取并保存一个对象的内部状态，以便以后恢复它。 解释器（Interpreter）模式：提供如何定义语言的文法，以及对语言句子的解释方法，即解释器。  结构型模式概述 ​\t结构型模式描述如何将类或对象按某种布局组成更大的结构。它分为类结构型模式和对象结构型模式，前者采用继承机制来组织接口和类，后者釆用组合或聚合来组合对象。由于组合关系或聚合关系比继承关系耦合度低，满足“合成复用原则”，所以对象结构型模式比类结构型模式具有更大的灵活性。\n代理模式 ​\t代理模式的定义：由于某些原因需要给某对象提供一个代理以控制对该对象的访问。这时，访问对象不适合或者不能直接引用目标对象，代理对象作为访问对象和目标对象之间的中介。\n适配器模式 ​\t将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。适配器模式分为类结构型模式和对象结构型模式两种，前者类之间的耦合度比后者高，且要求程序员了解现有组件库中的相关组件的内部结构，所以应用相对较少些。\n桥接模式 ​\t将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度。\n​\t桥接（Bridge）模式包含以下主要角色。\n 抽象化（Abstraction）角色：定义抽象类，并包含一个对实现化对象的引用。这里就相当于是一个桥将一个类与另一个类联系起来了。 扩展抽象化（Refined Abstraction）角色：是抽象化角色的子类，实现父类中的业务方法，并通过组合关系调用实现化角色中的业务方法。 实现化（Implementor）角色：定义实现化角色的接口，供扩展抽象化角色调用。 具体实现化（Concrete Implementor）角色：给出实现化角色接口的具体实现。  客户去买包，有钱包和书包，钱包又分红色和白色，书包也分红色和白色，如果按照普通的设计，那么就是书包继承包，钱包继承包，然后红色的书包继承书包，白色的书包继承书包等等，而桥接模式就是，先把颜色抽象出来成为一个单独的类（接口），红色实现颜色，黄色实现颜色，包将颜色变成属性（桥），书包继承包，钱包继承包，然后书包通过继承包就可以选择响应的颜色。\nColor color = new Yellow();\rBag bag = new Wallet();\rbag.setColor(color);\r 桥接模式通常适用于以下场景。\n 当一个类存在两个独立变化的维度，且这两个维度都需要进行扩展时。// 包按使用来分分为钱包和书包，按颜色分为红色和黄色 当一个系统不希望使用继承或因为多层次继承导致系统类的个数急剧增加时。// 因为如果采用多继承的话，增加一个垮包，需要增加三个类，（一个挎包类，一个黄色的挎包类，一个红色的挎包类） 当一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性时。  装饰模式 ​\t指在不改变现有对象结构的情况下，动态地给该对象增加一些职责（即增加其额外功能）的模式，它属于对象结构型模式。通常情况下，扩展一个类的功能会使用继承方式来实现。但继承具有静态特征，耦合度高，并且随着扩展功能的增多，子类会很膨胀。如果使用组合关系来创建一个包装对象（即装饰对象）来包裹真实对象，并在保持真实对象的类结构不变的前提下，为其提供额外的功能，这就是装饰模式的目标。下面来分析其基本结构和实现方法。装饰模式主要包含以下角色。\n  抽象构件（Component）角色：定义一个抽象接口以规范准备接收附加责任的对象。// 需要增加功能的类，shape类，抽象出了一个画的方法\n  具体构件（ConcreteComponent）角色：实现抽象构件，通过装饰角色为其添加一些职责。// 具体的构件，Circle画圆，Rectangle画长方形，这两个构件需要增加功能，比如画红色的圆。\n  抽象装饰（Decorator）角色：继承抽象构件，并包含具体构件的实例，可以通过其子类扩展具体构件的功能。// 一个可以将具体构件传入的类，ShapeDecorator\n  具体装饰（ConcreteDecorator）角色：实现抽象装饰的相关方法，并给具体构件对象添加附加的责任。// 通过实现抽象装饰，来扩展传入的构件，追加方法，这里追加了一个方法，红色的边框。\nShape circle = new Circle();// 画一个圆\rcircle.draw();//画一个圆\rShape redCircle = new RedShapeDecorator(new Circle());// 将圆传入具体装饰角色追加功能，这里是追加了一个红色边框\rredCircle.draw();//画出了一个红色边框的圆\r    装饰模式通常在以下几种情况使用。\r- 当需要给一个现有类添加附加职责，而又不能采用生成子类的方法进行扩充时。例如，该类被隐藏或者该类是终极类或者采用继承方式会产生大量的子类。\r- 当需要通过对现有的一组基本功能进行排列组合而产生非常多的功能时，采用继承关系很难实现，而采用装饰模式却很好实现。// 比如既要画红色的圆，又要画红色的长方形，\r- 当对象的功能要求可以动态地添加，也可以再动态地撤销时。\rJava I/o 标准库就是采用了装饰模式\r![InputStream部分类关系](http://image.laijianfeng.org/20180918InputStream.png)\r````Java\rDataInputStream in=new DataInputStream(new BufferedInputStream(new FileInputStream(\u0026quot;D:\\\\hello.txt\u0026quot;)));\r 外观模式 ​\t外观（Facade）模式又叫作门面模式，是一种通过为多个复杂的子系统提供一个一致的接口，而使这些子系统更加容易被访问的模式。该模式对外有一个统一接口，外部应用程序不用关心内部子系统的具体细节，这样会大大降低应用程序的复杂度，提高了程序的可维护性。\n外观（Facade）模式是“迪米特法则”的典型应用，它有以下主要优点。\n 降低了子系统与客户端之间的耦合度，使得子系统的变化不会影响调用它的客户类。 对客户屏蔽了子系统组件，减少了客户处理的对象数目，并使得子系统使用起来更加容易。 降低了大型软件系统中的编译依赖性，简化了系统在不同平台之间的移植过程，因为编译一个子系统不会影响其他的子系统，也不会影响外观对象。  外观（Facade）模式的主要缺点如下。\n 不能很好地限制客户使用子系统类，很容易带来未知风险。 增加新的子系统可能需要修改外观类或客户端的源代码，违背了“开闭原则”。  外观（Facade）模式包含以下主要角色。\n 外观（Facade）角色：为多个子系统对外提供一个共同的接口。 子系统（Sub System）角色：实现系统的部分功能，客户可以通过外观角色访问它。 客户（Client）角色：通过一个外观角色访问各个子系统的功能。  其结构图如图 2 所示。\n享元模式 ​\t享元（Flyweight）模式的定义：运用共享技术来有效地支持大量细粒度对象的复用。它通过共享已经存在的对象来大幅度减少需要创建的对象数量、避免大量相似类的开销，从而提高系统资源的利用率。享元模式的定义提出了两个要求，细粒度和共享对象。因为要求细粒度，所以不可避免地会使对象数量多且性质相近，此时我们就将这些对象的信息分为两个部分：内部状态和外部状态。\n 内部状态指对象共享出来的信息，存储在享元信息内部，并且不会随环境的改变而改变； 外部状态指对象得以依赖的一个标记，随环境的改变而改变，不可共享。  享元模式的主要角色有如下。\n  抽象享元角色（Flyweight）：是所有的具体享元类的基类，为具体享元规范需要实现的公共接口，非享元的外部状态以参数的形式通过方法传入。\n  具体享元（Concrete Flyweight）角色：实现抽象享元角色中所规定的接口。\n  非享元（Unsharable Flyweight)角色：是不可以共享的外部状态，它以参数的形式注入具体享元的相关方法中。\n  享元工厂（Flyweight Factory）角色：负责创建和管理享元角色。当客户对象请求一个享元对象时，享元工厂检査系统中是否存在符合要求的享元对象，如果存在则提供给客户；如果不存在的话，则创建一个新的享元对象。\n我的理解，其实所谓的享元模式就是将可以共享的元素或者方法抽象出来成为一个类，然后通过一个统一的接口传入不可共享的元素，完成工作，共享的方法是在一个工厂中，若此对象不存在则创建，然后加入到map中，若存在则直接从map中取出。\n  组合模式 ​\t组合（Composite Pattern）模式的定义：有时又叫作整体-部分（Part-Whole）模式，它是一种将对象组合成树状的层次结构的模式，用来表示“整体-部分”的关系，使用户对单个对象和组合对象具有一致的访问性。组合模式一般用来描述整体与部分的关系，它将对象组织到树形结构中，顶层的节点被称为根节点，根节点下面可以包含树枝节点和叶子节点，树枝节点下面又可以包含树枝节点和叶子节点，树形结构图如下。\n组合模式包含以下主要角色。\n 抽象构件（Component）角色：它的主要作用是为树叶构件和树枝构件声明公共接口，并实现它们的默认行为。在透明式的组合模式中抽象构件还声明访问和管理子类的接口；在安全式的组合模式中不声明访问和管理子类的接口，管理工作由树枝构件完成。（总的抽象类或接口，定义一些通用的方法，比如新增、删除） 树叶构件（Leaf）角色：是组合中的叶节点对象，它没有子节点，用于继承或实现抽象构件。 树枝构件（Composite）角色 / 中间构件：是组合中的分支节点对象，它有子节点，用于继承和实现抽象构件。它的主要作用是存储和管理子部件，通常包含 Add()、Remove()、GetChild() 等方法  行为型模式 ​\t行为型模式用于描述程序在运行时复杂的流程控制，即描述多个类或对象之间怎样相互协作共同完成单个对象都无法单独完成的任务，它涉及算法与对象间职责的分配。行为型模式分为类行为模式和对象行为模式，前者采用继承机制来在类间分派行为，后者采用组合或聚合在对象间分配行为。由于组合关系或聚合关系比继承关系耦合度低，满足“合成复用原则”，所以对象行为模式比类行为模式具有更大的灵活性。\n模板方法模式 ​\t定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。它是一种类行为型模式。\n模板方法模式包含以下主要角色。\n1）抽象类/抽象模板（Abstract Class）\n抽象模板类，负责给出一个算法的轮廓和骨架。它由一个模板方法和若干个基本方法构成。这些方法的定义如下。\n① 模板方法：定义了算法的骨架，按某种顺序调用其包含的基本方法。\n② 基本方法：是整个算法中的一个步骤，包含以下几种类型。\n 抽象方法：在抽象类中声明，由具体子类实现。 具体方法：在抽象类中已经实现，在具体子类中可以继承或重写它。 钩子方法：在抽象类中已经实现，包括用于判断的逻辑方法和需要子类重写的空方法两种。  2）具体子类/具体实现（Concrete Class）\n具体实现类，实现抽象类中所定义的抽象方法和钩子方法，它们是一个顶级逻辑的一个组成步骤。\n模板方法模式通常适用于以下场景。\n 算法的整体步骤很固定，但其中个别部分易变时，这时候可以使用模板方法模式，将容易变的部分抽象出来，供子类实现。 当多个子类存在公共的行为时，可以将其提取出来并集中到一个公共父类中以避免代码重复。首先，要识别现有代码中的不同之处，并且将不同之处分离为新的操作。最后，用一个调用这些新的操作的模板方法来替换这些不同的代码。 当需要控制子类的扩展时，模板方法只在特定点调用钩子操作，这样就只允许在这些点进行扩展。  所以平常写的代码到底是命令模式还是模板方法模式？我们平常的代码有点像命令模式但是没有实现者，具体命令类也没有实现者对象，调用者好像也没有，哈哈\n命令模式 ​\t将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。这样两者之间通过命令对象进行沟通，这样方便将命令对象进行储存、传递、调用、增加与管理。\n可以将系统中的相关操作抽象成命令，使调用者与实现者相关分离，其结构如下。\n模式的结构\n命令模式包含以下主要角色。\n 抽象命令类（Command）角色：声明执行命令的接口，拥有执行命令的抽象方法 execute()。 具体命令类（Concrete Command）角色：是抽象命令类的具体实现类，它拥有接收者对象，并通过调用接收者的功能来完成命令要执行的操作。 实现者/接收者（Receiver）角色：执行命令功能的相关操作，是具体命令对象业务的真正实现者。 调用者/请求者（Invoker）角色：是请求的发送者，它通常拥有很多的命令对象，并通过访问命令对象来执行相关请求，它不直接访问接收者。  其结构图如图 1 所示。\n策略模式 ​\t该模式定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的变化不会影响使用算法的客户。策略模式属于对象行为模式，它通过对算法进行封装，把使用算法的责任和算法的实现分割开来，并委派给不同的对象对这些算法进行管理。策略模式是准备一组算法，并将这组算法封装到一系列的策略类里面，作为一个抽象策略类的子类。策略模式的重心不是如何实现算法，而是如何组织这些算法，从而让程序结构更加灵活，具有更好的维护性和扩展性，现在我们来分析其基本结构和实现方法。\n策略模式的主要角色如下。\n 抽象策略（Strategy）类：定义了一个公共接口，各种不同的算法以不同的方式实现这个接口，环境角色使用这个接口调用不同的算法，一般使用接口或抽象类实现。 具体策略（Concrete Strategy）类：实现了抽象策略定义的接口，提供具体的算法实现。 环境（Context）类：持有一个策略类的引用，最终给客户端调用。  责任链模式 ​\t为了避免请求发送者与多个请求处理者耦合在一起，于是将所有请求的处理者通过前一对象记住其下一个对象的引用而连成一条链；当有请求发生时，可将请求沿着这条链传递，直到有对象处理它为止。\n通常情况下，可以通过数据链表来实现职责链模式的数据结构。\n模式的结构\n​\t职责链模式主要包含以下角色。\n 抽象处理者（Handler）角色：定义一个处理请求的接口，包含抽象处理方法和一个后继连接。 具体处理者（Concrete Handler）角色：实现抽象处理者的处理方法，判断能否处理本次请求，如果可以处理请求则处理，否则将该请求转给它的后继者。 客户类（Client）角色：创建处理链，并向链头的具体处理者对象提交请求，它不关心处理细节和请求的传递过程。  模式的应用场景\n 多个对象可以处理一个请求，但具体由哪个对象处理该请求在运行时自动确定。// 有多个具体处理者，由传入的条件决定使用哪个处理者 可动态指定一组对象处理请求，或添加新的处理者。 需要在不明确指定请求处理者的情况下，向多个处理者中的一个提交请求。  职责链模式存在以下两种情况。\n 纯的职责链模式：一个请求必须被某一个处理者对象所接收，且一个具体处理者对某个请求的处理只能采用以下两种行为之一：自己处理（承担责任）；把责任推给下家处理。 不纯的职责链模式：允许出现某一个具体处理者对象在承担了请求的一部分责任后又将剩余的责任传给下家的情况，且一个请求可以最终不被任何接收端对象所接收。  状态模式 ​\t对有状态的对象，把复杂的“判断逻辑”提取到不同的状态对象中，允许状态对象在其内部状态发生改变时改变其行为。状态模式把受环境改变的对象行为包装在不同的状态对象里，其意图是让一个对象在其内部状态改变的时候，其行为也随之改变。现在我们来分析其基本结构和实现方法。\n模式的结构\n状态模式包含以下主要角色。\n 环境类（Context）角色：也称为上下文，它定义了客户端需要的接口，内部维护一个当前状态，并负责具体状态的切换。 抽象状态（State）角色：定义一个接口，用以封装环境对象中的特定状态所对应的行为，可以有一个或多个行为。 具体状态（Concrete State）角色：实现抽象状态所对应的行为，并且在需要的情况下进行状态切换。  其结构图如图 1 所示。\n多线程存在 5 种状态，分别为新建状态、就绪状态、运行状态、阻塞状态和死亡状态，各个状态当遇到相关方法调用或事件触发时会转换到其他状态，其状态转换规律如图 3 所示。\n图3 线程状态转换图\n现在先定义一个抽象状态类（TheadState），然后为图 3 所示的每个状态设计一个具体状态类，它们是新建状态（New）、就绪状态（Runnable ）、运行状态（Running）、阻塞状态（Blocked）和死亡状态（Dead），每个状态中有触发它们转变状态的方法，环境类（ThreadContext）中先生成一个初始状态（New），并提供相关触发方法，图 4 所示是线程状态转换程序的结构图。\n观察者模式 ​\t指多个对象间存在一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。这种模式有时又称作发布-订阅模式、模型-视图模式，它是对象行为型模式。实现观察者模式时要注意具体目标对象和具体观察者对象之间不能直接调用，否则将使两者之间紧密耦合起来，这违反了面向对象的设计原则。\n观察者模式的主要角色如下。\n 抽象主题（Subject）角色：也叫抽象目标类，它提供了一个用于保存观察者对象的聚集类和增加、删除观察者对象的方法，以及通知所有观察者的抽象方法。 具体主题（Concrete Subject）角色：也叫具体目标类，它实现抽象目标中的通知方法，当具体主题的内部状态发生改变时，通知所有注册过的观察者对象。 抽象观察者（Observer）角色：它是一个抽象类或接口，它包含了一个更新自己的抽象方法，当接到具体主题的更改通知时被调用。 具体观察者（Concrete Observer）角色：实现抽象观察者中定义的抽象方法，以便在得到目标的更改通知时更新自身的状态。  中介者模式 ​\t定义一个中介对象来封装一系列对象之间的交互，使原有对象之间的耦合松散，且可以独立地改变它们之间的交互。中介者模式又叫调停模式，它是迪米特法则的典型应用。\n中介者模式实现的关键是找出“中介者”，下面对它的结构和实现进行分析。\n中介者模式包含以下主要角色。\n 抽象中介者（Mediator）角色：它是中介者的接口，提供了同事对象注册与转发同事对象信息的抽象方法。 具体中介者（Concrete Mediator）角色：实现中介者接口，定义一个 List 来管理同事对象，协调各个同事角色之间的交互关系，因此它依赖于同事角色。 抽象同事类（Colleague）角色：定义同事类的接口，保存中介者对象，提供同事对象交互的抽象方法，实现所有相互影响的同事类的公共功能。 具体同事类（Concrete Colleague）角色：是抽象同事类的实现者，当需要与其他同事对象交互时，由中介者对象负责后续的交互。  前面分析了中介者模式的结构与特点，下面分析其以下应用场景。\n 当对象之间存在复杂的网状结构关系而导致依赖关系混乱且难以复用时。 当想创建一个运行于多个类之间的对象，又不想生成新的子类时。  迭代器模式 ​\t提供一个对象来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示\n迭代器模式是通过将聚合对象的遍历行为分离出来，抽象成迭代器类来实现的，其目的是在不暴露聚合对象的内部结构的情况下，让外部代码透明地访问聚合的内部数据。现在我们来分析其基本结构与实现方法。\n模式的结构\n迭代器模式主要包含以下角色。\n 抽象聚合（Aggregate）角色：定义存储、添加、删除聚合对象以及创建迭代器对象的接口。 具体聚合（ConcreteAggregate）角色：实现抽象聚合类，返回一个具体迭代器的实例。 抽象迭代器（Iterator）角色：定义访问和遍历聚合元素的接口，通常包含 hasNext()、first()、next() 等方法。 具体迭代器（Concretelterator）角色：实现抽象迭代器接口中所定义的方法，完成对聚合对象的遍历，记录遍历的当前位置。  不是很懂\n访问者模式 ​\t将作用于某种数据结构中的各元素的操作分离出来封装成独立的类，使其在不改变数据结构的前提下可以添加作用于这些元素的新的操作，为数据结构中的每个元素提供多种访问方式。它将对数据的操作与数据结构进行分离，是行为类模式中最复杂的一种模式。\n访问者模式包含以下主要角色。\n 抽象访问者（Visitor）角色：定义一个访问具体元素的接口，为每个具体元素类对应一个访问操作 visit() ，该操作中的参数类型标识了被访问的具体元素。 具体访问者（ConcreteVisitor）角色：实现抽象访问者角色中声明的各个访问操作，确定访问者访问一个元素时该做什么。 抽象元素（Element）角色：声明一个包含接受操作 accept() 的接口，被接受的访问者对象作为 accept() 方法的参数。 具体元素（ConcreteElement）角色：实现抽象元素角色提供的 accept() 操作，其方法体通常都是 visitor.visit(this) ，另外具体元素中可能还包含本身业务逻辑的相关操作。 对象结构（Object Structure）角色：是一个包含元素角色的容器，提供让访问者对象遍历容器中的所有元素的方法，通常由 List、Set、Map 等聚合类实现。// 数据结构，需要包含元素  访问者模式的核心思想是为了访问比较复杂的数据结构，不去改变数据结构，而是把对数据的操作抽象出来，在“访问”的过程中以回调形式在访问者中处理操作逻辑。如果要新增一组操作，那么只需要增加一个新的访问者。\n备忘录模式 ​\t在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，以便以后当需要时能将该对象恢复到原先保存的状态。该模式又叫快照模式。备忘录模式的核心是设计备忘录类以及用于管理备忘录的管理者类，现在我们来学习其结构与实现。\n模式的结构\n备忘录模式的主要角色如下。\n 发起人（Originator）角色：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，它可以访问备忘录里的所有信息。 备忘录（Memento）角色：负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人。 管理者（Caretaker）角色：对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改。  自己的理解，备忘录模式其实就是发起人将自己的状态通过自身的方法保存在备忘录中，而这个备忘录是管理者的属性，也就是说，发起人将自己的状态保存在管理者的备忘录属性中，当发起人状态改变，但还未保存想要回滚时就可以从管理者这里取出自己保存的状态然后更新自己的状态，这就达到了回滚的效果。\n下面介绍备忘录模式如何同原型模式混合使用。在备忘录模式中，通过定义“备忘录”来备份“发起人”的信息，而原型模式的 clone() 方法具有自备份功能，所以，如果让发起人实现 Cloneable 接口就有备份自己的功能，这时可以删除备忘录类。也就是说将管理者直接管理发起人，当发起人状态改变，并保存时就把自己通过原型模式也就是克隆一份给到管理者，当需要回滚时，只需要将管理者中永远的发起人的状态更新给真正的发起人即可。\n解释器模式 ","id":16,"section":"posts","summary":"设计模式 七大软件设计原则 1 . 开闭原则 ​ 软件实体应当对扩展开放，对修改关闭。当应用的需求改变时，在不修改软件实体的源代码或者二进制代码的前提下","tags":["设计模式"],"title":"设计模式","uri":"https://wzgl998877.github.io/2022/01/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","year":"2022"}],"tags":[{"title":"http","uri":"https://wzgl998877.github.io/tags/http/"},{"title":"Java基础","uri":"https://wzgl998877.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"title":"Java并发","uri":"https://wzgl998877.github.io/tags/java%E5%B9%B6%E5%8F%91/"},{"title":"JVM","uri":"https://wzgl998877.github.io/tags/jvm/"},{"title":"LeetCode","uri":"https://wzgl998877.github.io/tags/leetcode/"},{"title":"Linux命令","uri":"https://wzgl998877.github.io/tags/linux%E5%91%BD%E4%BB%A4/"},{"title":"mybatis","uri":"https://wzgl998877.github.io/tags/mybatis/"},{"title":"mysql","uri":"https://wzgl998877.github.io/tags/mysql/"},{"title":"Netty","uri":"https://wzgl998877.github.io/tags/netty/"},{"title":"RPC","uri":"https://wzgl998877.github.io/tags/rpc/"},{"title":"spring","uri":"https://wzgl998877.github.io/tags/spring/"},{"title":"Websocket","uri":"https://wzgl998877.github.io/tags/websocket/"},{"title":"消息队列","uri":"https://wzgl998877.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"title":"设计模式","uri":"https://wzgl998877.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]}